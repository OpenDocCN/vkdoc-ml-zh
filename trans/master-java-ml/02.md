

# 二、现实世界监督学习的实用方法

从带有标记目标或标签的观察中学习的能力，通常是为了对未知数据做出预测，被称为**监督机器学习**。如果目标是类别，则问题是一个分类的，如果是数值，则称为**回归**。实际上，我们尝试的是推断将数据映射到目标的函数。有监督的机器学习被广泛用于各种各样的机器学习应用中，只要有标记的数据可用或者可以手动添加标记。

监督机器学习的核心假设是，从训练中使用的数据中学习到的模式将在尚未看到的数据中表现出来。

在本章中，我们将讨论在继续训练模型之前用于探索、分析和预处理数据的步骤。然后我们将介绍不同的建模技术，从简单的线性模型到复杂的集合模型。我们将展示不同的评估指标和验证标准，让我们能够比较模型的性能。一些讨论伴随着简短的数学解释，这将有助于更精确地表达概念，并激起更倾向于数学的读者的兴趣。在这一章中，我们将把重点放在作为监督学习的一种方法的分类上，但是这些原理适用于监督学习的两个广泛应用——分类和回归。

从本章开始，我们将介绍一些工具来帮助说明如何使用每章中介绍的概念来解决机器学习问题。没有什么比将新学到的知识直接应用到现实世界的问题中更能加深理解的了。在这个过程中，我们通常会获得比被动吸收理论更清晰、更相关的理解。如果学习新工具的机会是学习的一部分，那就更好了！为了实现这一目标，我们将引入大多数数据科学从业者熟悉的分类数据集，并使用它来解决分类问题，同时强调指导解决方案的流程和方法。

在本章中，我们将使用 RapidMiner 和 Weka 来构建我们从一个众所周知的数据集学习的过程。网站上提供了工作流和代码，供读者下载、执行和修改。

RapidMiner 是一个基于 GUI 的 Java 框架，它使得从工具内部进行端到端的数据科学项目变得非常容易。它有一个简单的拖放界面来构建流程工作流，以摄取和清理数据、探索和转换功能、使用各种机器学习算法执行培训、进行验证和模型评估、将您的最佳模型应用于测试数据等。这是一个很好的工具，可以学习如何使流程的各个部分协同工作并快速产生结果。Weka 是另一个基于 GUI 的框架，它有一个 Java API，我们将用它来说明执行分析所需的更多编码。

我们将在本章中讨论的主要话题是:

*   数据质量分析
*   描述性数据分析
*   可视化分析
*   数据转换和预处理
*   数据采样
*   特征相关性分析和降维
*   模型结构
*   模型评估、评价和比较
*   详细案例研究——马绞痛分类

# 形式描述和符号

我们想为监督学习中使用的术语介绍一些符号和正式定义。如果没有特别说明，我们将在本书的其余部分遵循这一符号，并在遇到新概念时适当地扩展它。该符号将提供一种精确和一致的语言来描述艺术术语，并能够更快速和有效地理解主题。

*   **实例**:每一个观察都是一个数据实例。通常变量 *X* 用于表示输入空间。每个数据实例有许多变量(也称为特征)，被称为维度为 *d* 的 **x** (粗体向量表示)，其中 *d* 表示每个实例中变量或特征或属性的数量。这些特征表示为**x**=*(x*[1]*，x* [2] *，…x*[d]*)*^T，其中每一个值都是与特征值相对应的数值时的标量。
*   **标签**:标签(也叫目标)是感兴趣的因变量，一般用 *y* 表示。在**分类**中，标签的值是问题域中明确定义的类别；它们不必是数字或是可以订购的东西。在**回归**中，标签是实值的。
*   **Binary classification**, where the target takes only two values, it is mathematically represented as:

    y ∈ {1，–1 }

*   **回归**，其中目标可以取实数域内的任意值，表示为:![Formal description and notation](graphics/B05137_02_008.jpg)
*   **数据集**:一般来说，数据集用 *D* 表示，由单个数据实例及其标签组成。实例通常表示为 set { **x** [1] ，**x**[2]…**x**[n]}。每个实例的标签表示为集合**y**= {*y*[1]*，y* [2] *，…y* [n] }。整个被标记的数据集被表示为集合中的成对元素，由*D*= {(**x**[1]， *y* [1] )，( **x** [2] ，*y*[2])……(**x**[n]，*y*

## *数据质量分析*

*从质量差的数据中学到的东西是有限的。质量问题可能包括噪音数据、缺失值和标签错误等因素。因此，第一步是了解我们面前的数据，以便我们可以确定如何解决任何数据质量问题。异常值仅仅是噪音还是群体中有趣异常的指示？对于所有要素，是否应该以相同的方式处理缺失数据？稀疏特征应该如何处理？这些和类似的问题一开始就出现了。*

*如果幸运的话，我们会收到一个干净的、准确标记的数据集，并附有描述数据元素、数据谱系以及数据是否已经进行了任何转换的文档。这样的数据集可以使用数据采样一节中描述的方法分成训练样本、验证样本和测试样本。但是，如果数据没有经过清理，不适合进行分区，那么在开始采样之前，我们必须首先对数据进行原则性的准备。(对数据进行分区的重要性将在本章后面专门讨论定型、验证和测试集的部分中解释)。*

*在以下部分中，我们将讨论在分析要素之前所需的数据质量分析和转换步骤。*

## *描述性数据分析*

*应对完整的数据样本(包括训练、验证和测试)进行分析和总结，以获得以下特征。在数据还没有被划分为训练、验证和测试的情况下，数据转换的任务需要确保样本具有相似的特征和统计数据。这对于确保经过训练的模型能够对看不见的数据进行归纳至关重要，我们将在数据采样一节中了解到这一点。*

### *基本标签分析*

*分析的第一步是了解标签在不同集合中的分布，以及在整个数据中的分布。这有助于确定，例如，目标变量的分布是否不平衡，如果是，是否在所有样本中是一致的。因此，第一步通常是找出每个类在训练和测试集中有多少个例子。*

### *基本特征分析*

*下一步是计算每个特征的统计数据，例如*

*   *唯一值的数量*
*   *缺失值的数量:可能包括按不同缺失值替代项分组的计数(NA，null，？，以此类推)。*
*   *对于分类:这跨特征类别计数，按标签类别跨特征类别计数，最常出现的类别(模式)，按标签类别的模式，等等。*
*   *对于数值型:最小值、最大值、中值、标准差、方差等。*

*特征分析提供了基本的见解，可以作为影响学习过程或算法选择的缺失值和噪声的有用指标。*

## *可视化分析*

*数据的可视化是一个广泛的话题，它是机器学习和数据挖掘领域中一个不断发展的领域。我们将只讨论可视化的一些重要方面，这些方面有助于我们在实践中分析数据。*

### *单变量特征分析*

*这里的目标是一次可视化一个与标签相关的特征。使用的技术如下:*

#### *分类特征*

*当问题是分类时，堆叠的条形图是显示标签中每个特征类别分布的简单方式。*

#### *连续特征*

*直方图和箱线图是连续特征的两种基本可视化技术。*

*直方图具有预定义的条柱，其宽度或者是固定的间隔，或者是基于用于分割全范围特征值的某种计算。然后，对落入每个容器中的数据实例的数量进行计数，并基于该计数调整容器的高度。存在直方图的变体，例如相对或基于频率的直方图、Pareto 直方图、二维直方图等等；每一个都是概念的细微变化，允许对特性有不同的理解。对于那些有兴趣了解这些变体的人来说，维基百科关于直方图的文章是一个很好的资源。*

*箱线图是数值特征的关键可视化技术，因为它们以百分点和异常值的形式显示分布。*

### *多元特征分析*

*多元特征分析的理念是将多个特征可视化，以深入了解它们之间的关系。这里解释一些众所周知的情节。*

*   ***散点图**:一种重要的技术，用于理解不同特征之间以及特征和标签之间的关系。通常，二维散点图在实践中使用，其中数字特征形成维度。数据点在某个假想轴上的排列显示出相关性，而数据点的分散显示出无相关性。在低维空间中识别聚类也是有用的。气泡图是散点图的变体，其中两个特征形成维度轴，第三个特征与数据点的大小成比例，该图呈现出“气泡”区域的外观。密度图表通过引入数据点颜色、背景颜色等来帮助可视化更多的特征，从而提供更多的见解。*
*   ***散点图矩阵**:散点图矩阵是散点图的扩展，其中每个特征(和标签)的成对散点图被可视化。它提供了一种有效比较和执行高维数据多元分析的方法。*
*   ***平行图**:在该可视化中，每个特征线性排列在 x 轴上，每个特征的值的范围形成了 *y* 轴。因此，每个数据元素都表示为一条线，每个特性的值位于平行轴上。类别标签(如果有)用于给线条着色。平行图有助于更好地理解有效分离数据的特征。离差图是平行图的变体，其中不是显示实际数据点，而是绘制平均值和标准偏差。安德鲁斯图是平行图的另一种变体，其中数据使用傅立叶级数进行转换，并且对应于每个的函数值被投影。*

*<title>Data transformation and preprocessing</title><link rel="stylesheet" href="epub.css" type="text/css">

# 数据转换和预处理

在本节中，我们将讨论数据转换的广泛话题。数据转换的主要思想是获取输入数据，并以谨慎的方式对其进行转换,以便对其进行清理，从中提取最相关的信息，并将其转换为可用于进一步分析和学习的形式。在这些转换过程中，我们必须只使用设计好的方法，同时记住不要添加任何会影响数据完整性的偏见或工件。

## 特征构建

在某些数据集的情况下，我们需要从已经给定的特征中创建更多的特征。通常，某种形式的聚合是使用常见的聚合器(如平均值、总和、最小值或最大值)来创建附加要素。例如，在金融欺诈检测中，卡欺诈数据集通常包含账户在账户活跃的不同时间段内的交易行为。执行行为合成(例如通过捕获“一天内每个账户发生借记交易时的金额总和”)是向数据集添加新维度(基于现有要素构建)的要素构造示例。一般来说，设计增强数据预测能力的新功能需要领域知识和数据经验，使其成为一门艺术和科学。

## 处理缺失值

在真实世界的数据集中，许多要素通常会有缺失值。在某些情况下，它们因测量误差、记录失误或因各种情况无法获得而丢失；例如，个人可以选择不透露年龄或职业。为什么要关心缺失值呢？一种极端且不常见的处理方法是忽略那些缺少特征的记录，换句话说，只保留那些“完整”的例子。当丢失的要素在数据中普遍存在时，这种方法可能会大大减小数据集的大小。正如我们将在后面看到的，如果我们正在处理的系统是复杂的，数据集的大小可以为我们提供宝贵的优势。此外，即使在“不完整”的记录中，尽管存在缺失值，但只要我们使用适当的措施来处理问题，通常也有可以利用的预测值。另一方面，当数据本身的遗漏很严重时，一个可能会无意中丢弃关键信息，如在贷款申请中故意虚报或混淆信息，隐瞒可用于最终确定骨 fides 的信息。

可以说，学习过程中的一个重要步骤是采用一些系统化的方法来处理缺失值，并理解每个案例中决策的后果。有一些算法(如 nave Bayes)对缺失值不太敏感，但一般来说，在对数据进行任何形式的分析之前，最好将这些缺失值作为预处理步骤进行处理。以下是处理缺失值的一些方法。

*   **用均值和众数替换**:当我们用连续值特征的均值替换该特征的缺失值时，新的均值显然保持不变。但是，如果平均值受到异常值的严重影响，更好的方法可能是在计算中剔除异常值后使用平均值，或者使用中位数或众数。同样，当某个要素在数据集中稀疏表示时，平均值可能没有意义。对于具有分类值的要素，用样本中出现频率最高的值替换缺失值是一种合理的选择。
*   **通过插补替换**:当我们插补缺失值时，我们实际上是在构建特征的分类或回归模型，并根据记录中的其他特征进行预测，以便对缺失值进行分类或估计。
*   **最近邻插补**:对于分类特征的缺失值，我们将所讨论的特征视为目标，并训练一个 KNN 模型，其中 k 为不同类别的已知数量。然后，该模型用于预测缺失值。(KNN 模型是非参数化的，它根据相邻数据实例的函数为“传入”数据实例赋值，该算法将在本章稍后讨论非线性模型时介绍)。
*   **基于回归的插补**:在连续值变量的情况下，我们使用线性模型(如线性回归)来估计缺失数据，其原理与分类值相同。
*   **用户自定义插补**:在许多情况下，最适合输入缺失值的值必须来自问题域。例如，7.0 的 pH 值是中性的，更高的是碱性的，更低的是酸性的。最有意义的可能是估算一个中性 pH 值，而不是平均值或中值，这种见解是用户定义估算的一个实例。同样，在用正常体温或静息心率替代的情况下——这些都是医学上的例子。

## 离群值

处理异常值需要大量的关注和分析。异常值可能是数据中的噪音或错误，也可能是特别感兴趣的异常行为。后一种情况在[第 3 章](ch03.html "Chapter 3. Unsupervised Machine Learning Techniques")、*无监督机器学习技术*中有深入的论述。这里，我们假设前一种情况，即领域专家确信这些值确实是第一种意义上的异常值，即需要适当处理的噪声或错误获取或记录的数据。

以下是检测数据异常值的不同技术

*   **四分位距(IQR)** :四分位距是对数据可变性的度量，或者等同于统计离差。每个数字特征根据其在数据集中的值进行排序，然后有序集被分成四分位数。中值一般用来衡量集中趋势。IQR 用上下四分位数之间的差值 Q3-Q1 来衡量。异常值通常被认为是高于 Q3 + 1.5 * IQR 和低于 Q1 - 1.5 * IQR 的数据值。
*   **基于距离的方法**:基于距离的方法的最基本形式使用**k-最近邻** ( **k-NN** )和距离度量来给数据点评分。常用参数是 k-NN 中的值 *k* 和一个距离度量，例如欧几里德距离。距离最远的数据点被认为是异常值。有许多使用局部邻域、概率或其他因素的变体，这些都将在[第 3 章](ch03.html "Chapter 3. Unsupervised Machine Learning Techniques")、*无监督机器学习技术*中讨论。混合数据集既有分类特征又有数字特征，会扭曲基于距离的度量。
*   **基于密度的方法**:基于密度的方法计算给定距离 *D* 内数据点的比例，如果比例小于指定阈值 p，则认为是离群点。参数 p 和 D 被认为是用户定义的值；适当选择这些值的挑战是在预处理阶段使用这些方法的主要障碍之一。
*   **特征**的数学转换:对于非正态数据，比较的平均值会产生很大的误导，就像存在异常值的情况一样。非参数统计允许我们对高度倾斜的数据进行有意义的观察。在许多情况下，使用对数或平方根函数对这些值进行转换往往会使数据标准化，或者使它们更易于进行统计测试。这些变换极大地改变了要素分布的形状，例如，异常值越极端，对数变换的影响就越大。
*   **在机器学习模型中使用稳健的统计算法处理异常值**:我们在下一节建模中讨论的许多分类算法都隐式或显式地处理异常值。作为元学习框架工作的 Bagging 和 Boosting 变体通常对异常值或噪声数据点具有弹性，并且可能不需要预处理步骤来处理它们。
*   **标准化**:许多算法——基于距离的方法就是一个很好的例子——对特征的尺度非常敏感。预处理数字特征可确保所有数字特征都在正常范围内。这里给出了最著名的特征归一化技术:

    *   **最小-最大归一化**:在这种技术中，给定范围*【L，U】*，通常为*【0，1】*，每个具有值 *x* 的特征按照最小值和最大值 *x* [max] 和 *x* 进行归一化 使用公式:![Outliers](graphics/B05137_02_016.jpg)
    *   **Z 分数归一化**:在这种技术中，也称为标准化，特征值得到自动转换，使得平均值为 0，标准偏差为 1。 变换的技术如下:对于每个特征 *f* ，计算平均值( *f* )和标准差σ( *f* )，然后将值为 *x* 的特征变换为:

    ![Outliers](graphics/B05137_02_019.jpg)

## 离散化

许多算法只能处理类别值或名义值才有效，例如贝叶斯网络。在这种情况下，使用监督或非监督方法将数字特征离散化成类别就变得势在必行。讨论的一些技术有:

*   **宁滨**离散化:这种技术也被称为等宽离散化。范围从值*x*max 和*x*min 的每个特征 *f* 的数据的整个范围被分成预定数量的等间隔的 *k* ，每个具有宽度![Discretization](graphics/B05137_02_020.jpg)。“分割点”或离散化间隔为:![Discretization](graphics/B05137_02_021.jpg)
*   **按频率**离散化:这种技术也被称为等频率离散化。对特征进行排序，然后将整个数据离散成预定义的 *k* 区间，使得每个区间包含相同的比例。由于预定义的值 *k* ，通过宁滨离散化和通过频率离散化这两种技术都遭受信息损失。
*   **通过熵**离散化:给定标签，在值以迭代方式变化的分裂点上计算熵，以便区间的箱尽可能纯净或有区别。参考*特征评估技术*章节，了解基于熵(信息增益)的理论和计算。

## 数据采样

接收到的数据集可能经常需要明智的采样，以便有效地从数据中学习。数据的特征以及建模练习的目标决定了是否需要采样，如果需要，如何进行采样。在我们开始从这些数据中学习之前，创建训练、验证和测试数据样本至关重要，如本节所述。

### 需要取样吗？

当数据集很大或有噪声，或偏向一种类型时，是否采样的问题就变得很重要。答案取决于各个方面，如数据集本身、用于选择模型的目标和评估标准，以及潜在的其他实际考虑因素。在某些情况下，算法在内存和空间方面存在可伸缩性问题，但在样本上却能有效地工作，这可以通过模型在回归或分类目标方面的表现来衡量。比如 SVM 在内存和训练次数上分别缩放为*O(n*2*)*和 *O(n* ³ *)* 。在其他情况下，数据是如此不平衡，以至于许多算法不够健壮来处理这种倾斜。在文献中，旨在通过创建新的训练样本来重新平衡原始数据提取中的类别分布的步骤也被称为**重采样**。

### 欠采样和过采样

数据集在类别分布中表现出明显的不平衡，可以说包含了一个明显的少数类别。通常，这个少数类是我们特别感兴趣的一组实例，正是因为它的成员出现在如此罕见的情况下。比如信用卡诈骗，只有不到 0.1%的数据属于诈骗。这种偏斜不利于学习；毕竟，当我们寻求最小化分类中的总误差时，我们给所有的类以同等的权重，而不管一个类与另一个类相比是否代表不足。在二元分类问题中，我们称少数类为正类，多数类为负类，这是我们在下面的讨论中将遵循的约定。

多数类欠采样是一种常用于解决数据偏斜的技术。以信用卡欺诈为例，我们可以从原始数据集中创建不同的训练样本，这样每个样本都有来自原始数据集中的所有欺诈案例，而非欺诈案例则以某种固定的比例分布在所有训练样本中。因此，在通过这种方法创建的给定训练集中，与原始倾斜数据集相比，多数类现在代表性不足，有效地平衡了类的分布。可以以这种方式创建具有比例为 1:20 到 1:50 的标记阳性和标记阴性实例的训练样本，但是必须注意所使用的阴性实例的样本应该具有与主数据集的数据统计和分布相似的特征。使用多个训练样本以及不同比例的正面和负面实例的原因是为了使任何可能存在的采样偏差变得明显。

或者，我们可以选择对少数类进行过采样。如前所述，我们创建多个样本，其中来自少数类的实例是通过从原始数据集中进行有替换或无替换的采样来选择的。在没有替换的情况下采样时，样本之间没有复制的实例。通过替换，可能会在多个样本中发现一些实例。在样本的这种初始播种之后，我们可以通过从每个样本中的少数类内进行替换的随机采样来产生更平衡的类分布，直到我们得到期望的正例与负例的比率。过采样可能易于过度拟合，因为由于重复值，分类决策边界往往变得更加具体。 **SMOTE** ( **合成少数过采样技术**)是一种技术，通过在正类的相邻实例之间进行插值，在特征空间的空隙中创建合成数据点来缓解这个问题(*引用*【20】)。

#### 分层抽样

创建样本，使得具有相似特征的数据在总体中以相同的比例出现，这被称为分层抽样。在多类分类中，如果有 *N* 个类，每个类都有一定的比例，则创建样本，使它们以与原始数据集中相同的比例代表每个类。一般来说，创建多个样本来训练和测试模型以验证抽样的偏差是一个很好的实践。

## 培训、验证和测试集

创建良好分类模型的圣杯是在一组高质量、有代表性的(训练数据)上进行训练，调整参数并找到有效的模型(验证数据)，最后，通过模型在看不见的数据(测试数据)上的行为来评估模型的性能。

逻辑分组背后的中心思想是确保模型在训练期间没有见过的数据上得到验证或测试。否则，一个简单的“死记硬背的学习者”就能胜过算法。学习算法的泛化能力必须在不同于训练数据集但来自相同群体的数据集上进行评估(*参考文献*【11】)。在从训练中移除太多数据以增加验证和测试的预算之间的平衡可能导致模型遭受“拟合不足”，即没有足够的示例来构建有助于泛化的模式。另一方面，分配所有标记数据用于训练而不执行任何验证或测试的极端选择会导致“过度拟合”，即模型过于忠实地拟合示例，而不能足够好地概括。

通常，在大多数机器学习挑战和真实世界的客户问题中，预先给定一个训练集和测试集来评估模型的性能。在这些约定中，唯一的问题是如何验证和找到给定训练集的最有效的参数。在某些情况下，只给出带标签的数据集，您需要考虑训练集、验证集和测试集，以确保您的模型不会过拟合或欠拟合数据。

建模需要三个逻辑过程，因此需要三个逻辑数据集，即训练、验证和测试。训练数据集的目的是为学习算法提供带标签的数据以构建模型。验证集的目的是查看通过对验证集进行训练来评估的训练模型的参数的效果。最后，在训练集和验证集的组合上重新训练最佳参数或模型，以找到最佳模型，然后在盲测试集上测试该模型。

![Training, validation, and test set](graphics/B05137_02_022.jpg)

图 1:培训、验证和测试数据以及如何使用它们

有两件事会影响学习或泛化能力:算法(及其参数)的选择和训练数据的数量。这种的概括能力可以通过包括预测误差在内的各种指标来评估。模型的未知误差或风险的总体估计由下式给出:

![Training, validation, and test set](graphics/B05137_02_023.jpg)

这里，*噪声*是随机噪声， *Var (G，n)* 被称为方差误差，是对我们的假设或算法 *(G)* 在给定不同数据集的情况下易受影响程度的度量。![Training, validation, and test set](graphics/B05137_02_023a.jpg)称为偏差误差，代表模型中的最佳算法(所有可能数据集的平均学习者)与最佳算法的距离。

如图*图 2* 和*图 3* 所示的学习曲线——其中绘制了训练和测试误差，保持算法及其参数不变或训练数据大小不变——给出了欠拟合或过拟合的指示。

在训练数据大小固定的情况下，不同的算法或者相同的算法选择不同的参数可以表现出不同的学习曲线。*图 2* 显示了基于偏差和方差给出两条不同学习曲线的相同数据量的两种算法。

![Training, validation, and test set](graphics/B05137_02_028.jpg)

图 2:模型复杂度固定时的训练数据与错误率的关系，表示模型的不同选择。

算法或模型选择也会影响模型性能。需要调整更多参数的复杂算法可能会导致过度拟合，而参数较少的简单算法可能会拟合不足。当定型数据大小固定时，说明模型性能和复杂性的经典图如下:

![Training, validation, and test set](graphics/B05137_02_030.jpg)

图 3:当训练数据大小固定时，在训练和测试数据上，模型复杂度与错误率的关系。

验证允许探索参数空间以找到最能概括的模型。正则化(将在线性模型中讨论)和验证是应该使用来防止过度拟合的两种机制。有时“k 倍交叉验证”过程用于验证，这涉及创建数据的 *k* 样本，并使用*(k–1)*进行训练，剩余的样本进行测试，重复 *k* 次以给出平均估计值。下图以五重交叉验证为例:

![Training, validation, and test set](graphics/B05137_02_034.jpg)

图 4:五重交叉验证。

之后的是一些常用的技术，用于执行数据采样、验证和学习:

*   **培训、验证和测试的随机分割** : 60，20，20。用 60%进行训练，用 20%进行验证，然后结合训练和验证数据集来训练一个最终模型，用于在剩余的 20%上进行测试。分割可以是随机进行的，基于时间，基于区域，等等。
*   **训练、交叉验证和测试**:分成二对一的训练和测试，在训练集上使用交叉验证进行验证，三分之二的训练和三分之一的测试。可以随机地、基于时间、基于区域等等进行分割。
*   **训练和交叉验证**:当训练集小时，不需要太多的参数调整，只进行模型选择。对整个数据集运行交叉验证，并通过对整个数据集的学习选择最佳模型。



# 特征相关性分析和降维

特征相关性和选择的目标是找到区别于目标变量的特征，并帮助降低数据的维度[1，2，3]。这主要通过改善维数灾难的影响和通过去除由不相关特征引起的噪声来提高模型性能。通过仔细评估删除和不删除特征的验证集上的模型，我们可以看到特征相关性的影响。由于对 *k* 特征的穷举搜索涉及 2 个^k–1 个集合(考虑 *^k* 特征的所有组合，其中每个特征或者被保留或者被移除，不考虑不存在特征的退化情况)，必须被评估的模型的相应数量可能变得令人望而却步，因此需要某种形式的启发式搜索技术。下面介绍这些技术中最常见的一些。

## 特征搜索技术

用于查找特征集的一些非常常见的搜索技术有:

*   **前进或爬坡**:在此搜索中，一次添加一个功能，直到评估模块输出性能无进一步变化。
*   **向后搜索**:从整个集合开始，一次删除一个特征，直到性能没有改善。一些应用程序交叉使用前向和后向技术来搜索特征。
*   **进化搜索**:遗传算法等各种进化技术可用作搜索机制，基于过滤器或基于包装器的方法的评估指标可用作指导该过程的适合度标准。

## 特征评估技术

在高层次上，有三种基本方法来评估特性。

### 过滤方法

这种方法指的是使用技术而不使用机器学习算法进行评估。过滤方法的基本思想是使用一种搜索技术来选择一个特征(或特征子集),并使用一些统计测量来测量其重要性，直到达到停止标准。

#### 单变量特征选择

这个搜索就像根据所采用的统计方法对每个特征进行排序一样简单。

##### 信息论方法

所有的信息论方法都在核心使用熵机制的概念。其思想是，如果特征随机出现在数据集中，则存在最大熵，或者，等价地，压缩或编码的能力较低，并且该特征可能是不相关的。另一方面，如果特征值的分布是这样的，某个范围的值在一个类中相对于其他类更普遍，那么熵被最小化，并且该特征是有区别的。以这种方式用熵来描述问题需要某种形式的离散化，将数字特征转换成类别，以便计算概率。

考虑一个带有训练数据*D*X 的二元分类问题。如果 *X* [i] 是第 *i* ^(th) 个特征具有 *v* 个截然不同的分类值使得*D*[Xi]*= { D*[1]*，D*[2]*…D*[v]*}*

![Information theoretic approach](graphics/B05137_02_041.jpg)

这里， *Info(D* [j] *)* 是分区的熵，计算如下:

![Information theoretic approach](graphics/B05137_02_043.jpg)

这里， *p* [+] *(D)* 是集合 *D* 中的数据在正类中的概率， *p_(D)* 是在该样本中在负类中的概率。特征的信息增益是根据总体信息和特征的信息来计算的

*Info gain(X*[I]*)= Info(D)–Info(D*[Xi]*)*

对于数字特征，值按升序排序，相邻值之间的分割点被视为不同的值。

熵的减少越大，特征的相关性越高。当特征具有大量值时，信息增益存在问题；这就是增益比派上用场的时候。增益比通过引入分割信息来校正大分割的信息增益。特征*X*T2 I 和*增益比*的分割信息由下式给出:

![Information theoretic approach](graphics/B05137_02_048.jpg)![Information theoretic approach](graphics/B05137_02_049.jpg)

还有其他杂质测量，如基尼杂质指数(如关于*决策树*算法的章节所述)和基于不确定性的测量来计算特征相关性。

##### 统计方法

卡方特征选择是最常用的特征选择方法之一，它以统计假设检验为基础。无效假设是特征和类变量相互独立。数值要素被离散化，因此所有要素都具有分类值。应急表的计算方法如下:

| 

特征值

 | 

Class=P

 | 

类别=N

 | 

总纲*年谱* + *年谱*

 |
| --- | --- | --- | --- |
| *X*T2 1 | (*n*[1P]&#124;*[1P]* | (*n*[1N]&#124;*[1N]* | *n*1 |
| …. | … | …. | … |
| *X*m | (*n*[mP]&#124;*[mP]* | (*n*[【Mn】]&#124;*[)]* | *n*m |
|   | *n** P | *n** P | *n* |

> *列联表 1:显示二元类的特征值和类分布。*

在前面的表中， *n* [ij] 是离散化后值等于*x*I 和类值 *j* 的特征的数量。

价值总和为:

![Statistical approach](graphics/B05137_02_065.jpg)![Statistical approach](graphics/B05137_02_066.jpg)![Statistical approach](graphics/B05137_02_067.jpg)![Statistical approach](graphics/B05137_02_068.jpg)

这里 *n* 是数据实例的数量， *j = P，N* 是类值， *i =1，2，… m* 索引特征的不同离散化值，表具有*m–1*个自由度。

卡方统计由下式给出:

![Statistical approach](graphics/B05137_02_072.jpg)

将卡方值与置信度阈值进行比较，以测试显著性。例如，对于 *i = 2* ，阈值为 5%时的卡方值为 3.84；如果我们的值小于表中的值 3.83，那么我们知道该特征是有趣的，并且零假设被拒绝。

#### 多元特征选择

大多数特征选择的多元方法有两个目标:

*   减少特征和其他选定特征之间的冗余
*   最大化特征与分类标签的相关性或关联性

寻找这种特征子集的任务不可能是穷尽的，因为该过程可能具有大的搜索空间。启发式搜索方法如向后搜索、向前搜索、爬山和遗传算法通常用于寻找特征的子集。接下来介绍两种非常著名的用于满足上述目标的评估技术。

##### 最小冗余最大相关性(mRMR)

在这种技术中，数字特征通常被离散化——如单变量预处理中所做的那样——以获得不同类别的值。

对于的每个子集 *S* ，两个特征*X*I 和*X*j 之间的冗余度可以度量为:

![Minimal redundancy maximal relevance (mRMR)](graphics/B05137_02_077.jpg)

这里， *MI (X* [i] *，X* [j] *)* =两个特征之间互信息的度量 *X* [i] 和 *X* [j] 。特征*X*I 与类别 *C* 之间的相关性可以度量为:

![Minimal redundancy maximal relevance (mRMR)](graphics/B05137_02_081.jpg)

此外，可以将这两个目标结合起来，使用以下方法找到最佳特征子集:

![Minimal redundancy maximal relevance (mRMR)](graphics/B05137_02_082.jpg)

##### 基于相关性的特征选择(CFS)

的基本思路是类似于前面的例子；子集 *S* 的总体价值被测量为:

![Correlation-based feature selection (CFS)](graphics/B05137_02_083.jpg)

这里， *k* 是特征的总数，![Correlation-based feature selection (CFS)](graphics/B05137_02_084.jpg)是平均特征类相关性，![Correlation-based feature selection (CFS)](graphics/B05137_02_085.jpg)是平均特征-特征间相关性。分子给出相关性因子，而分母给出冗余因子，因此搜索的目标是最大化总比率或*价值*。

还有其他技术，例如基于快速相关性的特征选择，它基于相同的原则，但是在计算度量时有所不同。读者可以在 Weka 中试验这种技术和其他技术。

滤波器方法的优点是其方法独立于学习算法，因此无需选择算法和参数。它们也比基于包装的方法更快。

### 包装方法

搜索技术保持与特征搜索方法中讨论的相同；只是评估方法改变了。在包装方法中，使用机器学习算法来评估被发现基于各种度量进行区分的特征子集。用作包装方法的机器学习算法可以与用于建模的算法相同或不同。

最常见的是，在学习算法中使用交叉验证。性能指标，如曲线下面积或 F 值，作为交叉验证的平均值获得，指导搜索过程。由于训练和评估模型的成本非常高，我们选择训练速度快的算法，如线性回归、线性 SVM 或基于决策树的算法。

一些包装器方法已经非常成功地使用特定的算法，例如随机森林来测量特征相关性。

### 嵌入式方法

这种方法不需要特征搜索技术。不是将特征选择作为预处理来执行，而是在机器学习算法本身中完成。规则归纳、决策树、随机森林等执行特征选择作为训练算法的一部分。一些算法，如回归或基于 SVM 的方法，称为**收缩方法**，可以在模型中添加正则化项，以克服数据集中噪声特征的影响。基于脊和套索的正则化是回归中可用于隐式提供特征选择的众所周知的技术。

还有其他使用无监督算法的技术将在[第 3 章](ch03.html "Chapter 3. Unsupervised Machine Learning Techniques")、*无监督机器学习技术*中讨论，这些技术也可以在有监督的设置中有效使用，例如**主成分分析** ( **PCA** )。



# 模型构建

在现实世界的问题中，有许多学习上的限制和许多方法来评估模型在看不见的数据上的表现。当应用于一个给定的问题或一类特定领域的问题时，每种建模算法都有其优点和缺点。这在著名的**没有免费的午餐定理** ( **NFLT** )中得到了阐述，该定理称——对于监督学习的情况——平均所有数据分布，每种分类算法的表现都与任何其他算法一样好，包括总是选择相同类别的算法！在[http://www.no-free-lunch.org/](http://www.no-free-lunch.org/)中可以找到 NFLT 在监督学习、搜索和优化中的应用。

在本节中，我们将讨论最常用的实用算法，给出必要的细节来回答诸如算法的输入和输出是什么之类的问题。它是如何工作的？选择算法时要考虑哪些优点和局限性？对于每个模型，我们将包括样本代码和在所选数据集上测试模型获得的输出。这将为读者提供对该过程的洞察。一些算法，如神经网络和深度学习，贝叶斯网络，基于流的收入，等等，将在他们自己的章节中单独讨论。

## 线性模型

当数据可线性分离时，线性模型工作良好。这个应该永远是首先要建立的。

### 线性回归

线性回归可用于分类和估计问题。这是实践中最广泛使用的方法之一。它包括通过数据点找到最佳拟合超平面。

#### 算法输入和输出

特征必须是数字。使用各种预处理技术对分类特征进行转换，例如当分类值变成具有 1 和 0 值的特征时。线性回归模型在分类中输出分类类，在回归中输出数值。许多实现也给出了置信度值。

#### 它是如何工作的？

模型试图在输入空间中学习一个“超平面”，使每类数据点之间的误差最小化(*参考* [4])。

线性模型学习的 d 维输入中的超平面由下式给出:

![How does it work?](graphics/B05137_02_087.jpg)

模型将输入空间划分成的两个区域(二元分类)是![How does it work?](graphics/B05137_02_088.jpg)和![How does it work?](graphics/B05137_02_089.jpg)。将值 1 关联到特征 0 的坐标，即 *x* 0=1，假设空间或模型的向量表示为:

![How does it work?](graphics/B05137_02_091.jpg)

权重矩阵可以使用各种方法导出，例如使用如下矩阵符号的普通最小二乘法或迭代法:

![How does it work?](graphics/B05137_02_092.jpg)

这里 **X** 是输入矩阵， **y** 是标签。如果最小二乘问题中的矩阵**X**TX 不是满秩的，或者如果遇到各种数值稳定性问题，解决方案修改为:

![How does it work?](graphics/B05137_02_096.jpg)

这里，![How does it work?](graphics/B05137_02_097.jpg)被加到大小为( *n* + 1， *n* + 1)的单位矩阵**I**n 的对角线上，其余的值被设置为 0。该解决方案被称为**岭回归**，参数λ理论上控制解决方案的平方损失和低范数之间的权衡。常数λ也称为正则化常数，有助于防止“过拟合”。

#### 优点和局限性

*   当有少于 100 个特征和几千个数据点时，这是一种尝试和获得洞察力的合适方法。
*   在某种程度上是可以解释的，因为权重给出了对每个特性的影响的见解。
*   假设线性关系、附加和不相关的要素，因此它不会对复杂的非线性真实世界数据建模。线性回归的一些实现允许移除共线要素来克服这一问题。
*   对数据中的异常值非常敏感，如果存在巨大的异常值，则必须在执行线性回归之前对其进行处理。
*   异方差，即不相等的训练点方差，会影响简单的最小二乘回归模型。诸如加权最小二乘法之类的技术被用来克服这种情况。

### 天真的贝叶斯

基于贝叶斯规则的，朴素贝叶斯分类器假设数据的特征相互独立(*参考文献* [9】)。它特别适合于大型数据集，并且通常比其他更复杂的技术性能更好，尽管它天真地假设了特征独立性。

#### 算法输入和输出

朴素贝叶斯模型可以获取既分类又连续的特征。通常，如果连续要素以正确的格式离散化，朴素贝叶斯模型的性能会得到提高。朴素贝叶斯输出类和所有类值的概率分数，使其成为评分模型的良好分类器。

#### 它是如何工作的？

它是一种基于概率的建模算法。基本思想是使用贝叶斯法则，并测量不同项的概率，如下所示。可以使用预处理(如离散化)来测量概率，假设某个分布，或者在给定足够数据的情况下，映射数字特征的分布。

应用贝叶斯法则获得后验概率作为预测值，并且 *k* 代表第*k*第类。：

![How does it work?](graphics/B05137_02_101.jpg)![How does it work?](graphics/B05137_02_102.jpg)

#### 优点和局限性

*   它对孤立的噪声数据点具有鲁棒性，因为在估计输入数据的概率时，这些点是平均的。
*   来自贝叶斯分类的作为置信度值的概率分数可以用作评分模型。
*   可以很好地处理缺失值，因为它们不用于估计概率。
*   此外，它对不相关的属性也很健壮。如果这些特征是无用的，那么这些类别的概率分布将是均匀的，并且会自我抵消。
*   在训练速度和内存方面非常好，它可以并行化，因为方程中概率的每个计算都是相互独立的。
*   使用朴素贝叶斯时，相关特征可能是一个大问题，因为条件独立性假设不再有效。
*   在大多数优化算法中，误差的正态分布是一种假设。

### 逻辑回归

如果我们使用线性回归模型，比如说使用最小二乘回归方法，输出必须转换成类，比如说 0 和 1。许多线性回归算法将类别和置信度输出为概率。根据经验，如果我们看到线性回归的概率大多超出 0.2 到 0.8 的范围，那么逻辑回归算法可能是更好的选择。

#### 算法输入和输出

类似于线性回归的，所有特征必须是数字。分类特征必须转换成数字。与朴素贝叶斯一样，该算法输出类别和每个类别的概率，并可用作评分模型。

#### 它是如何工作的？

逻辑回归使用输入要素中的线性函数对类的后验概率进行建模。

二元分类的逻辑回归模型如下所示:

![How does it work?](graphics/B05137_02_104.jpg)

模型是线性模型的 log-odds 或 logit 变换(*参考* [6])。通常使用各种优化方法来计算权重向量，例如**迭代重新加权最小二乘法** ( **IRLS** )或**布罗伊登–弗莱彻–戈德法布–山诺** ( **BFGS** )方法，或这些方法的变体。

#### 优点和局限性

*   克服了输入和输出之间的异方差和某些非线性问题。
*   误差估计中不需要正态分布假设。
*   它是可以解释的，但不如线性回归模型，因为需要对统计数据有所了解。它给出了比值比、 *p* 值等信息，这些信息有助于理解特征对类的影响，以及基于 *p* 值的显著性进行隐式特征关联。
*   在实践中，必须采用 L1 或 L2 正则化来克服逻辑回归模型中的过度拟合。
*   许多优化算法可用于提高训练速度和鲁棒性。

## 非线性模型

接下来，我们将讨论一些众所周知的、实用的和最常用的非线性模型。

### 决策树

决策树又称为**分类回归树** ( **大车** ) ( *引用*【5】)。它们的表示是一个二进制树，通过在每个内部节点上根据单个属性评估一个不等式来构建，每个叶节点对应于由通向它的路径中的决策产生的输出值或类。当提供新的输入时，通过从根开始遍历树来预测输出。

#### 算法输入和输出

特征可以是分类的，也可以是数字的。它生成类作为输出，大多数实现使用基于频率的估计给出分数或概率。决策树概率不像朴素贝叶斯和逻辑回归那样是平滑的函数，尽管有这样的扩展。

#### 它是如何工作的？

通常，创建一个单独的树，从根处的单个特征开始，根据特征的值将决策分成多个分支，而在叶子处有一个类或多个特征。要做的选择有很多，比如有多少棵树，如何在根级或者后续的叶级选择特征，以及不分类时如何拆分特征值。这导致了许多不同的算法或对基本决策树的修改。许多分割特征值的技术与离散化章节中讨论的类似。通常，应用某种形式的修剪来减小树的大小，这有助于解决过度拟合问题。

基尼指数是另一种用于分割特征的流行技术。集合 *S* 中所有数据点的基尼指数为![How does it work?](graphics/B05137_02_106.jpg)，其中*p*1，*p*2…*p*k 为每一类的概率分布。

如果 *p* 是集合 *S* 中属于所述类正的所有数据点的数据的分数或概率，则 1–*p*是另一类的分数或二进制分类中的错误率。如果将数据集 *S* 拆分成 *r* 路 *S* [1] *，S* [2] *，…S* [r] 那么每组的错误率可以量化为| *S* [i] |。一种 *r* 方式分割的基尼指数如下:

![How does it work?](graphics/B05137_02_113.jpg)

基尼系数最低的部分用于选择。CART 算法是一种流行的决策树算法，它使用基尼指数作为划分标准。

数据点组 *S* 的熵可以类似地计算为:

![How does it work?](graphics/B05137_02_114.jpg)

类似地，基于熵的分割计算如下:

![How does it work?](graphics/B05137_02_115.jpg)

熵分裂的值越低，特征越好，这在 ID3 和 C4.5 决策树算法中使用(*参考文献* [12])。

停止标准和修剪标准是相关的。早期停止树的生长或修剪的想法是为了减少“过度拟合”,它类似于线性和逻辑模型中的正则化。通常，训练集被分成树生长集和剪枝集，以便剪枝使用不同的数据来克服来自生长集的任何偏差。**最小描述长度** ( **MDL** )，它根据节点的数量来惩罚树的复杂性，是许多决策树算法中使用的流行方法。

![How does it work?](graphics/B05137_02_116.jpg)

图 5:示出了二维二进制分类问题和分别在阈值 *X* [1t] 和 *X* [1t] 使用分裂导出的决策树

#### 优点和局限性

*   决策树的主要优势是它们非常容易解释。它们可以用外行人的术语来理解，并且特别适合业务领域专家容易理解的精确模型。
*   如果有大量的特征，那么随着算法复杂性的增加，构建决策树会花费大量的训练时间。
*   决策树存在过度拟合的固有问题。许多树算法都有修剪选项来减少这种影响。使用剪枝和验证技术可以在很大程度上缓解这个问题。
*   当特征之间存在相关性时，决策树工作得很好。
*   决策树建立跨类的轴平行边界，其偏差会引入错误，尤其是在复杂、平滑、非线性的边界中。

### K-最近邻(KNN)

K-Nearest Neighbors 属于非参数和懒惰算法的分支。k-最近邻不会对底层数据做出任何假设，也不会从训练数据中构建和归纳模型(*参考文献* [10】)。

#### 算法输入和输出

虽然 KNN 可以处理分类和数字特征，但是距离计算(查找邻居的核心)更适合处理数字特征。将相同范围内的数字要素归一化是必需的强制步骤之一。KNN 的输出通常是基于邻居距离计算的类。

#### 它是如何工作的？

KNN 利用全部训练数据对看不见的测试数据进行预测。当看不见的测试数据出现时，KNN 使用一些距离计算找到 K 个“最近的邻居”,并基于邻居和决定类别的度量对新点进行分类。如果我们考虑由对应于两个数据点的**x**1 和**x**2 表示的两个向量，则距离计算如下:

*   欧几里德距离:![How does it work?](graphics/B05137_02_121.jpg)
*   余弦距离或相似度:![How does it work?](graphics/B05137_02_122.jpg)

用于对未知进行分类的度量可以简单地是 *K* 个邻居中的多数类。

训练时间很短，因为它所要做的只是构建数据结构来保存数据，以便在出现看不见的数据时最小化最近邻的计算。该算法依赖于选择如何存储来自训练数据点的数据以提高搜索邻居的效率、使用哪种距离计算来查找最近的邻居以及使用哪种度量来基于所有邻居的类别进行分类。由使用验证技术选择 KNN 中的 *K* 的值是至关重要的。

![How does it work?](graphics/B05137_02_123.jpg)

图 6:使用不同 K 选择的二维数据说明 K-最近邻。

#### 优点和局限性

*   没有对基础数据分布的假设和最少的训练时间使它成为一种非常有吸引力的学习方法。
*   KNN 使用本地信息来计算距离，在某些领域可以产生高度适应的行为。
*   当有效地选择 *K* 时，它对有噪声的训练数据是鲁棒的。
*   根据数据点的数量和硬件限制，保存用于分类的整个训练数据可能是有问题的
*   特征的数量和维数灾难对该算法的影响更大，因此在 KNN 建模之前必须进行某种形式的维数缩减或特征选择。

### 支持向量机(SVM)

简单地说，支持向量机可以被视为线性分类器，通过解决一个受约束的优化问题来最大化分离超平面和数据之间的间隔。SVMs 甚至可以通过使用稍后描述的内核调用到更高维空间的变换来处理不可线性分离的数据。

#### 算法输入和输出

SVM 只对数字特征有效，尽管大多数实现可以处理转换成数字或二进制的分类特征。标准化通常是一种选择，因为它有助于训练的优化部分。SVM 的输出是类预测。存在给出概率估计作为置信度的实现，但是这需要相当多的训练时间，因为它们使用 k 倍交叉验证来构建估计。

#### 它是如何工作的？

在其线性形式中，SVM 的工作类似于线性回归分类器，其中在两个类之间绘制线性决策边界。两者之间的区别在于，使用 SVM 时，边界是以这样一种方式绘制的，即边界附近的点之间的“边距”或距离是最大的。边界上的点被称为“支持向量”(*参考*【13 和 8】)。

因此，SVM 试图在类似于线性回归模型的线性模型中找到权重向量，如下式所示:

![How does it work?](graphics/B05137_02_124.jpg)

重量 *w* [0] 在这里用 *b* 表示。二元类 y ∈{1，-1}的 SVM 试图找到一个超平面:

![How does it work?](graphics/B05137_02_127.jpg)

超平面试图分离数据点，使得具有该类的所有点都位于超平面的边上，如下所示:

![How does it work?](graphics/B05137_02_128.jpg)![How does it work?](graphics/B05137_02_129.jpg)

使用基于约束的优化使模型的裕度最大化，该优化具有由 *C* 表示的惩罚函数，用于克服由![How does it work?](graphics/B05137_02_131.jpg)表示的误差:

![How does it work?](graphics/B05137_02_132.jpg)

使得![How does it work?](graphics/B05137_02_133.jpg)和![How does it work?](graphics/B05137_02_134.jpg)。

由于上述原因，它们也被称为大间隔分类器。基于核的 SVM 将输入数据转换到假设的特征空间，其中 SV 机器以线性方式工作，并且在特征空间中绘制边界。

变换表示上的核函数由下式给出:

![How does it work?](graphics/B05137_02_135.jpg)

这里φ是输入空间上的变换。可以看出，SVM 的整个优化和解决方案保持不变，唯一的例外是点积**x**[I]**x**[j]被核函数 *k* ( **x** [i] ， **x** [j] 代替，这是一个涉及不同空间中的两个向量而没有实际变换到那个空间的函数。这就是所谓的**内核技巧**。

通常使用的最广为人知的内核是:

*   **高斯径向基核** :![How does it work?](graphics/B05137_02_139.jpg)
*   **多项式内核** :![How does it work?](graphics/B05137_02_140.jpg)
*   **乙状结肠仁** :![How does it work?](graphics/B05137_02_141.jpg)

SVM 的性能对优化的一些参数以及内核参数和核心 SV 参数如代价函数 *C* 非常敏感。诸如网格搜索或进化搜索之类的搜索技术与诸如交叉验证之类的验证技术相结合，通常用于找到最佳参数值。

![How does it work?](graphics/B05137_02_142.jpg)

图 7:从训练数据中学习的 SVM 线性超平面，其在两个类之间产生最大的间距。

![How does it work?](graphics/B05137_02_144.jpg)

图 8:内核变换，说明如何使用多项式变换将二维输入空间变换为数据可线性分离的三维特征空间。

#### 优点和局限性

*   如果参数选择得当，支持向量机在泛化能力、低过拟合方面是最好的，并且对于复杂的非线性数据具有良好的理论基础。
*   即使有大量的特征和较少的训练数据，支持向量机也能很好地工作。
*   支持向量机对噪声训练数据不太敏感。
*   支持向量机最大的缺点是它们不可解释。
*   SVM 的另一个大问题是它的训练时间和记忆要求。它们是 *O(n* ² *)* 和 *O(n* ³ *)* ，当数据量较大或存在硬件限制时，会导致重大的可伸缩性问题。有一些修改有助于减少这两者。
*   SVM 通常对二分类问题工作良好，但是对于多类分类问题，尽管有诸如一对多和一对所有的技术，但是它不如诸如决策树的一些其他分类器那样健壮。

## 集成学习和元学习者

结合多种算法或模型进行分类，而不是仅仅依靠一种算法或模型进行分类，这被称为集成学习。它有助于组合各种模型，因为每个模型都可以被视为——在高层次上——在整个数据集中检测特定模式的专家。每个基础学习者也可以在稍微不同的数据集上学习。最后，将所有模型的结果结合起来进行预测。基于组合中使用的算法的相似程度，训练数据集如何呈现给每个算法，以及算法如何组合结果以最终对未知数据集进行分类，集成学习有许多分支:

![Ensemble learning and meta learners](graphics/B05137_02_145.jpg)

图 9:集成学习策略的图示

一些常见的集成学习类型有:

*   不同的学习算法
*   相同的学习算法，但参数选择不同
*   不同特征集上的不同学习算法
*   不同训练数据的不同学习算法

### 引导聚集或装袋

这是最常用的集成方法之一,用于划分不同样本中的数据，并在每个样本上建立分类器。

#### 算法输入和输出

输入受到所使用的基础学习者的选择的限制——如果使用决策树，基本上没有限制。该方法输出类成员资格以及类的概率分布。

#### 它是如何工作的？

bagging 的核心思想是将 bootstrapping 估计应用于具有高方差的不同学习者，如决策树。Bootstrapping 是任何依赖于随机抽样替换的统计方法。使用引导将整个数据分成不同的样本，并且对于每个样本，使用基础学习器来构建模型。最后，在预测时，平均预测是使用多数投票得出的——这是一种结合所有学习者的技术。

##### 随机森林

随机森林是对基本袋装决策树的改进。即使有了 bagging，基本决策树在创建树的每个分割点都有一个所有特征的选择。正因为如此，即使是不同的样本，很多树也会形成高度相关的子模型，导致套袋的性能变差。除了随机数据集之外，通过为不同的模型提供随机特征，子模型之间的相关性降低，并且随机森林显示出比基本袋装树好得多的性能。随机森林中的每棵树在随机特征上生长其结构，从而最小化偏差；在决策时组合许多这样的树减少了方差(*参考文献*【15】)。随机森林也用于测量特征相关性，方法是对树中的杂质减少进行平均，并对所有特征进行排序，以给出每个特征的相对重要性。

#### 优点和局限性

*   比单一基础学习者更好的概括。克服基础学习者过度适应的问题。
*   bagging 的可解释性非常低，因为它作为元学习者工作，甚至结合了可解释的学习者。
*   像大多数其他集成学习者一样，Bagging 对噪声和离群值具有弹性。
*   给定训练数据为 iid，随机森林通常不会过度拟合。

### 助推

Boosting 是集成学习的另一种流行形式，基于使用弱学习器，迭代学习“错误分类”或难以学习的点。因此，这种想法是“提升”难以学习的实例，并使基础学习者更有效地学习决策边界。有各种各样的增强方式，如 AdaBoost、LogitBoost、ConfidenceBoost、梯度增强等等。我们在这里提出了 AdaBoost 的一个非常基本的形式(*参考文献*【14】)。

#### 算法输入和输出

输入受到所使用的基础学习者的限制——如果使用决策树，基本上没有限制。输出类别成员资格以及类别的概率分布。

#### 它是如何工作的？

boosting 背后的基本思想是对输入样本进行迭代重新加权，以创建新的数据分布，从而在每次迭代中从简单的基础学习者那里学习模型。

最初，用权重![How does it work?](graphics/B05137_02_146.jpg)对所有实例进行统一加权，并且在每次迭代 *t* 时，对群体进行重新采样或重新加权为![How does it work?](graphics/B05137_02_148.jpg)，其中![How does it work?](graphics/B05137_02_149.jpg)和 *Z* t 是归一化常数。

最终模型是迭代中学习到的所有模型的线性组合:

![How does it work?](graphics/B05137_02_151.jpg)

每次迭代中数据的重新加权或重新采样基于“误差”；导致误差的数据点被更多地采样或具有更大的权重。

#### 优点和局限性

*   比基础学习者更好的泛化能力，非常有效地克服了过度拟合的问题。
*   AdaBoost 等一些升压算法容易受到均匀噪声的影响。有一些增强的变体，如“GentleBoost”和“BrownBoost ”,可以降低异常值的影响。
*   Boosting 在误差估计上有理论界限和保证，使其成为统计上鲁棒的算法。



# 模型评估、评价和比较

这里讨论的主要观点是:

*   如何评估或估计分类器在未知数据集上的性能，它将在未来未知数据集上进行预测。
*   我们应该使用哪些指标来评估模型的性能？
*   如果必须在算法之间做出选择，我们如何比较算法？

## 模型评估

为了训练模型、调整模型参数、选择模型并最终评估模型对未知数据的预测行为，我们需要许多数据集。我们不能在一组数据上训练模型，并在同一组数据上估计其行为，因为它将具有明显的乐观偏差，并且估计不太可能与看不见的数据中的行为相匹配。因此，至少需要将可用数据划分为训练集和测试集。此外，在对测试集执行测试之前，我们需要调整模型的参数，并测试调整对单独数据集的影响。如果我们使用相同的数据集进行训练、参数调整和测试，乐观偏差和错误估计的相同论点也适用。因此，理论上和实践上都需要三个数据集，即训练、验证和测试。

在训练集上对模型进行训练，在验证集上验证不同参数对训练集的影响，并在测试集上运行具有所选参数的最终模型，以评估模型对未来未知数据的性能。当数据集不够大，或者很大但类之间的不平衡很大时，也就是说，一个类只存在于总人口的一小部分中，我们不能创建太多的样本。回想一下，我们的方法中描述的步骤之一是创建不同的数据样本和数据集。如果总的训练数据很大，并且具有很好的数据比例和类比率，那么使用随机分层划分来创建这三个集合是最常用的选择。在某些表现出季节性和时间相关行为的数据集中，基于时间界限创建数据集是一种常见的做法。在许多情况下，当数据集不够大时，可能只创建两个物理分区，即训练和测试分区。训练数据集的范围大致在 66%到 80%之间，而其余部分用于测试。然后，使用 k 倍交叉验证技术从训练数据集创建验证集。训练数据集被拆分 *k* 次，每次产生 *k-1/k* 个随机训练 *1/k* 个测试数据样本，生成所需性能的平均度量。这样，有限的训练数据被分割 *k* 次，并且训练/测试的不同分割的平均性能被用于测量参数的效果。使用 10 重交叉验证是交叉验证中最常见的做法。

## 模型评估指标

调整参数或选择模型时的下一个重要决策是根据某些性能指标做出决策。在分类学习中，根据业务需求，您可以根据不同的指标做出决策。例如，在某些领域，不遗漏单个真阳性是最重要的关注点，而在人类参与评判模型结果的其他领域，有太多的假阳性是更大的关注点。在某些情况下，拥有总体良好的准确性被认为是更重要的。在高度不平衡的数据集中，如欺诈或网络攻击，一个类只有少数实例，而其他类有数百万个实例。在这种情况下，精确度给出了模型性能的错误指示，一些其他指标，如精确度、真阳性比率或曲线下的面积被用作指标。

我们现在将讨论分类算法评估中最常用的指标(*参考文献*【16、17 和 19】)。

![Model evaluation metrics](graphics/B05137_02_152.jpg)

图 10:分类模型的模型评估度量

### 混淆矩阵和相关指标

![Confusion matrix and related metrics](graphics/B05137_02_153.jpg)

图 11:混淆矩阵

混淆矩阵是定义个模型性能指标的核心。度量和同义术语的扩散是不同学科中矩阵元素的不同数量的效用的结果，每个强调模型行为的不同方面。

矩阵的四个元素是假阳性、假阴性、真阳性和真阴性的原始计数。通常更有趣的是这些量的不同比率，真阳性率(或灵敏度，或回忆)，和假阳性率(FPR，或 1-特异性，或辐射)。准确性反映了正确预测的百分比，无论是第 1 类还是第 0 类。对于倾斜数据集，准确性不是特别有用，因为即使是常量预测也可能表现良好。

### ROC 和 PRC 曲线

前面提到的指标，如准确度、精确度、召回率、灵敏度和特异性都是集合，也就是说，它们描述了整个数据集的行为。在许多复杂问题中，看到 TPs 和 FPs 等指标之间的权衡通常是有价值的。

许多分类器，大多是基于概率的分类器，除了给出分类之外，还给出预测的置信度或概率。获得 ROC 或 PRC 曲线的过程是在学习的模型上运行看不见的验证或测试集，然后获得预测和预测的概率。根据置信度按降序对预测进行排序。对于每个概率或置信度，计算两个度量，FP 的分数(FP 率)和 TP 的分数(TP 率)。

将 TP 率绘制在 *y* 轴上，将 FP 率绘制在 *x* 轴上，得到 ROC 曲线。随机分类器的 ROC 曲线接近对角线，而好分类器的 ROC 曲线倾向于图的左上。曲线 ( **AUC** )下的**面积是利用 ROC 曲线从 0 到 1 的梯形面积在 ROC 曲线下测得的面积。例如，在运行交叉验证时，可能会有许多 ROC 曲线。有两种方法可以得到“平均”ROC 曲线:一是使用垂直平均法，即在不同 FP 率下绘制 TPR 平均值，二是使用水平平均法，即在不同 TP 率下绘制 FPR 平均值。根据经验，曲线下面积大于 0.8 的分类器被认为适合预测未知数据。**

精确度召回曲线或 PRC 曲线类似于 ROC 曲线，但不是 TPR 对 FPR，而是精确度和召回指标分别绘制在 *y* 和 *x* 轴上。当数据高度不平衡时，也就是说，ROC 曲线不能真正显示影响，而 PRC 曲线在判断绩效时更可靠。

### 增益图和升力曲线

升力和增益图更偏向于灵敏度或真阳性。这两个图表的全部目的是展示模型预测和置信度如何取代随机选择，在未知数据的样本中检测出更好的质量或真阳性。

这通常对用于检测金融犯罪欺诈或网络安全威胁的检测引擎非常有吸引力。增益图和提升曲线给出了将在总数据的不同四分位数或间隔检测到的真实真阳性的精确估计。这将为业务决策者提供关于需要多少调查人员或检测欺诈行为或网络攻击将花费多少时间的洞察力，从而可以提供模型的真实 ROI。

生成增益图或升力曲线的过程与通过模型运行看不见的验证或测试数据并获得预测以及置信度或概率的过程相似。它包括按降序排列概率，并保持数据集每个四分位数的 TPs 计数。最后，每四分位数计数的直方图给出了提升曲线，而四分位数上增加的 TPs 累积计数给出了增益图。在 RapidMiner 等许多工具中，使用固定的较大间隔(使用宁滨)来获取计数和累积计数，而不是四分位数等粗略间隔。

## 型号对比

当选择算法或给定算法的正确参数时，我们要么在不同的数据集上进行比较，要么在交叉验证的情况下，在同一数据集的不同分割上进行比较。在这些比较的决策中采用了统计检验的方法。使用经典统计学的假设检验的基本思想是比较来自算法的两个度量。零假设是基于度量的算法之间没有差异，因此进行测试以验证或拒绝基于度量的零假设(*参考文献*【16】)。统计测试回答的主要问题是——算法得到的结果或度量是其真实特征，还是偶然？

在本节中，我们将讨论比较实际场景中使用的分类算法的最常用方法。

### 比较两种算法

一般的流程是在相同的训练集上训练算法，并在多个验证集、不同的测试集或交叉验证上运行模型，测量之前讨论过的感兴趣的指标，如错误率或曲线下面积，然后获取每个算法的指标统计数据，以确定哪个效果更好。每种方法都有其优点和缺点。

#### 麦克内马试验

这个是非参数测试，因此它没有对数据和分布做出假设。McNemar 的测试建立了一个性能指标的列联表，如“错误分类或错误”,其中包括:

两种算法的错误分类计数(*c*00

*   被算法 *G1* 误分类计数，但被算法*G2*(*c*01 正确分类
*   被算法 *G2* 错误分类，但被算法*G1*(*c*10 正确分类的计数
*   *G1* 和*G2*(*c*[11])![McNemar's Test](graphics/B05137_02_162.jpg)正确分类的计数

如果χ ² 超过![McNemar's Test](graphics/B05137_02_164.jpg)统计量，那么我们可以拒绝零假设，即算法 *G1* 和 *G2* 的两个性能指标在 1–α的置信值下相等。

##### 成对 t 检验

这是一个参数测试，正态分布计算指标的假设变得有效。通常情况下，它与交叉验证过程和指标结果(如曲线下面积或精确度或误差率)相结合，然后计算平均值和标准偏差。除了正态分布假设之外，两个指标来自相同方差总体的额外假设可能是该方法的一大缺点。

![Paired-t test](graphics/B05137_02_166.jpg)

![Paired-t test](graphics/B05137_02_167.jpg)是两种算法 *G1* 和 *G2* 的性能指标的均值差异。

![Paired-t test](graphics/B05137_02_168.jpg)

这里， *d* i 是两个算法 *G1* 和 *G2* 在试验中的性能指标之差，有 *n* 次试验。

使用平均差异和标准偏差的标准误差计算出*t*-统计量,如下所示，并将其与右侧 alpha 值表进行比较，以检查显著性:

![Paired-t test](graphics/B05137_02_170.jpg)

#### Wilcoxon 符号秩检验

在数据集上测试两个指标的最流行的非参数方法是使用 Wilcoxon 符号秩测试。在相同的训练数据上训练算法，并且在不同的验证或测试集上计算诸如错误率或不准确区域之类的度量。设 *d* [i] 为两个分类器在*I*t^(th)试验中对于 *N* 数据集的性能度量之差。然后根据其绝对值对差异进行排名，并对平局进行平均排名。设*R*+为第二种算法优于第一种算法的等级之和，R^–为第一种算法优于第二种算法的等级之和:

![Wilcoxon signed-rank test](graphics/B05137_02_174.jpg)![Wilcoxon signed-rank test](graphics/B05137_02_175.jpg)

然后将统计量![Wilcoxon signed-rank test](graphics/B05137_02_176.jpg)与α的阈值![Wilcoxon signed-rank test](graphics/B05137_02_177.jpg)进行比较，以拒绝假设。

### 比较多种算法

我们现在将讨论当涉及两个以上的算法，并且我们需要对许多算法进行评估指标的比较时，最常用的两种技术。

#### 方差分析检验

这些是假设样本的正态分布的参数测试，也就是我们为评估而计算的指标。ANOVA 测试遵循与其他测试相同的过程，即在相似的训练集上训练模型/算法，并在不同的验证或测试集上运行它。ANOVA 中计算的主要数量是每个算法性能的度量平均值，然后计算所有算法的总体度量平均值。

设 *p* [ij] 为 *k* 试验和 *l* 分类器的 *i = 1，2… k* 和 *j = 1，2 …l* 的性能度量。分类器 *j* 在所有试验中的平均性能和总体平均性能为:

![ANOVA test](graphics/B05137_02_182.jpg)![ANOVA test](graphics/B05137_02_183.jpg)

评估两种类型的变化。第一个是组内变异，即每个算法与总体度量平均值的总偏差，第二个是组间变异，即每个算法度量平均值的偏差。组内变异和组间变异用于计算各自的组内和组间平方和，如下所示:

![ANOVA test](graphics/B05137_02_184.jpg)

使用两个平方和以及诸如 F-statistic(两者之比)的计算，可以在 alpha 值处进行显著性测试，以接受或拒绝零假设:

![ANOVA test](graphics/B05137_02_185.jpg)

方差分析检验与配对 t 检验在假设指标正态分布和假设方差相等方面具有相同的局限性。

#### 弗里德曼试验

Friedman 的测试是一种用于多种算法比较的非参数测试,它不像 ANOVA 那样假设数据分布或度量的方差。它使用排名而不是性能指标的直接进行计算。在每个数据集或试验中，对算法进行排序，最好的算法排名为 1，对所有分类器依此类推。计算一个算法在 *n* 个数据集上的平均排名，比如说*R*j。对 *l* 个分类器的弗里德曼统计量计算如下，并与阿尔法值进行比较，以接受或拒绝零假设:

![Friedman's test](graphics/B05137_02_187.jpg)<title>Case Study – Horse Colic Classification</title><link rel="stylesheet" href="epub.css" type="text/css">

# 案例研究——马绞痛分类

为了说明[第一章](ch01.html "Chapter 1. Machine Learning Review")、*机器学习综述*中描述的不同步骤和方法，从数据分析到模型评估，具有真实世界特征的代表性数据集是必不可少的。

我们已经从以下链接可获得的 UCI 库中选择了“马绞痛数据集:[https://archive.ics.uci.edu/ml/datasets/Horse+Colic](https://archive.ics.uci.edu/ml/datasets/Horse+Colic)

数据集有 23 个特征，并且很好地混合了分类特征和连续特征。它具有大量带有缺失值的特征和实例，因此理解如何替换这些缺失值并在建模中使用它在这种处理中变得更加实际。大量缺失数据(30%)实际上是该数据集的一个显著特征。数据由连续的属性以及名义类型的属性组成。此外，自我预测的存在使得从实践的角度来看，使用这个数据集是有益的。

这个练习的目标是应用到目前为止我们已经吸收的监督学习的技术。我们将使用一个真实的数据集和两个开源工具包——WEKA 和 rapid miner——来完成这项工作。在这些工具的帮助下，我们将构建一个管道，允许我们通过数据清理、学习过程和模型评估从数据文件的摄取开始。

Weka 是一个用于机器学习的 Java 框架——我们将看到如何使用这个框架在几行代码中从头到尾解决一个分类问题。除了 Java API，Weka 还有一个 GUI。

RapidMiner 是一个图形环境，具有拖放功能和一大套算法和可视化工具，使得使用数据和不同的建模技术快速运行实验变得极其容易。

## 商业问题

商业问题是确定数据集众所周知的变量的给定值——如果马的损伤是外科手术造成的。我们将使用测试集作为必须分类的看不见的数据。

## 机器学习映射

基于数据和标签，这是一个二元分类问题。数据已经分为训练数据和测试数据。这使得评估技术更简单，因为从特征选择到模型的所有方法都可以在相同的测试数据上进行评估。

该数据集包含 300 个训练和 68 个测试示例。有 28 个属性，目标对应于病变是否是外科的。

## 数据分析

在查看标签类别在训练和测试样本上的分布之后，我们在特征分析之前组合 300 个训练样本和 68 个测试样本。

### 标签分析

无类别与有类别的比率在训练集中是 109/191 = 0.57，在测试集中是 0.66:

| 

训练数据集

 |
| --- |
| 手术损伤？ | 1(是) | 2(否) |
| 示例数量 | One hundred and ninety-one | One hundred and nine |
| 测试数据集 |
| 手术损伤？ | 1(是) | 2(否) |
| 示例数量 | Forty-one | Twenty-seven |

> *表 2:标签分析*

#### 特性分析

下面的是主要特征的屏幕截图，包括按缺失值排序的类型、缺失值、最小值、最大值、模式和标准偏差的基本统计数据。观察结果如下:

*   不存在具有非缺失值的分类或连续特征；最少的是 368 个中有 74 个缺失的特征“脉冲”，即 20%的值缺失，高于一般的噪声阈值！
*   大多数数字特征都有缺失值，例如，“鼻饲反流 PH”的 368 个值中有 247 个缺失，即 67%的值缺失！
*   许多分类特征都有缺失值，例如，“abidominocentesis appearance”有 368 个缺失值中的 165 个，即 45%的值缺失！
*   缺失值必须以某种方式处理，以克服如此大的数字所产生的噪音！![Features analysis](graphics/B05137_02_188.jpg)图 12:数据集中要素的基本统计数据.

## 监督学习实验

在本节的中，我们将介绍使用两种不同工具的监督学习实验——在一个工具中强调编码和分析，在另一个工具中强调 GUI 框架。这给了开发人员探索他们最喜欢的路线的机会。

### Weka 实验

在本节的中，我们已经向提供了完整的代码，并将介绍从加载数据、转换数据、选择特性、构建样本模型、根据测试数据对其进行评估，甚至比较算法的统计显著性的整个过程。

#### Java 端到端流程示例

在每个算法中，使用相同的训练/测试数据，并对所有指标进行评估，如下所示。训练和测试文件按如下方式加载到内存中:

```
DataSource source = new DataSource(trainingFile);
Instances data = source.getDataSet();
if (data.classIndex() == -1)
  data.setClassIndex(data.numAttributes() - 1);
```

这里显示了使用 WEKA 的通用代码，其中每个分类器都由一个过滤的分类器包装，用于替换丢失的值:

```
//replacing the nominal and numeric with modes and means
Filter missingValuesFilter= new ReplaceMissingValues();
//create a filtered classifier to use filter and classifier
FilteredClassifier filteredClassifier = new FilteredClassifier();
filteredClassifier.setFilter(f);
// create a bayesian classifier
NaiveBayes naiveBayes = new NaiveBayes();
// use supervised discretization
naiveBayes.setUseSupervisedDiscretization(true);
//set the base classifier e.g naïvebayes, linear //regression etc.
fc.setClassifier(filteredClassifier)
```

当分类器需要执行特征选择时，在 Weka 中，`AttributeSelectedClassifier`进一步包装`FilteredClassifier`,如下所示:

```
AttributeSelectedClassifier attributeSelectionClassifier = new AttributeSelectedClassifier();
//wrap the classifier
attributeSelectionClassifier.setClassifier(filteredClassifier);
//univariate information gain based feature evaluation
    InfoGainAttributeEval evaluator = new InfoGainAttributeEval();
//rank the features
Ranker ranker = new Ranker();
//set the threshold to be 0, less than that is rejected
ranker.setThreshold(0.0);
attributeSelectionClassifier.setEvaluator(evaluator);
attributeSelectionClassifier.setSearch(ranker);
//build on training data
attributeSelectionClassifier.buildClassifier(trainingData);
// evaluate classifier giving same training data
Evaluation eval = new Evaluation(trainingData);
//evaluate the model on test data
eval.evaluateModel(attributeSelectionClassifier,testingData);
```

这里给出了评估的样本输出:

```
=== Summary ===

Correctly Classified Instances     53       77.9412 %
Incorrectly Classified Instances    15       22.0588 %
Kappa statistic             0.5115
Mean absolute error           0.3422
Root mean squared error         0.413
Relative absolute error        72.4875 %
Root relative squared error      84.2167 %
Total Number of Instances       68 

=== Detailed Accuracy By Class ===

 TP Rate FP Rate Precision Recall F-Measure MCC   ROC Area PRC Area Class
 0.927  0.444  0.760   0.927  0.835   0.535  0.823  0.875  1
 0.556  0.073  0.833   0.556  0.667   0.535  0.823  0.714  2
Weighted Avg.  0.779  0.297  0.789   0.779  0.768   0.535  0.823  0.812 

=== Confusion Matrix ===

 a b <-- classified as
 38 3 | a = 1
 12 15 | b = 2

```

#### Weka 实验者和模型选择

正如在*模型评估指标*部分中所解释的，为了选择模型，我们需要验证哪一个将在看不见的数据集上工作良好。交叉验证必须在训练集上完成，选择的性能指标需要使用标准统计测试指标进行分析。这里，我们展示了一个使用相同训练数据的示例，10 重交叉验证，对两个模型执行 30 次实验，并使用配对 t 检验比较结果。

一种是使用朴素贝叶斯进行预处理，包括替换缺失值和通过移除任何得分低于 0.0 的特征来执行特征选择。

另一个使用相同的预处理和 AdaBoostM1 和朴素贝叶斯。

![Weka experimenter and model selection](graphics/B05137_02_189.jpg)

图 13: WEKA 实验人员展示了使用两种算法重复 30 次交叉验证运行的过程。

![Weka experimenter and model selection](graphics/B05137_02_190.jpg)

图 14: WEKA 实验者的结果，显示了使用配对 t 检验比较两种算法的正确率或准确度。

### RapidMiner 实验

现在让我们使用 RapidMiner 中的马疝气数据集进行一些实验。我们将再次遵循本章第一部分提出的方法。

### 注意

本节不是 RapidMiner 工具的教程。实验者应该阅读优秀的文档和用户指南，以熟悉该工具的使用。软件中有专门针对每个操作员的教程，我们建议您在想要了解如何使用特定操作员时使用这些教程。

一旦我们使用数据访问工具导入了测试和训练数据文件，我们将希望直观地探索数据集，以熟悉情况。特别重要的是识别 28 个属性中的每一个是连续的(RapidMiner 中的数值、整数或实数)还是分类的(RapidMiner 中的名义、二项式或多项式)。

#### 可视化分析

从工具的**结果**面板，我们执行数据的单变量、双变量和多变量分析。统计工具给出了每个特征的简短摘要，包括连续类型的最小值、最大值、平均值和标准差，以及标称类型的最小、最大值和频率。

当我们进行双变量分析时，数据的有趣特征开始显现出来。在四分位数颜色矩阵中，颜色代表两个可能的目标值。正如在方框图中看到的，我们立即注意到一些属性比其他属性更清楚地区分了两个目标值。让我们检查几个:

![Visualization analysis](graphics/B05137_02_191.jpg)

图 15:四分位数颜色矩阵

蠕动:该特征显示了按目标值分开时分布的显著差异。两者之间的四分位数区域几乎没有重叠。这表明了该特征相对于目标的辨别能力。

另一方面，直肠温度的曲线显示分布中没有可察觉的差异。这表明该特征与目标的相关性低。从特征脉冲中可以得出类似的推论。当我们评估这些特征相对于目标的辨别能力时，我们期望这些特征排名相当低。

最后，痛苦的情节有一个非常不同的特点。它也能识别目标，但方式与蠕动截然不同。就疼痛而言，类别 2 的数据差异比类别 1 大得多。除了第 2 组与第 1 组相比差异较大之外，不同组间的腹胀差异也明显不同。

![Visualization analysis](graphics/B05137_02_192.jpg)

图 16:散点图矩阵

探索数据的一个重要部分是理解不同的属性如何相互关联以及如何与目标关联。这里我们考虑成对的特征，看看值*在组合*中的出现是否能告诉我们一些关于目标的信息。在这些图中，数据点的颜色是目标。

![Visualization analysis](graphics/B05137_02_193.jpg)

图 17:气泡图

在气泡图中，我们可以通过使用绘图工具指定 *x* 和 *y* 轴以及表示为代表特性的气泡大小的第三维度，来一次可视化四个特性。目标类由颜色表示。

在总蛋白的低端，我们在直肠温度值的中间范围内看到较高的 pH 值。在这一组中，高 pH 值似乎显示出与外科手术损伤更强的相关性。对于总蛋白大于 50 的值，还发现了总蛋白差异更大的另一个聚类。在这个集群中，pH 值的变化也很小。

#### 功能选择

对数据有了一些了解后，我们准备使用理论中的一些技术来评估特征相关性。

这里我们使用两种技术:一种是基于目标属性的卡方统计计算特征的权重，另一种是基于基尼系数。结果如表所示。请注意，正如我们在通过可视化进行特征分析时所推断的，脉搏和直肠温度都被证明具有低相关性，如两种技术所示。

| 

卡方检验

 | 

基尼指数

 |
| --- | --- |
| 

属性

 | 

重量

 | 

属性

 | 

重量

 |
| --- | --- | --- | --- |
| 疼痛 | 54.20626 | 疼痛 | 0.083594 |
| 腹部 | 53.93882 | 腹部 | 0.083182 |
| 蠕动 | 38.73474 | 蠕动 | 0.059735 |
| 腹部扩张 | 35.11441 | 腹部扩张 | 0.054152 |
| 外围脉冲 | 23.65301 | 外围脉冲 | 0.036476 |
| 腹腔穿刺外观 | 20.00392 | 腹腔穿刺外观 | 0.030849 |
| 温度极端值 | 17.07852 | 温度极端值 | 0.026338 |
| 粘膜 | 15.0938 | 粘膜 | 0.023277 |
| 鼻饲回流 | 14.95926 | 鼻饲回流 | 0.023069 |
| PackedCellVolume | 13.5733 | PackedCellVolume | 0.020932 |
| 直肠粘膜检查-粪便 | 11.88078 | 直肠粘膜检查-粪便 | 0.018322 |
| 毛细血管再充盈时间 | 8.078319 | 毛细血管再充盈时间 | 0.012458 |
| 呼吸速率 | 7.616813 | 呼吸速率 | 0.011746 |
| 总蛋白质 | 5.616841 | 总蛋白质 | 0.008662 |
| 鼻饲回流 | 2.047565 | 鼻饲回流 | 0.003158 |
| 脉搏 | 1.931511 | 脉搏 | 0.002979 |
| 年龄 | 0.579216 | 年龄 | 8.93E-04 |
| 鼻胃管 | 0.237519 |   |   |
| 腹腔中心总蛋白 | 0.181868 |   |   |
| 直肠温度 | 0.139387 |   |   |

> *表 3:通过卡方检验和基尼指数这两种不同技术确定的相关特征。*

#### 模型流程

在 RapidMiner 中，您可以使用输入和输出可以链接在一起的操作符来定义计算管道。以下过程表示用于执行整组操作的流程，从加载训练和测试数据开始，处理缺失值，通过相关性对特征进行加权，过滤出低得分特征，训练使用随机森林装袋作为算法的集成模型，最后将学习到的模型应用于测试数据并输出性能指标。请注意，应用于训练数据集的所有预处理步骤也必须通过组模型操作符以相同的顺序应用于测试集:

![Model process flow](graphics/B05137_02_194.jpg)

图 18: RapidMiner 流程图

在该过程的顶部之后，在最左侧的操作者中摄取训练集，随后排除非预测因素(医院编号、CP 数据)和自我预测因素(病变 1)。接下来是运算符，分别用连续属性和分类属性的平均值和众数替换缺失值。接下来，Feature Weights 操作符基于卡方统计评估每个特征的权重，然后是忽略低权重特征的过滤器。然后，使用随机森林分类器，使用 Bagging 将该预处理数据集用于训练模型。

通过 Group Models 操作符，对训练数据使用的预处理步骤按适当的顺序组合在一起，并在倒数第二个步骤中应用于测试数据。最后，在最后一步中，评估并呈现伴随混淆矩阵和其他性能度量的测试实例上的目标变量的预测。

#### 模型评估指标

我们现在准备比较各种模型的结果。如果你一直坚持下去，你可能会发现你的结果与这里呈现的不同——这可能是由于一些学习算法的随机性质，或者模型中使用的一些超参数值的差异。

我们考虑了三种不同的训练数据集:

*   缺少值的原始训练数据
*   处理缺失值后转换的训练数据
*   处理缺失值并应用特征选择(卡方检验)以选择高区分度特征的训练数据。

我们在每个数据集上考虑了三组不同的算法:

*   线性算法(朴素贝叶斯和逻辑回归)
*   非线性算法(决策树和 KNN)
*   集成算法(Bagging、Ada Boost 和随机森林)。

##### 混淆度量的评估

| 

模型

 | 

pulse

 | 

定期用量法(Fixed Period Requirements)

 | 

精确

 | 

特征

 | 

准确(性)

 | 

罗马纪元

 |
| --- | --- | --- | --- | --- | --- | --- |
| 朴素贝叶斯 | 68.29% | 14.81% | 87.50% | 85.19% | 75.00% | Zero point eight three six |
| 逻辑回归 | 78.05% | 14.81% | 88.89% | 85.19% | 80.88% | Zero point eight five six |
| 决策图表 | 68.29% | 33.33% | 75.68% | 66.67% | 67.65% | Zero point six nine six |
| k-神经网络 | 90.24% | 85.19% | 61.67% | 14.81% | 60.29% | Zero point five five six |
| 装袋(GBT) | 90.24% | 74.07% | 64.91% | 25.93% | 64.71% | Zero point seven three seven |
| Ada Boost(朴素贝叶斯) | 63.41% | 48.15% | 66.67% | 51.85% | 58.82% | Zero point six one three |

> *表 4:根据缺失值的马结肠数据训练的模型的不可见(测试)数据的结果*

| 

模型

 | 

pulse

 | 

定期用量法(Fixed Period Requirements)

 | 

精确

 | 

特征

 | 

准确(性)

 | 

罗马纪元

 |
| --- | --- | --- | --- | --- | --- | --- |
| 朴素贝叶斯 | 68.29% | 66.67% | 60.87% | 33.33% | 54.41% | Zero point five five nine |
| 逻辑回归 | 78.05% | 62.96% | 65.31% | 37.04% | 61.76% | Zero point six eight nine |
| 决策图表 | 97.56% | 96.30% | 60.61% | 3.70% | 60.29% | Zero point eight one two |
| k-神经网络 | 75.61% | 48.15% | 70.45% | 51.85% | 66.18% | Zero point six four eight |
| 装袋(随机森林) | 97.56% | 74.07% | 66.67% | 25.93% | 69.12% | Zero point eight nine two |
| 装袋(GBT) | 82.93% | 18.52% | 87.18% | 81.48% | 82.35% | Zero point eight seven |
| Ada Boost(朴素贝叶斯) | 68.29% | 7.41% | 93.33% | 92.59% | 77.94% | Zero point eight nine five |

> *表 5:根据马结肠数据训练的模型的不可见(测试)数据的结果，其中缺失值被替换*

| 

模型

 | 

pulse

 | 

定期用量法(Fixed Period Requirements)

 | 

精确

 | 

特征

 | 

准确(性)

 | 

罗马纪元

 |
| --- | --- | --- | --- | --- | --- | --- |
| 朴素贝叶斯 | 75.61% | 77.78% | 59.62% | 29.63% | 54.41% | Zero point five five one |
| 逻辑回归 | 82.93% | 62.96% | 66.67% | 37.04% | 64.71% | Zero point six nine two |
| 决策图表 | 95.12% | 92.59% | 60.94% | 7.41% | 60.29% | Zero point eight two four |
| k-神经网络 | 75.61% | 48.15% | 70.45% | 51.85% | 66.18% | Zero point six six nine |
| 装袋(随机森林) | 92.68% | 33.33% | 80.85% | 66.67% | 82.35% | Zero point nine one five |
| 装袋(GBT) | 78.05% | 22.22% | 84.21% | 77.78% | 77.94% | Zero point eight seven two |
| Ada Boost(朴素贝叶斯) | 68.29% | 18.52% | 84.85% | 81.48% | 73.53% | Zero point eight four eight |

> *表 6:使用卡方统计技术选择的特征对马结肠数据进行训练的模型的看不见的(测试)数据的结果*

###### ROC 曲线、升力曲线和增益图

性能图使我们能够直观地评估在三个实验中的两个实验中使用的模型——没有任何缺失数据替换，并且在替换缺失数据后使用卡方加权的特征——并将它们相互比较。成对的图显示了我们在本章前面了解的每种线性(逻辑回归)、非线性(决策树)和集成(Bagging，使用梯度推进树)技术的性能曲线，这些曲线来自两个实验的结果。

![ROC Curves, Lift Curves, and Gain Charts](graphics/B05137_02_195.jpg)

图 19:使用缺失数据的实验的 ROC 性能曲线

![ROC Curves, Lift Curves, and Gain Charts](graphics/B05137_02_196.jpg)

图 20:使用缺失数据的实验累积增益性能曲线

![ROC Curves, Lift Curves, and Gain Charts](graphics/B05137_02_197.jpg)

图 21:使用缺失数据的试验的举升性能曲线

## 结果、观察和分析

处理缺失值的影响是巨大的。在七个分类器中，除了朴素贝叶斯和逻辑回归，当缺失值按照各种指标(包括 AUC、精度、准确度和特异性)的指示进行处理时，所有分类器都显示出显著的改进。这告诉我们，处理可能“有噪声”的缺失值是数据转换的一个重要方面。朴素贝叶斯有它自己管理缺失值的内部方法，我们的实验结果表明，它在空值处理方面比我们的外部转换做得更好。但是一般来说，当您考虑所有分类器时，转换缺失值的想法似乎是有益的。

正如建模一节中所讨论的，一些算法需要正确处理缺失值和特征选择，以获得最佳性能。从结果中，我们可以看到，例如，决策树的性能从缺失数据时的 0.696、管理缺失数据时的 0.812 以及缺失数据与特征选择一起处理时的最佳性能 0.824 逐渐提高。当执行这两个步骤时，七个分类器中的六个提高了 AUC(和其他度量)的性能；比较 AUC 的*表 5* 和*表 6* 可以让我们快速了解这些情况。这证明了在执行建模之前进行预处理(如缺失值处理和特征选择)的重要性。

从结果得出的主要结论是，该问题是高度非线性的，因此从最简单的决策树到集成随机森林的大多数非线性分类器表现非常好。最佳性能来自元学习算法随机森林，丢失的值得到适当处理，最相关的特征用于训练。通过 AUC 测量的最佳线性模型性能是 0.856，用于具有数据原样(即，具有缺失值)的逻辑回归，而随机森林通过伴随特征选择的缺失数据的适当处理实现了 0.915 的 AUC 性能。一般来说，从*表 3* 中可以明显看出，非线性分类器或元学习器在大多数性能指标上比线性分类器表现得更好。

以适当的方式处理丢失的值可以被认为是“噪声”,从而显著提高 AdaBoost 的性能。AUC 从 0.613 提高到 0.895，FPR 从 48.15 降低到 7.41%。这确实符合该技术的预期理论行为。

与其他常见技术相比，元学习技术使用 boosting 和 bagging 的概念，在处理真实世界的数据时相对更有效。结果似乎证明了这一点，因为 AdaBoost 使用朴素贝叶斯作为基础学习器，对经过适当噪声处理的数据进行训练，在大部分指标中表现优于朴素贝叶斯，如*表 5* 和*表 6* 所示。在*表 6* 中，与基本分类器相比，随机森林和 GBTs 以及 AdaBoost 也表现出最佳性能，再次证实了正确的过程和集成学习可以在真实世界的噪声数据集中产生最佳结果。

### 注意

本章中 WEKA 和 RapidMiner 过程文件的所有数据、模型和结果可在以下位置获得:[https://github . com/mjmlbook/mastering-Java-machine-learning/tree/master/chapter 2](https://github.com/mjmlbook/mastering-java-machine-learning/tree/master/Chapter2)。



# 总结

监督学习是机器学习应用中使用的主要技术。该方法由一系列步骤组成，从数据探索、数据转换和数据采样开始，经过特征缩减、模型构建，最后是模型评估和比较。这个过程的每一步都涉及到一些必须回答关键问题的决策:我们应该如何估算缺失值？我们应该使用什么样的数据采样策略？给定数据集中的噪声量和规定的可解释性目标，最合适的算法是什么？本章演示了这些过程和技术在现实世界问题中的应用——使用 UCI 马结肠数据集的分类问题。

无论问题是分类(当目标是分类值时)还是回归(当目标是实值连续变量时)，用于监督学习的方法都是相似的。在这一章中，我们用分类来说明。

第一步是数据质量分析，包括特征的描述性统计、使用单变量的可视化分析和多变量特征分析。在各种绘图类型的帮助下，我们可以发现数据中的不同趋势，并检查某些要素可能与标注值相关，也可能不相关。数据分析之后是数据预处理，其中的技术包括处理噪声的方法，如在缺失数据和异常值的情况下，以及通过标准化和离散化为建模技术准备数据。

在预处理之后，我们必须适当地将数据分成训练、验证和测试样本。根据数据的特征和手头的问题，可以使用不同的采样策略，例如，当数据有偏差时，或者当我们有多类分类问题时。根据数据大小，交叉验证是创建单独验证集的常见替代方法。

下一步是剔除不相关的特征。在过滤方法中，使用单变量分析的技术要么是基于熵的(信息增益、增益率)，要么是基于统计假设检验的(卡方检验)。对于主要的多变量方法，目标是在一起考虑时减少冗余特征，或者使用与目标标记最密切相关的特征。在包装器方法中，我们使用机器学习算法来告诉我们更多有区别的特征。最后，一些学习技术以正则项的形式将特征选择嵌入到算法中，通常使用脊或套索技术。这些代表了嵌入式方法。

建模技术大致分为线性、非线性和集成方法。在线性算法中，要素的类型可以决定要使用的算法-线性回归(仅数字要素)、朴素贝叶斯(数字或分类)和逻辑回归(仅数字要素，或分类转换为数字)是可行的。在选择每种方法或使用这些模型解释学习结果时，必须了解每种方法的优缺点。

决策树、k-NN 和 SVM 都是非线性技术，它们都有自己的优势和局限性。例如，可解释性是决策树的主要优势。k-NN 在面对噪声数据时是稳健的，但在处理高维数据时表现不佳。SVM 的可解释性较差，但即使在数据集有限且要素数量较多的情况下也能大放异彩。

随着许多不同模型的合作，集成方法可以利用最好的。Bagging 和 boosting 都是在集成中比它们使用的基础学习器更好地概括的技术，并且在许多应用中很受欢迎。

最后，在评估模型性能和相互比较模型时，可以使用哪些策略和方法？验证集或交叉验证的作用对于归纳未知数据的能力至关重要。从混淆矩阵得到的性能评估度量被普遍用于评估分类器；有些在某些领域和学科中比其他领域和学科更常用。当分类阈值变化时，ROC、增益和升力曲线是模型性能范围的很好的视觉表示。当成对比较模型时，使用基于统计假设检验的几个指标。Wilcoxon 和 McNemar 的是两个非参数检验；配对 t 检验是参数方法的一个例子。同样，在比较多种算法时，一种常见的不对数据分布做出假设的非参数检验是 Friedman 检验。ANOVA 是参数测试，假设指标的正态分布和方差相等。

本章的最后部分介绍了使用 RapidMiner 工具开发和评估模型的过程，这些模型用于对 UCI 马结肠数据集的测试数据进行分类。设计了三个实验来比较和对比不同数据预处理条件下模型的性能，即，不处理缺失数据，使用标准技术替换缺失数据，以及最后，在零替换之后进行特征选择。在每个实验中，我们选择多种线性、非线性和集合方法。作为整个过程的一部分，我们说明如何使用建模环境。我们可以从结果中得出启示性的结论，这使我们能够深入了解数据，并展示不同情况下各类技术的相对优势和劣势。我们的结论是，数据是高度非线性的，集成学习显示出明显优于其他技术的优势。



# 参考文献

1.  D.贝尔和 h .王(2000 年)。一种关联形式及其在特征子集选择中的应用。机器学习，41(2):175–195。
2.  J.多克(1992 年)。*评估特征选择方法及其在计算机安全中的应用*。技术报告 CSE–92–18，Davis，CA:加州大学计算机科学系。
3.  米（meter 的缩写））本·巴萨特(1982 年)。*在特征评估中使用距离测量、信息测量和误差界限*。载于 P. R. Krishnaiah 和 L. N. Kanal 编辑的《统计手册》,第 2 卷，第 773-791 页，北荷兰。
4.  Littlestone N，Warmuth M (1994) *加权多数算法*。信息计算 108(2):212–261
5.  Breiman L .、Friedman J.H .、Olshen R.A .、Stone C.J. (1984) *分类和回归树*，沃兹福思国际集团。
6.  B.Ripley(1996)，*模式识别和神经网络*。剑桥大学出版社，剑桥。
7.  布雷曼(1996 年)。 *Bagging 预测器，机器学习*，24 123-140。
8.  Burges，C. (1998 年)。*模式识别支持向量机教程。数据挖掘和知识发现*。2(2):1-47.
9.  Bouckaert，R. (2004)，*对连续变量表现良好的朴素贝叶斯分类器，计算机科学讲义*，第 3339 卷，第 1089–1094 页。
10.  Aha D (1997)。*懒学*，Kluwer 学术出版社，多德雷赫特
11.  Nadeau，c .和 Bengio，Y. (2003 年)，*泛化误差的推论*。机器学习 52:239–281。
12.  昆兰博士(1993 年)。C4.5: *机器学习的程序*，摩根·考夫曼，旧金山。
13.  Vapnik，V. (1995)，*统计学习理论的本质*。斯普林格出版社。
14.  沙皮尔热，歌手 Y，辛格哈尔 A (1998)。*应用于文本过滤的 Boosting 和 Rocchio】。在 SIGIR '98:第 21 届信息检索研究与发展国际年会论文集，第 215-223 页*
15.  布雷曼 L.(2001 年)。*随机森林*。机器学习，45 卷 1 期，第 5-32 页。
16.  Nathalie Japkowicz 和 Mohak Shah (2011 年)。*评估学习算法:分类观点*。剑桥大学出版社。
17.  汉利 j .和麦克尼尔 B. (1982)。*受试者工作特性(ROC)曲线下面积的含义和用途*。放射学 143，29–36。
18.  玺恩，李伟银，李玉山(2000)。*三十三种新旧分类算法的预测精度、复杂度和训练时间的比较*。机器学习 40:203–228。
19.  A.摩尔和李明善(1994 年)。*最小化交叉验证误差的高效算法*。进行中。第 11 国际机场。糖膏剂《论机器学习》,第 190-198 页，新泽西州新不伦瑞克。摩根·考夫曼。
20.  Nitesh 诉 Chawla 等人。艾尔。(2002).*合成少数过采样技术*。人工智能研究杂志。16:321-357.*