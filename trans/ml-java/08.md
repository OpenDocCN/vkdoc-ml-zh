<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 使用深度学习的图像识别 4j

图像在网络服务、社交网络和网络商店中无处不在。与人类相反，计算机很难理解图像中的内容及其代表的意义。在这一章中，我们将首先看看教计算机如何理解图像背后的挑战，然后重点关注一种基于深度学习的方法。我们将查看配置深度学习模型所需的高级理论，并讨论如何使用 Java 库 Deeplearning4j 实现能够对图像进行分类的模型。

本章将涵盖以下主题:

*   图像识别简介
*   讨论深度学习基础知识
*   建立图像识别模型

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 图像识别简介

图像识别的典型目标是检测和识别数字图像中的对象。图像识别在工厂自动化中应用于监控产品质量；识别潜在危险活动的监视系统，如移动人员或车辆；通过指纹、虹膜或面部特征提供生物识别的安全应用；自动驾驶汽车重建道路和环境条件；诸如此类。

数字图像不是以基于属性的描述的结构化方式呈现的；相反，它们被编码为不同通道中的颜色量，例如，黑白和红绿蓝通道。学习目标是识别与特定对象相关联的模式。传统的图像识别方法包括将图像转换成不同的形式，例如，识别物体的角、边缘、同色斑点和基本形状。这样的模式然后被用来训练学习者区分物体。下面列出了一些传统算法的著名例子:

*   边缘检测找到图像中对象的边界
*   角点检测识别两条边缘的交点或其他感兴趣的点，例如线的末端、曲率最大值或最小值等等
*   斑点检测识别与其周围区域相比在诸如亮度或颜色的属性上不同的区域
*   脊线检测使用平滑函数识别图像中的其他感兴趣点
*   **尺度不变特征变换** ( **SIFT** )是一种鲁棒的算法，可以匹配对象，即使它们的尺度或方向不同于数据库中的代表性样本
*   霍夫变换识别图像中的特定模式

最近的一种方法基于深度学习。深度学习是神经网络的一种形式，它模仿大脑处理信息的方式。深度学习的主要优势在于，有可能设计出能够自动提取相关模式的神经网络，进而可以用来训练学习者。随着神经网络的最新进展，图像识别的准确性显著提高。例如， **ImageNet** 挑战赛向参赛者提供了来自 1000 个不同对象类别的 120 多万张图像，据报道，使用**支持向量机** ( **SVM** )的最佳算法的错误率从 2010 年的 28%下降到 2014 年的 7%，使用了深度神经网络。

在这一章中，我们将快速浏览一下神经网络，从基本的构建模块，感知器，开始，逐渐引入更复杂的结构。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 神经网络

第一个神经网络是在六十年代被引入的，它受到了生物神经网络的启发。神经网络的想法是绘制生物神经系统，即大脑如何处理信息。它由相互连接的神经元层组成。在计算机术语中，它们也被称为**人工神经网络** ( **安**)。对于计算机，需要训练才能让这个模型学习，就像人脑一样。大脑中的神经元在接收到来自附近相互连接的神经元的信号时被激活，这同样适用于人工神经网络。神经网络的最新进展已经证明，深度神经网络非常适合模式识别任务，因为它们能够自动提取有趣的特征并学习底层呈现。在这一节中，我们将刷新自己的基本结构和组件，从一个单一的感知器到深层网络。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 感知器

感知器是基本的神经网络构建模块，也是最早的监督算法之一。它被定义为特征的总和，乘以相应的权重和偏差。当接收到输入信号时，它与指定的权重相乘。这些权重是为每个输入信号或输入定义的，并且在学习阶段不断调整权重。权重的调整取决于最后结果的误差。在与各自的权重相乘后，所有的输入与称为**偏差**的某个偏移值相加。偏差值也通过权重来调整。因此，它从随机权重和偏差开始，并且随着每次迭代，权重和偏差被调整，以便下一个结果向期望的输出移动。最后，最终结果被转换成输出信号。将所有这些加在一起的函数被称为**和传递函数**，它被输入到激活函数中。如果二元阶跃激活函数达到一个阈值，则输出为 1，否则为 0，这就给了我们一个二元分类器。下图显示了一个示意图:

![](img/9d234876-bb61-48f0-98b4-33d0da465223.png)

训练感知器涉及相当简单的学习算法，该算法计算计算的输出值和正确的训练输出值之间的误差，并使用该误差来创建对权重的调整，从而实现梯度下降的形式。这种算法通常被称为 **delta 规则**。

单层感知器不是很先进，非线性可分离函数，如 XOR，不能用它来建模。为了解决这个问题，引入了一种具有多个感知器的结构，称为**多层感知器**，也称为**前馈神经网络**。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 前馈神经网络

前馈神经网络是由几个感知器组成的人工神经网络，这些感知器按层组织，如下图所示:输入层、输出层以及一个或多个隐藏层。隐层与外界无关，故名。每一层感知器，也称为神经元，都与下一层的感知器直接相连，而两个神经元之间的连接则具有与感知器权重类似的权重。因此，一层中的所有感知器都与下一层中的感知器相连，信息被前馈到下一层。该图显示了一个具有四单元**输入层**，对应于长度`4`的特征向量的大小，四单元**隐藏层**，以及两单元**输出层**的网络，其中每个单元对应于一个类值:

![](img/6ab8b4ab-f8aa-4184-8620-bd78071abb2c.png)

前馈神经网络通过找到输入和输出值之间的关系来学习，这些值被多次输入到网络中。训练多层网络最流行的方法是反向传播。在反向传播中，计算的输出值与正确的值进行比较，其方式与 delta 规则中的方式相同。然后通过各种技术通过网络反馈该误差，调整每个连接的权重以减少误差值。使用网络输出值和原始输出值之间的平方差来计算误差。误差表明我们离原始输出值有多远。这个过程重复足够多的训练周期，直到误差低于某个阈值。

前馈神经网络可以有一个以上的隐藏层，其中每个附加的隐藏层在前面的层之上建立一个新的抽象。这通常会产生更精确的模型；然而，增加隐藏层的数量会导致两个已知的问题:

*   **消失梯度问题**:随着隐藏层越来越多，反向传播的训练对于将信息传递给前面的层变得越来越没用，导致这些层的训练非常缓慢
*   **过拟合**:模型与训练数据拟合得太好，在真实例子上表现不佳

让我们看看解决这些问题的其他一些网络结构。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 自动编码器

**自动编码器**是一个前馈神经网络，旨在学习如何压缩原始数据集。它的目的是将输入复制到输出。因此，我们不会将要素映射到输入图层，也不会将标注映射到输出图层，而是将要素映射到输入图层和输出图层。隐藏图层中的单元数通常不同于输入图层中的单元数，这迫使网络扩展或减少原始要素的数量。这样，网络将学习重要的特征，同时有效地应用降维。

下图显示了一个示例网络。三单位输入层首先扩展为四单位层，然后压缩为单单位层。网络的另一端将单层单元恢复到四单元层，然后恢复到原始的三输入层:

![](img/f229c5d1-e298-4e0f-b8e0-eaf36699f2be.png)

一旦训练好网络，我们就可以像传统的图像处理一样，从左侧提取图像特征。它由编码器和解码器组成，其中编码器的工作是创建或隐藏一个或多个捕捉输入本质的层，解码器从层中重建输入。

自动编码器也可以组合成**堆叠式自动编码器**，如下图所示。首先，我们将讨论基本自动编码器中的隐藏层，如前所述。然后，我们将学习隐藏层(绿色圆圈)并重复这个过程，这实际上学习了一个更抽象的表达。我们可以多次重复这一过程，将原始特征转换成越来越小的维度。最后，我们将所有的隐藏层叠加到一个常规的前馈网络中，如图右上方所示:

![](img/e053137e-b22e-4ff8-ad2c-65eea70d5c4a.png)

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 受限玻尔兹曼机

**受限玻尔兹曼机** ( **RBM** )是一种无向神经网络，也称为**生成随机网络** ( **GSNs** )，可以学习其输入集合上的概率分布。顾名思义，它们起源于玻尔兹曼机器，这是一种在八十年代推出的递归神经网络。在玻尔兹曼机器中，每个节点或神经元都与所有其他节点相连，当节点计数增加时，这使得处理变得困难。受限意味着神经元必须形成两个完全连接的层，一个输入层和一个隐藏层，如下图所示:

![](img/4595eeb9-cbda-4f68-b845-a9f3b9bf91d6.png)

与前馈网络不同，可见层和隐藏层之间的连接是无向的，因此这些值可以在可见到隐藏和隐藏到可见两个方向上传播。

训练 RBMs 基于对比散度算法，该算法使用类似于反向传播的梯度下降过程来更新权重，并且在马尔可夫链上应用 Gibbs 采样来估计梯度，即如何改变权重的方向。

RBM 也可以被堆叠起来创建一个被称为**深度信念网络** ( **DBNs** )的类。在这种情况下，RBM 的隐藏图层充当 RBM 图层的可见图层，如下图所示:

![](img/3710f522-4873-439c-a0b0-89625751661a.png)

在这种情况下，训练是递增的:一层一层地训练。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 深度卷积网络

最近在图像识别基准测试中取得非常好结果的一种网络结构是**卷积神经网络** ( **CNN** )或 ConvNet。CNN 是一种前馈神经网络，其构造方式模仿视觉皮层的行为，利用输入图像的 2D 结构，即表现出空间局部相关性的模式。它的工作原理是大脑如何回忆或记忆图像。作为人类，我们只根据特征来记忆图像。鉴于这些特征，我们的大脑将开始自己形成图像。在计算机中，考虑下图，该图显示了如何检测功能:

![](img/28592e50-146d-45af-9de0-426d399d967f.png)

同样，从图像中检测到许多特征，如下图所示:

![](img/26759343-9494-4e76-a340-39649c60028c.png)

CNN 由许多卷积层和二次采样层组成，后面可选地是全连接层。下图显示了一个这样的例子。输入层读取图像中的所有像素，然后我们应用多个过滤器。在下图中，应用了四种不同的过滤器。每个过滤器被应用于原始图像；例如，6×6 过滤器的一个像素被计算为 6×6 平方的输入像素和相应的 6×6 权重的加权和。这有效地引入了类似于标准图像处理的滤波器，例如平滑、相关、边缘检测等等。产生的图像被称为**特征图**。在下图的示例中，我们有四个特征映射，每个过滤器一个。

下一层是子采样层，它减小了输入的大小。每个特征图通常在 2×2(对于大图像高达 5×5)的连续区域上用平均值或最大值池进行二次抽样。例如，如果特征图大小为 16×16，子采样区域为 2×2，则减小的特征图大小为 8×8，其中通过计算最大值、最小值、平均值或一些其他函数将 4 个像素(2×2 的正方形)组合成单个像素:

![](img/eb58d84f-21ad-423b-b211-fd1e634e2a48.png)

网络可能包含几个连续的卷积和子采样层，如上图所示。特定的特征地图被连接到下一个简化/回旋的特征地图，而同一层的特征地图彼此不连接。

在最后一个子采样或卷积层之后，通常有一个完全连接的层，与标准多层神经网络中的层相同，表示目标数据。

使用修改的反向传播算法来训练 CNN，该算法考虑了子采样层，并且基于应用该滤波器的所有值来更新卷积滤波器权重。

一些好的 CNN 设计可以在 ImageNet 竞赛结果页面找到:[http://www.image-net.org/](http://www.image-net.org/)。一个例子是 *AlexNet* ，它在 *A. Krizhevsky 等人*的 *ImageNet 分类与深度协变神经网络*论文中有所描述。

这就结束了我们对主要神经网络结构的回顾。在下一节中，我们将继续讨论实际的实现。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 图像分类

在本节中，我们将讨论如何使用 Deeplearning4j 库实现一些神经网络结构。让我们开始吧。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 深度学习 4j

正如我们在[第 2 章](6fd557d7-2807-4a6d-8f93-d7c4ca094b7e.xhtml)、*中讨论的，用于机器学习的 Java 库和平台*，Deeplearning4j 是一个开源的、分布式的 Java 和 Scala 深度学习项目。Deeplearning4j 依靠 Spark 和 Hadoop for MapReduce，并行训练模型，并在一个中心模型中迭代平均它们产生的参数。详细的库总结在[第 2 章](6fd557d7-2807-4a6d-8f93-d7c4ca094b7e.xhtml)、*用于机器学习的 Java 库和平台*中给出。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 获取 DL4J

获取 Deeplearning4j 最便捷的方式是通过 Maven 资源库:

1.  启动一个新的 Eclipse 项目并选择 Maven 项目，如下面的屏幕截图所示:

![](img/8aed3b3c-3950-4926-b37c-4bbfc82bc7df.png)

2.  打开`pom.xml`文件，并在`<dependencies>`部分下添加以下依赖项:

```
<dependency> 
    <groupId>org.deeplearning4j</groupId> 
    <artifactId>deeplearning4j-nlp</artifactId> 
   <version>${dl4j.version}</version> 
</dependency> 

<dependency> 
    <groupId>org.deeplearning4j</groupId> 
    <artifactId>deeplearning4j-core</artifactId> 
    <version>${dl4j.version}</version> 
</dependency> 
```

3.  最后，右键单击 Project，选择 Maven，然后选择 Update project。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# MNIST 数据集

最著名的数据集之一是 MNIST 数据集，它由手写数字组成，如下图所示。该数据集由 60，000 幅训练图像和 10，000 幅测试图像组成:

![](img/d3340f60-5ca7-425a-bb00-97edef834272.png)

该数据集通常用于图像识别问题，以对算法进行基准测试。记录的最差错误率是 12%，没有预处理，并且在单层神经网络中使用 SVM。目前截至 2016 年，错误率最低的只有 0.21%，使用的是 **DropConnect** 神经网络，其次是深度卷积网络 0.23%，深度前馈网络 0.35%。

现在，让我们看看如何加载数据集。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 加载数据

Deeplearning4j 提供了现成的 MNIST 数据集加载器。加载程序被初始化为`DataSetIterator`。首先让我们导入`DataSetIterator`类和所有受支持的数据集，它们是`impl`包的一部分，例如，iris、MNIST 和其他:

```
import org.deeplearning4j.datasets.iterator.DataSetIterator; 
import org.deeplearning4j.datasets.iterator.impl.*; 
```

接下来，我们将定义一些常数，例如，图像由 28 x 28 像素组成，有 10 个目标类和 60，000 个样本。我们将初始化一个新的`MnistDataSetIterator`类，它将下载数据集及其标签。这些参数是迭代批次大小、样本总数以及数据集是否应该二进制化:

```
int numRows = 28; 
int numColumns = 28; 
int outputNum = 10;
int numSamples = 60000;
int batchSize = 100;
int iterations = 10;
int seed = 123;
DataSetIterator iter = new MnistDataSetIterator(batchSize, 
numSamples,true);  
```

拥有一个已经实现的数据导入器确实很方便，但是它不能处理您的数据。让我们快速看一下它是如何实现的，以及需要修改什么来支持您的数据集。如果您急于开始实现神经网络，您可以安全地跳过本节的其余部分，并在需要导入您自己的数据时返回。

To load the custom data, you'll need to implement two classes: `DataSetIterator`, which holds all of the information about the dataset, and `BaseDataFetcher`, which actually pulls the data either from a file, database, or the web. Sample implementations are available on GitHub at [https://github.com/deeplearning4j/deeplearning4j/tree/master/deeplearning4j-core/src/main/java/org/deeplearning4j/datasets/iterator/impl](https://github.com/deeplearning4j/deeplearning4j/tree/master/deeplearning4j-core/src/main/java/org/deeplearning4j/datasets/iterator/impl). 
Another option is to use the **Canova** library, which was developed by the same authors, at [http://deeplearning4j.org/canovadoc/](http://deeplearning4j.org/canovadoc/).<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 建筑模型

在这一节中，我们将讨论如何建立一个实际的神经网络模型。我们将从一个基本的单层神经网络开始，建立一个基准，并讨论基本操作。稍后，我们将使用 DBN 和多层卷积网络来改进这个初始结果。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 构建单层回归模型

我们先从建立基于 softmax 激活函数的单层回归模型开始，如下图所示。由于我们有一个单层，**输入到神经网络的**将是所有的图形像素，即 28×28 =**748 个**神经元。**输出**神经元的数量为 **10** ，每个数字一个。网络层完全连接，如下图所示:

![](img/7a5ce7ad-1fe2-46db-95f4-8e456cefd72d.png)

神经网络通过`NeuralNetConfiguration.Builder()`对象定义如下:

```
MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder() 
```

我们将定义梯度搜索的参数，以便用共轭梯度优化算法执行迭代。`momentum`参数决定了优化算法收敛到局部最优的速度。`momentum`越高，训练越快；但是更高的速度会降低模型的准确性:

```
.seed(seed) 
.gradientNormalization(GradientNormalization.ClipElementWiseAbsolu
   teValue) 
   .gradientNormalizationThreshold(1.0) 
   .iterations(iterations) 
   .momentum(0.5) 
   .momentumAfter(Collections.singletonMap(3, 0.9)) 
   .optimizationAlgo(OptimizationAlgorithm.CONJUGATE_GRADIENT) 
```

接下来，我们将指定网络有一层，并定义误差函数`NEGATIVELOGLIKELIHOOD`、内部感知器激活函数`softmax`，以及对应于总
图像像素和目标变量数量的输入和输出层数，如以下代码块所示:

```
.list(1) 
.layer(0, new  
OutputLayer.Builder(LossFunction.NEGATIVELOGLIKELIHOOD) 
.activation("softmax") 
.nIn(numRows*numColumns).nOut(outputNum).build()) 
```

最后，我们将网络设置为`pretrain`，禁用反向传播，实际构建未训练的网络结构:

```
   .pretrain(true).backprop(false) 
   .build(); 
```

一旦定义了网络结构，我们就可以用它来初始化一个新的`MultiLayerNetwork`，如下:

```
MultiLayerNetwork model = new MultiLayerNetwork(conf); 
model.init(); 
```

接下来，我们将通过调用`setListeners`方法将模型指向训练数据，如下所示:

```
model.setListeners(Collections.singletonList((IterationListener) 
   new ScoreIterationListener(listenerFreq))); 
```

我们还将调用`fit(int)`方法来触发端到端网络训练:

```
model.fit(iter);  
```

为了评估模型，我们将初始化一个新的`Evaluation`对象，它将存储批处理结果:

```
Evaluation eval = new Evaluation(outputNum); 
```

然后，我们可以批量迭代数据集，以便将内存消耗保持在合理的水平，并将结果存储在一个`eval`对象中:

```
DataSetIterator testIter = new MnistDataSetIterator(100,10000); 
while(testIter.hasNext()) { 
    DataSet testMnist = testIter.next(); 
    INDArray predict2 =  
    model.output(testMnist.getFeatureMatrix()); 
    eval.eval(testMnist.getLabels(), predict2); 
} 
```

最后，我们可以通过调用`stats()`函数得到结果:

```
log.info(eval.stats()); 
```

一个基本的单层模型可以达到以下精度:

```
    Accuracy:  0.8945 
    Precision: 0.8985
    Recall:    0.8922
    F1 Score:  0.8953

```

在 MNIST 数据集上获得 89.22%的准确率，即 10.88%的错误率是非常糟糕的。我们将通过使用受限玻尔兹曼机器和多层卷积网络，从简单的一层网络到适度复杂的深度信念网络来改进这一点。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 建立一个深度的信念网络

在这一部分，我们将基于 RBM 构建一个深度信念网络(DBN)，如下图所示。该网络由四层组成。第一层将 **748** 输入减少到 **500** 神经元，然后到 **250** ，接着是 **200** ，最后到最后的 **10** 目标值:

![](img/7859d3a0-9129-4f63-9274-6e95a9819d6a.png)

由于代码与前面的示例相同，我们来看看如何配置这样一个网络:

```
MultiLayerConfiguration conf = new 
   NeuralNetConfiguration.Builder() 
```

我们将定义梯度优化算法，如下面的代码所示:

```
    .seed(seed) 
    .gradientNormalization( 
    GradientNormalization.ClipElementWiseAbsoluteValue) 
    .gradientNormalizationThreshold(1.0) 
    .iterations(iterations) 
    .momentum(0.5) 
    .momentumAfter(Collections.singletonMap(3, 0.9)) 
    .optimizationAlgo(OptimizationAlgorithm.CONJUGATE_GRADIENT) 
```

我们还将指定我们的网络将有四层:

```
   .list(4) 
```

第一层的输入将是`748`神经元，输出将是`500`神经元。我们将使用均方根误差交叉熵和 Xavier 算法，通过基于输入和输出神经元的数量自动确定初始化的规模来初始化权重，如下所示:

```
.layer(0, new RBM.Builder() 
.nIn(numRows*numColumns) 
.nOut(500)          
.weightInit(WeightInit.XAVIER) 
.lossFunction(LossFunction.RMSE_XENT) 
.visibleUnit(RBM.VisibleUnit.BINARY) 
.hiddenUnit(RBM.HiddenUnit.BINARY) 
.build()) 
```

接下来的两层将具有相同的参数，除了输入和输出神经元的数量:

```
.layer(1, new RBM.Builder() 
.nIn(500) 
.nOut(250) 
.weightInit(WeightInit.XAVIER) 
.lossFunction(LossFunction.RMSE_XENT) 
.visibleUnit(RBM.VisibleUnit.BINARY) 
.hiddenUnit(RBM.HiddenUnit.BINARY) 
.build()) 
.layer(2, new RBM.Builder() 
.nIn(250) 
.nOut(200) 
.weightInit(WeightInit.XAVIER) 
.lossFunction(LossFunction.RMSE_XENT) 
.visibleUnit(RBM.VisibleUnit.BINARY) 
.hiddenUnit(RBM.HiddenUnit.BINARY) 
.build()) 
```

现在，最后一层将把神经元映射到输出，我们将使用`softmax`激活函数，如下所示:

```
.layer(3, new OutputLayer.Builder() 
.nIn(200) 
.nOut(outputNum) 
.lossFunction(LossFunction.NEGATIVELOGLIKELIHOOD) 
.activation("softmax") 
.build()) 
.pretrain(true).backprop(false) 
.build(); 
```

其余的训练和评估与单层网络示例中的相同。请注意，与单层网络相比，训练深层网络可能需要更多的时间。准确率应该在 93%左右。

现在，让我们来看看另一个深层网络。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 构建多层卷积网络

在最后一个例子中，我们将讨论如何构建卷积网络，如下图所示。该网络将由七层组成。首先，我们将使用最大池重复两对卷积和子采样层。最后的二次采样层然后连接到密集连接的前馈神经网络，在最后三层中分别由 120 个神经元、84 个神经元和 10 个神经元组成。这样的网络有效地形成了完整的图像识别管道，其中前四层对应于特征提取，后三层对应于学习模型:

![](img/56a26eae-f5f1-4d22-b174-2c2c43484a8a.png)

网络配置如我们之前所做的那样初始化:

```
MultiLayerConfiguration.Builder conf = new 
   NeuralNetConfiguration.Builder() 
```

我们将指定梯度下降算法及其参数，如下所示:

```
.seed(seed) 
.iterations(iterations) 
.activation("sigmoid") 
.weightInit(WeightInit.DISTRIBUTION) 
.dist(new NormalDistribution(0.0, 0.01)) 
.learningRate(1e-3) 
.learningRateScoreBasedDecayRate(1e-1) 
.optimizationAlgo( 
OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT) 
```

我们还将指定七个网络层，如下所示:

```
.list(7) 
```

第一卷积层的输入是完整的图像，而输出是六个特征图。卷积层将应用 5×5 过滤器，结果将存储在 1×1 单元中:

```
.layer(0, new ConvolutionLayer.Builder( 
    new int[]{5, 5}, new int[]{1, 1}) 
    .name("cnn1") 
    .nIn(numRows*numColumns) 
    .nOut(6) 
    .build()) 
```

第二层是二次采样层，它将占用 2 x 2 区域，并将最大结果存储在 2 x 2 元素中:

```
.layer(1, new SubsamplingLayer.Builder( 
SubsamplingLayer.PoolingType.MAX,  
new int[]{2, 2}, new int[]{2, 2}) 
.name("maxpool1") 
.build()) 
```

接下来的两层将重复前两层:

```
.layer(2, new ConvolutionLayer.Builder(new int[]{5, 5}, new 
   int[]{1, 1}) 
    .name("cnn2") 
    .nOut(16) 
    .biasInit(1) 
    .build()) 
.layer(3, new SubsamplingLayer.Builder
   (SubsamplingLayer.PoolingType.MAX, new 
   int[]{2, 2}, new int[]{2, 2}) 
    .name("maxpool2") 
    .build()) 
```

现在，我们将把二次采样层的输出连接到由`120`神经元组成的密集前馈网络，然后通过另一层连接到`84`神经元，如下所示:

```
.layer(4, new DenseLayer.Builder() 
    .name("ffn1") 
    .nOut(120) 
    .build()) 
.layer(5, new DenseLayer.Builder() 
    .name("ffn2") 
    .nOut(84) 
    .build()) 
```

最后一层连接`84`神经元和`10`输出神经元:

```
.layer(6, new OutputLayer.Builder
   (LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD) 
    .name("output") 
    .nOut(outputNum) 
    .activation("softmax") // radial basis function required 
    .build()) 
.backprop(true) 
.pretrain(false) 
.cnnInputSize(numRows,numColumns,1); 
```

为了训练这种结构，我们可以重用我们在前两个例子中开发的代码。同样，培训可能需要一些时间。网络准确率应该在 98%左右。

Since model training significantly relies on linear algebra, training can be significantly sped up by using a **graphics processing unit** (**GPU**) for an order of magnitude. As the GPU backend, at the time of writing this book, is undergoing a rewrite, please check the latest documentation at [http://deeplearning4j.org/documentation](http://deeplearning4j.org/documentation).

正如我们在不同的例子中看到的，越来越复杂的神经网络允许我们自动提取相关特征，从而完全避免了传统的图像处理。然而，我们为此付出的代价是增加处理时间和大量的学习示例，以使这种方法有效。

<link href="Styles/Style00.css" rel="stylesheet" type="text/css"> <link href="Styles/Style01.css" rel="stylesheet" type="text/css"> <link href="Styles/Style02.css" rel="stylesheet" type="text/css"> <link href="Styles/Style03.css" rel="stylesheet" type="text/css">     

# 摘要

在本章中，我们讨论了如何识别图像中的模式，以便通过涵盖深度学习的基本原则来区分不同的类别，并讨论了如何使用 Deeplearning4j 库来实现它们。我们从更新基本的神经网络结构开始，并讨论了如何实现它们来解决手写数字识别问题。

在下一章，我们将进一步研究模式；然而，代替图像中的模式，我们将处理具有时间依赖性的模式，这可以在传感器数据中找到。