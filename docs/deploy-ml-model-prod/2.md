# 2.模型部署和挑战

在前一章中你已经复习了机器学习的概念，所以现在进入下一阶段是合乎逻辑的。什么是机器学习部署，在进行部署时有哪些常见挑战？

这一章包括两个主题。首先，这一章讨论了什么是模型部署，以及模型生产的不同方面。第二，本章涵盖了在大规模生产过程中面临的不同挑战。在模型部署的两个阶段(部署前和部署后阶段)都可以观察到这些挑战，但是为了简单起见，我们将把这些挑战作为一个整体来关注。虽然机器学习团队所面临的挑战对于每个特定的案例都是独特的，但是我们将讨论与部署相关的最常见的案例。

## 模型部署

在前一章中，我们看到了建立机器学习模型或深度学习模型(无论是本地还是云中)需要什么。模型的复杂程度或性质可能因具体情况而异，但基本框架是相似的。我们有一些来自数据源(可以是单个源或多个源)的典型数据，然后是一系列数据清理和预处理步骤，然后我们从输入数据中提取或创建重要特征，以训练特定用例的机器学习模型。一旦模型经过训练或准备好在生产环境中使用，就可以通过一些 API 将它暴露给看不见的数据来进行预测。然而，最后一部分带来了一些挑战。如果我们试图在建立成功的 ML 模型后观察这个循环，它看起来有点像图 [2-1](#Fig1) 。

第一阶段是在生产中部署训练好的 ML 模型并测试结果。接下来是在连续级别上对模型进行性能监控。一旦模型的性能低于预期的基准水平，就需要重新训练和评估模型，用新模型替换旧模型。这包括模型管理(版本、特性等。).在不影响现有用户请求的情况下，模型被再次部署到生产环境中(您将在接下来的 ML 部署章节中了解更多)。一旦新模型被部署，图 [2-1](#Fig1) 中所示的相同步骤将在整个框架中重复。

![img/493063_1_En_2_Chapter/493063_1_En_2_Fig1_HTML.jpg](img/493063_1_En_2_Chapter/493063_1_En_2_Fig1_HTML.jpg)

图 2-1

部署中的 ML 模型

虽然部署在本质上非常直观，因为有数百万个应用程序已经在机器学习的环境中无缝工作，但可能需要进一步解释。与其他典型的软件应用程序(如移动应用程序)相比，机器学习应用程序在本质上有两个主要方面的不同。

*   基础模型

*   基础数据

当我们说我们将在生产中部署模型或生产化模型时，我们指的是将机器学习模型集成到现有的业务应用程序中。简而言之，我们将 ML 模型作为 REST API 端点公开，以服务于应用程序平台内的请求或指导用户请求。要在生产中部署的这个模型可以是一个独立的预测器，根据用于批处理数据的算法提供一些输出，或者可以用于实时处理请求，使其成为一个动态模型。从数据科学家的角度来看，模型部署通常可以被视为机器学习周期的最后一个阶段；然而，这是模型管理阶段的开始。能够成功部署机器学习模型需要来自多个利益相关方的大量输入和协调，例如数据科学家、数据工程师、应用程序开发人员、mlop/devo PS 和业务团队成员。老实说，这是机器学习生命周期中最困难的阶段，因为在部署阶段可能会出现许多问题。我们将在本章的后面深入探讨这些挑战。

## 为什么我们需要机器学习部署？

到目前为止，我们已经很好地理解了机器学习模型是做什么的，以及它是如何被训练的，但关键是要理解 ML 模型在整个商业应用中的作用。它可以是简单的预测，也可以是多种预测或某种建议的组合。最终，它需要使整个业务应用程序更加有效。例如，生产中的 ML 模型可以用于基于网站上的活动来预测每个在线访问者购买或不购买特定产品的倾向，或者基于其他因素来预测网络流量。不管 ML 在整个应用程序中的实际角色如何，部署都成为 ML 模型与应用程序对话的一个不可或缺的部分。

有人可能会问，为什么将 ML 模型投入生产如此重要？这个问题有多个答案，但最重要的是从机器学习模型中提取真正的价值。它必须成为应用程序的一部分，并为应用程序提供所有的预测和见解。我能想到的不将机器学习模型投入生产的最佳类比就像是为体育赛事进行训练，但却没有参与其中。这限制了它嵌入到应用程序中可能产生的影响。话虽如此，但在某些情况下，不将模型投入生产更有意义。如前所述，这取决于案例和使用机器学习的应用程序的实际上下文。在某些情况下，一个独立的模型确实被证明更简单，更容易使用。独立模型在构建、训练、预测、提取业务见解和制定决策方面要快得多。但是，在下列情况下，这可能不是一种相关的方法:

*   数据是巨大的。

*   数据正在流动。

*   有很多活跃用户。

*   有更快的反应。

专门针对大数据进行训练以处理类似预测数据的 ML 模型需要在整体应用中得到很好的管理。类似地，如果手头的数据是流类型的，那么模型应该与应用程序集成在一起，以处理不断传入的数据。另一个方面是当你有大量用户的时候；在这种情况下，您希望确保模型能够处理许多请求，并且相同模型的多个实例并行运行以服务于这些请求。需要记住的一个关键点是，在生产中部署 ML 模型并不能保证预测质量的一致性。在现实中，随着模型暴露于真实数据，模型的性能通常会迅速恶化(这种影响被称为*漂移*，您将在“挑战”部分了解更多信息)，这就是模型管理发挥重要作用的地方。

总之，部署有助于通过将模型与应用程序集成来提取机器学习的真正价值，从而产生切实的业务洞察力。这也意味着可以根据实时数据进行预测。

## 挑战

如果部署 ML 模型很容易，没有任何问题，我就不会写本章的这一节了。很少有人拥有从开发阶段到生产阶段的理想条件，而没有一些改变和调整。我们必须理解开发一个模型和部署一个模型之间的主要区别。这两种任务在性能、速度和资源消耗方面的预期都是不同的。通常情况下，有两个独立的小组分别在这些阶段中的每一个阶段工作(尽管随着更多的数据科学家承担 ML 部署任务以及 DevOps 人员正在学习自己构建 ML/DL 模型，这一趋势正在发生变化)。在对 ML 模型的所有期望中，最与众不同的一个是，当模型在生产中服务于来自用户的实时请求时，需要连续地监控模型的性能，因为应用程序必须在生产中具有模型的最佳可用版本。

斯卡利等人在 2015 年发表的著名谷歌论文《机器学习系统中隐藏的技术债务》，在质疑机器学习在整体应用中的实际作用和重要性时，向机器学习界提出了不同的观点( [`https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf`](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf) )。

> *“他们说，在现实世界的机器学习(ML)系统中，只有一小部分是由实际的 ML 代码组成的。有大量的周边基础设施和流程来支持它们的发展。”*

该论文提到，其他组件，如数据依赖性、模型复杂性、可再现性、测试、监控和版本变更，在获得现实的 ML 应用中起着相对更大的作用。在那篇论文之前，对机器学习角色的普遍看法是，它是整个生命周期中最关键的部分，如图 [2-2](#Fig2) 所示。

![img/493063_1_En_2_Chapter/493063_1_En_2_Fig2_HTML.jpg](img/493063_1_En_2_Chapter/493063_1_En_2_Fig2_HTML.jpg)

图 2-2

应用程序中的 ML 角色

根据这篇论文，这与现实相差甚远。实际上，机器学习代码是整个事物方案的一小部分，如图 [2-3](#Fig3) 所示。有许多其他的组件驱动着基于 ML 的应用程序的真正价值。

![img/493063_1_En_2_Chapter/493063_1_En_2_Fig3_HTML.jpg](img/493063_1_En_2_Chapter/493063_1_En_2_Fig3_HTML.jpg)

图 2-3

应用程序中的实际 ML 角色

老实说，模型部署期间面临的挑战与图 [2-3](#Fig3) 中所示的组件密切相关，因为它们使整个应用程序变得实用。如前所述，部署团队还会面临其他挑战。接下来的几节将为您提供一个关于将 ML 模型投入生产时会发生什么的合理想法。

### 挑战 1:利益攸关方之间的协调

如前所述，部署模型时最自然的障碍是与没有数据科学或机器学习背景的其他团队成员保持一致，如开发人员、应用程序开发人员和业务团队成员。模型部署是一项团队任务，需要不断的沟通和对整体目标的共同理解。在 ML 模型开发的早期阶段进行适当的规划将有助于 MLOps/DevOps 团队提前为部署做好准备。

### 挑战 2:编程语言差异

与应用程序集成或开发人员使用的语言(Java/C++/Ruby)相比，机器学习模型很可能是用不同的语言(Python/TensorFlow/PyTorch)构建的。这使得集成更加困难，因为 ML 模型需要使用应用程序的本地语言重新编码。如今，迁移 ML 模型以轻松地与应用程序的其余部分集成已经变得越来越容易，但是使用公共语言来构建模型以避免集成问题也很有帮助。

### 挑战 3:模型漂移

当涉及到机器学习模型在生产中的性能时，模型漂移是一种常见现象。当模型的预测性能降低到可接受的基准以下时，就会发生模型漂移。同样，这取决于模型在什么样的环境中使用以及如何评估这些预测，但是每个应用程序都需要有最佳版本的后端 ML 模型，以获得更高的效率和输出。这成为在生产中持续跟踪已部署模型的性能的主要原因之一。

但是，如果我们深入了解生产中模型性能下降的原因，我们可以将性能下降归因于几个原因。

*   改变新数据的行为

*   改变对新数据的解释

#### 改变数据的行为

我们通常会根据具有必要特性的历史数据训练模型，并在达到满意的性能水平后(在所有超参数调整和测试后)将模型投入生产。然而，一个简单的事实是，随着时间的推移，数据可能会以不同的方式发生变化，带来模型之前未发现的新变化和维度(在训练期间)。这会影响模型在实时或生产中的性能。一个例子是，如果使用机器学习来预测用户转换或不转换(购买或不购买产品)的可能性或倾向，基于使用捕获在线行为的前两年历史数据的训练(用户在做出购买决定之前如何在网站上导航)。在开始时，该模型表现得非常好，能够在所有在线访问者中决定谁是潜在的认真买家，谁是临时访客，但随着时间的推移，用户的购买模式和行为会发生变化，并且会出现与机器学习模型所建议的不同的结果。也许模型学习了不同的决策界限来区分购买者和非购买者，现在需要根据新的潜在模式重新调整。这被称为*模型漂移*，因为预测是基于输入数据的动态特性。

#### 改变对新数据的解释

在另一种情况下，类别或标签的解释可能会随着时间的推移而改变。例如，如果先前给定的一组客户属于类别 A，但是由于理解和业务案例的变化，该类别或者被改变或者与其他类别(比如说类别 C)组合，这将影响模型的整体性能。在再次投入生产之前，我们需要使用新的标签集(针对历史数据)对模型进行重新训练。这在机器学习中也被称为*概念漂移*。

### 挑战 4:内部部署与基于云的部署

许多企业发现很难决定是需要使用内部资源进行模型部署还是选择云服务。从长远来看，根据应用程序用户的数量，这两种决策会产生不同的影响。在决定生产策略之前，DS 团队和基础设施团队应该考虑所有的利弊。

### 挑战 5:明确的所有权

所有权有时会变得令人困惑，因为当涉及到模型部署时，需要清楚地定义每个团队成员的角色和职责。数据科学家假设他们的工作在模型建立后就完成了，而开发人员/开发人员对模型中发生的事情一无所知，因此需要更多的输入来将模型正确地集成到应用程序中。在一天结束时，整个团队的共同责任是致力于部署，以确保将正确的模型部署到生产中，并避免不必要的延迟。

### 挑战 6:模型性能监控

尽管监视发生在模型部署阶段之后，但仍需要在实际部署之前进行规划。框架需要到位，以便在一致的基础上跟踪模型的性能。这有助于围绕以下问题制定策略:

*   什么时候重新训练模型？

*   使用多少数据来重新训练模型？

*   该型号的性能基准是什么？

在一段时间内，来自该框架的数据有助于得出模型在生产中的可接受性能的基准数字。

### 挑战 7:发布/版本管理

当涉及到机器学习部署时，有许多来回的活动，版本跟踪成为整个成功部署过程的重要部分。因此，版本控制有助于跟踪哪个模型是最好的模型、不同的文件依赖关系以及数据资源指针。有多种方式可以处理版本控制；Git 是最广泛使用的跟踪不同版本和分阶段部署的工具。

### 挑战 8:隐私保护和安全模型

模型部署中的另一个挑战是保护模型免受任何恶意攻击，并将模型数据暴露给第三方渗透。这对于确保该模型不会暴露给任何在安全模式下运行的未授权用户变得至关重要。

还有许多其他挑战，如可伸缩性、公开服务等。，我们将在接下来的章节中继续讨论这些挑战。在下一章，我们将会看到模型部署的不同模式。我们可以将模型部署分为四种不同的方法。

*   在本地部署模型

*   在生产服务器上保存模型

*   将模型部署为 REST 服务

*   托管服务

## 结论

在这一章中，我们回顾了模型部署的基础及其相关的挑战。