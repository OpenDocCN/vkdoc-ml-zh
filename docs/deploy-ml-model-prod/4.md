# 4.使用 Docker 的机器学习部署

在过去的几年里，Docker 改变了应用程序在生产中的部署方式。应用程序架构已经从整体服务转移到微服务，对持续(正在进行的)部署有了更多的控制，不会影响大部分正在运行的应用程序。事实证明，Docker 有助于让应用程序大规模运行并始终可用。虽然距离 Docker 发布已经过去了七年多，但它最近已经得到了开发人员社区的大量关注(尤其是 DevOps 和 MLOps 团队)。大大小小的公司都在应用程序中使用 Docker。

在这一章中，我们将回顾 Docker 生态系统，看看 Docker 的不同组成部分。本章涵盖三个主要主题。首先，本章介绍了 Docker 是什么以及它为什么有用。其次，本章涵盖了不同的组件，如 Docker 映像、Docker 服务器、Docker Hub 和容器。最后，本章介绍了如何“Dockerize”整个 ML 应用程序，并使用 Docker 容器运行它。Docker 在过去的几年里变得非常受欢迎，并且有许多专门关于这个主题的书籍。我们将涵盖从机器学习的角度来看与我们最相关的主题。

## Docker 是什么，我们为什么需要它？

场景 1:假设我们想在笔记本电脑或主机系统上安装一个新的应用程序。这是一个简单的过程。我们通常会从应用程序的源代码中下载安装文件，并在我们的系统中运行它。有时第一次尝试就能完美安装；然而，其他时候，我们可能会遇到不同的问题(依赖性、兼容性错误等)。)，如图 [4-1](#Fig1) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig1_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig1_HTML.jpg)

图 4-1

典型应用程序安装

场景 2:假设我们在特定的环境中使用特定的库在我们的机器上编写了一些代码。当我们在本地执行它时，一切都运行得很完美，但是当我们与他人共享它进行测试时，它就坏了。发生这种情况是因为底层配置发生了变化。这可能是因为缺少依赖项、不同的操作系统或其他原因。

Docker 可以很好地处理前面两种情况，因为 Docker 可以确保在任何地方运行应用程序的环境都是相同的。如果我们能够在一台特定的机器上运行一个应用程序或某些代码，我们也可以很容易地在其他任何地方运行它。这就是 Docker 的妙处。它使安装和运行任何应用程序或程序变得容易，而不必担心底层系统上的一组依赖项和文件。用一个例子来详细说明，如果我们必须在我们的系统上安装 Redis(一个内存中的数据库)，我们必须去 Redis 网站并遵循某些指示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Figa_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Figa_HTML.jpg)

从输出来看，这似乎很简单，但是在每个阶段我们都可能会遇到错误，因为缺少安装 Redis 的依赖项。Docker 让这变得超级简单快捷。通过一行代码，我们能够在我们的系统上安装 Redis(在 Docker 中)。

```py
docker container run redis

```

### Docker 简介

> **Docker**是一个执行操作系统级虚拟化的计算机程序，也称为容器化。”**

 *容器允许我们将应用程序所需的所有文件打包到一个包中，比如库、二进制文件和其他依赖项。这样，我们的应用程序可以在任何机器上运行，并具有相同的行为。核心思想是能够复制应用程序的行为，而不管它在哪个主机上运行。例如，当我们构建任何应用程序时，我们通常在开发环境中编写代码，然后在测试环境中测试它。就生产环境而言，这些环境通常互不相同，因此，由于操作平台不同，开发人员会遇到多种问题。Docker 确保如果应用程序在开发环境中成功运行，它也可以安全地部署在生产环境中，如图 [4-2](#Fig2) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig2_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig2_HTML.jpg)

图 4-2

应用程序部署阶段

### Docker 与虚拟机

您可能在某个时候使用过虚拟机。当我们想要创建不同的环境并使用不同的操作系统运行不同的应用程序时，虚拟机非常强大。虚拟化层有一个虚拟机管理程序来创建虚拟机。一旦在主机系统上创建了虚拟机，每个虚拟机都将拥有自己的一套操作系统、库、二进制文件和应用程序。如图 [4-3](#Fig3) 所示，虚拟机会消耗一定量的内存和硬件资源，而这些资源是无法与其他虚拟机共享的。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig3_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig3_HTML.jpg)

图 4-3

基于虚拟机管理程序的虚拟化

在 Docker 中没有管理程序；取而代之的是 Docker 服务器，它将每个运行在单独容器中的 app 隔离开来，如图 [4-4](#Fig4) 所示。说到底，Docker 应用程序是使用 Linux 操作系统的轻量级虚拟机；这样做的好处是 Docker 只根据需求使用内存和硬件资源，而在虚拟机中，我们必须在创建虚拟机之前分配资源，并且资源不能在虚拟机之间共享。这是资源的浪费，增加了成本(在云上)。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig4_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig4_HTML.jpg)

图 4-4

基于 Docker 的虚拟化

## Docker 组件和有用的命令

既然我们已经介绍了 Docker 及其用途，我们可以看看 Docker 生态系统的其他组件。Docker 实际上是一个由 Docker 镜像、Docker CLI、Docker 服务器和 Docker Hub 等多个组件组成的平台，如图 [4-5](#Fig5) 所示。我们将详细研究其中的每一个，以了解整个 Docker 生态系统以及组件之间的交互方式。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig5_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig5_HTML.jpg)

图 4-5

Docker 生态系统

### Docker 图像

在进入 Docker 映像之前，它本质上是 Docker 容器的蓝图，先了解一下 Docker 文件是有意义的。一个 *Dockerfile* 是 Docker 容器生命周期的初始化点。我们首先需要一个 Docker 文件来构建 Docker 映像，然后基于该映像运行一个容器。

#### Dockerfile

当我们使用 Docker 图像时，会出现两种情况。

*   使用公共 Docker 图像

*   构建客户 Docker 图像

在第一种情况下，我们可能不需要创建 Dockerfile，因为我们可以简单地从 Docker Hub 中提取映像，并使用它创建/运行一个容器，而无需对映像进行任何更改。例如，如果我们想使用 Docker 运行 Nginx(一个 web 服务器),我们只需提取 Nginx Docker 映像，不做任何更改就可以运行它。然而，在第二种情况下，我们希望根据我们的特定需求定制图像，我们需要创建一个 docker 文件。

Dockerfile 是一个简单的文本文件，没有任何扩展名，固定名称为`Dockerfile`。它包含一组命令(根据需求不同，每个文件会有所不同)，执行这些命令来构建 Docker 映像。创建 Dockerfile 的过程非常简单，如图 [4-6](#Fig6) 所示。我们将查看 docker 文件来理解这些命令。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig6_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig6_HTML.jpg)

图 4-6

Dockerfile 过程

我们从我们想要利用的基础映像开始，而不是从零开始。之后，我们有了与文件、依赖项和环境变量相关的附加命令。最后，Dockerfile 包含在运行容器时应该首先执行的启动命令。

#### Dockerfile 命令

尽管 docker 文件中可以使用许多命令( [`https://kapeli.com/cheat_sheets/Dockerfile.docset/Contents/Resources/Documents/index`](https://kapeli.com/cheat_sheets/Dockerfile.docset/Contents/Resources/Documents/index) )，但大多数情况下，以下命令足以满足基本需求。想法是从新映像的基础映像开始，并向新映像添加依赖项和需求。

以下命令用于创建 Dockerfile 文件。我们将在一个示例的帮助下查看这些内容，在这个示例中，我们创建了一个 over 文件来运行 Node.js 应用程序。

*   `FROM`

*   `COPY`

*   `WORKDIR`

*   `EXPOSE`

*   `RUN`

*   `CMD OR ENTRYPOINT`

以下命令为 Dockerfile 提供了基础映像，它需要成为映像其余部分的起点:

```py
FROM node:alpine

```

对于 Node.js 应用程序，我们提到了官方的 Node.js 基础映像。`FROM`总是 docker 文件中的第一个命令，因为它后来成为整个容器的基础层。

下一个命令是将工作目录或项目文件夹的内容从主机系统添加或复制到 Docker 容器文件夹:

```py
COPY . /app/usr/nodejs

```

我们可以使用`COPY`命令在 Docker 中创建一个新的文件夹，或者复制同一个工作文件夹中的所有文件和脚本。在前一个例子中，我们将所有应用程序文件复制到 Docker 容器中一个名为`nodejs`的新文件夹中。核心思想是在运行时提供 Docker 中所有可用的应用程序文件。

既然我们已经复制了 Docker 文件夹中的所有内容，那么从那个特定的文件夹:`nodejs`运行应用程序是有意义的。因此，我们将工作目录更改为 Docker 容器中的`nodejs`文件夹。我们利用`WORKDIR`来设置应用程序的目录。

```py
WORKDIR /app/usr/nodejs

```

Docker 容器有自己的一组网络端口，因此为了响应传入的请求，我们需要在一个端口上公开应用程序。`EXPOSE`命令允许我们让外部请求在给定的端口上访问应用程序。

```py
EXPOSE 5000

```

`RUN`命令帮助我们安装一组依赖项和库，以便在容器内运行应用程序。我们没有单独安装每个依赖项，而是使用了一个包含所有特定版本所需文件的`requirement.txt`文件。

```py
RUN pip install -r requirement.txt

```

Dockerfile 中的最后一个命令是`CMD`，它是容器的启动命令。

```py
CMD ["yarn", "start"]

```

### 坞站集线器

Docker Hub ( [`https://hub.docker.com/`](https://hub.docker.com/) )对于图像就像 GitHub 对于代码库一样。这是一个公共和私人图像的集合。它包含官方图像以及为不同应用定制的公共图像。例如，我们获得 Postgres、Spark、Ubuntu 和其他类似应用程序的官方图片。它允许用户使用官方映像直接运行容器并使用应用程序。我们需要一个帐户来访问 Docker Hub。它还允许我们从本地系统提取和推送 Docker 映像。一旦保存在 Docker Hub 上，我们就可以在任何给定的环境中的任何时间点使用特定的图像。现在 Docker 文件已经创建，我们也看到了 Docker Hub，我们可以研究 Docker 客户机和服务器的细节，并使用它们从我们前面创建的 Docker 文件创建 Docker 映像。

### Docker 客户端和 Docker 服务器

Docker 的生态系统中有很多组件；其中最重要的两项如下:

*   客户端坞站(CLI)

*   docker server 守护进程

Docker CLI 是在任何系统上与 Docker 交互的网关。我们可以通过 CLI 向 Docker 服务器发出指令或命令，它通过 Docker 服务器与它们进行通信，只需稍作修改。Docker CLI 也是我们可以看到容器输出或登录到正在运行的容器的地方。要查看关于 Docker 客户端和服务器的更多信息，我们可以简单地在我们的终端中运行`docker version`，如图 [4-7](#Fig7) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig7_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig7_HTML.jpg)

图 4-7

Docker 服务器信息

另一方面，`docker server`执行所有与映像、网络、卷和容器相关的任务。基本上，它在幕后完成所有繁重的工作。如果图像出现在本地，它会查看这些图像；否则，它会从 Docker Hub 下载它们。为了更好地理解这一点，我们来看一个例子。如果我们需要运行 Nginx 服务器，我们将运行的命令是`docker container run nginx`。

为了使用 Docker 运行 Nginx 服务器，需要遵循一系列步骤。当我们使用 CLI 向 Docker 发出命令时，它会被传递给 Docker 服务器，后者会在本地系统上查找特定的映像。如果映像在本地可用，它会使用该特定映像初始化并运行容器，否则它会访问 Docker Hub 并提取该特定映像(在本例中为 Nginx 映像)，如图 [4-8](#Fig8) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig8_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig8_HTML.jpg)

图 4-8

Docker 图像提取

一旦图像保存在本地图像缓存中，它就不必两次提取相同的图像，下次使用该图像运行容器时，它会被重用。在运行 node.js 的示例中，我们只需从 Dockerfile 构建图像，如图 [4-9](#Fig9) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig9_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig9_HTML.jpg)

图 4-9

docker image from dockerfile 停靠影像

我们看到了从 Docker 文件构建 Docker 映像的过程。它本质上包含了容器应该操作的信息。Docker 映像就像文件系统的快照——应用程序需要运行的一组目录和文件。它们还包含要执行的初始化命令，而容器的实例使用映像运行。这也可能是可选的，因为我们也可以通过在运行时提供一个新命令来覆盖默认的启动命令。因此，映像是核心文件，它包含了与需要运行的应用程序相关的所有关键需求和配置信息。

不用说，它使用运行应用程序所需的最小配置集，这使得 Docker 快速且易于使用，但有时应用程序本质上可能相当复杂，我们最终会为应用程序的各个组件创建不同的 Docker 映像，以使它们能够相互通信，从而成功执行。如前所述，映像充当运行特定应用程序所需的所有文件和目录的来源。如果映像没有正确包含相关的配置文件或依赖项，我们就不能使用 Docker 运行应用程序，因为它依赖于正在执行的这些文件。例如，假设我们试图覆盖 Nginx Docker 容器的默认命令，转而运行`ls`命令。如图 [4-10](#Fig10) 所示，我们看到这个容器中已经存在一堆文件夹。这些文件夹是运行 Nginx 服务器所需的默认配置文件和依赖项。这些是 Nginx Docker 基本映像的一部分，以确保该映像的实例在任何地方都能成功运行。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig10_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig10_HTML.jpg)

图 4-10

访问正在运行的容器

### 码头集装箱

既然我们了解了什么是图像以及 Docker 图像都包含什么，我们就可以继续讨论容器了。该映像用于启动容器，这些容器不过是特定映像的运行实例。可以从同一个映像创建多个容器，使同一个应用程序有多个实例运行，如图 [4-11](#Fig11) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig11_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig11_HTML.jpg)

图 4-11

使用相同 Docker 图像的多个容器

实际上，容器是在特定环境中运行的打包应用程序。Docker 容器就是从那个环境开始的。其实现方式是从主机资源中分配一些资源。我们已经知道，Docker 映像充当文件系统快照，并且还包含启动命令。一旦我们将这个映像传递给 Docker CLI，它就会与 Docker 服务器通信，用这个特定的映像启动容器。因此，Docker 服务器确保在容器内分配的资源(RAM、CPU、硬盘、网络)内创建类似的文件系统，如图 [4-12](#Fig12) 所示。一旦初始化，特定的应用程序就像主机系统上的任何其他应用程序一样在容器内运行。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig12_HTML.png](img/493063_1_En_4_Chapter/493063_1_En_4_Fig12_HTML.png)

图 4-12

图像到容器

如前所述，容器是一个进程或一组进程，它利用分配给它的一组特定资源来运行特定的应用程序。运行一个容器实际上有两个部分。

*   创建容器

*   运行容器

对于第一部分，我们获取基本映像，并根据映像的默认文件系统和配置文件获取分配给容器的不同资源。记住，我们不执行任何启动或覆盖命令来运行容器，如图 [4-13](#Fig13) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig13_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig13_HTML.jpg)

图 4-13

Docker 容器初始化

在第二部分中，一旦分配了资源，运行容器包括执行启动命令或覆盖命令以成功运行应用程序。`-a`表示附加容器 ID，以查看执行后的输出，如图 [4-14](#Fig14) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig14_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig14_HTML.jpg)

图 4-14

运行 Docker 容器

`docker run`命令依次执行前两个阶段。

#### 一些有用的容器相关命令

我们可以使用以下命令列出所有正在运行的容器:

```py
[In]: docker container ps

```

如果我们想查看到目前为止使用的所有容器，我们可以将`–all`添加到前面的命令中:

```py
[In]: docker container ps –all

```

如果我们想从 Docker Hub 中提取一个特定的图像，并使用它根据我们的特定需求定制一些东西，我们可以使用`pull`命令。

```py
[In]: docker pull redis

```

为了使用特定的映像运行容器，我们使用了`docker run`命令。

```py
[In]: docker run

```

正如我们在这个例子中已经看到的，我们可以使用`build`命令从 Docker 文件创建一个 Docker 映像。

```py
[In]: docker build

```

如果我们想将 Docker 映像推送到 Docker Hub 平台，我们可以使用带有映像唯一名称的`docker push`命令。

```py
[In]: docker push

```

如果我们想停止一个正在运行的容器，我们可以使用`docker stop`命令。如果集装箱在十秒钟内没有停止，则`docker kill`命令将被激活，集装箱将被立即移走。

```py
[In]: docker stop

```

如果我们想要删除一个容器，我们可以使用`rm`命令来删除使用容器 ID 的特定容器。

```py
[In]: docker rm

```

如果我们想删除一个特定的 Docker 图像，我们可以使用`rmi`命令。有时，我们可能不得不使用`docker rmi –force`来强制删除图像。

```py
[In]: docker rmi

```

`exec`命令帮助我们进入一个正在运行的容器。

```py
[In]: docker exec

```

命令通过移除所有停止的容器和悬挂的图像来清理你的系统，并释放大量空间。

```py
[In]: docker system prune

```

## 使用 Docker 的机器学习

在本节中，我们将从头构建一个分类模型，并尝试使用 Flask 应用程序部署它。与前一章的唯一区别是将整个应用程序 Dockerize 并在任何平台上运行。我们还将利用库 Flasgger 来处理应用程序的 UI 部分，以便更直观地使用结果。首先，让我们在本地系统中创建一个名为`docker_app`的新文件夹。

我们将按照以下步骤执行该流程:

1.  训练 ML 模型。

2.  保存并导出 ML 模型。

3.  创建一个包含 UI 层的 Flask 应用程序。

4.  为应用程序构建自定义 Docker 图像。

5.  使用 Docker 容器运行应用程序。

6.  停下集装箱。

### 步骤 1:训练机器学习模型

这是我们将在特定数据集上训练机器学习模型的第一阶段。由于总体想法是部署 ML 应用程序，所以重点是将应用程序容器化，而不是提高模型的准确性。因此，我们不会涉及太多的特征工程或复杂的 ML 模型。更确切地说，一个简单的逻辑回归或随机森林模型就足够了。话虽如此，我们总是可以用不同的、更好的模型替换给定的模型，而不会影响流程的其余部分。

在这种情况下，我们拥有的数据集来自一个关于客户历史交易的在线平台。它包含数据点，如年龄、浏览的总页数以及客户是新客户还是回头客。输出变量包含客户是否在线购买了产品。因此，我们将训练一个简单的逻辑回归模型来对测试数据进行预测，然后出于部署目的将其导出。

我们首先导入两个基本库 numpy 和 pandas，然后研究数据集。

```py
[In]: import numpy as np
[In]: import pandas as pd

[In]: df = pd.read_csv('online_sales.csv')
[In]: df.shape
[Out]:(316200, 4)

```

在总共有 4 列的数据集中，我们有大约 30 万条记录。我们来看看数据是怎么看的，阶级平衡。

![img/493063_1_En_4_Chapter/493063_1_En_4_Figb_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Figb_HTML.jpg)

```py
[In]:df.head()
[Out]:

```

```py
[In]: df.converted.value_counts()
[Out]:
0    306000
1     10200

```

我们可以清楚地看到，在这个数据集中有一个倾斜的目标类，通常需要通过一些欠采样/过采样技术来处理。但是，我们并不希望在这个练习中找到最佳的模型精度，因此我们将使用我们拥有的所有数据来构建模型。我们还可以在模型训练之前检查数据是否包含要处理的任何缺失值。

![img/493063_1_En_4_Chapter/493063_1_En_4_Figc_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Figc_HTML.jpg)

```py
[In]: df.info()
[Out]:

```

由于数据集中的任何列都没有任何缺失值，因此我们可以继续将数据分为定型集和测试集。

```py
[In]: input_columns = [column for column in df.columns if column != 'converted']

[In]: print (input_columns)
[Out]: ['age', 'new_user', 'total_pages_visited']

[In]: output_column = 'converted'
[In]:print (output_column)
[Out]: converted

[In]: X = df.loc[:,input_columns].values
[In]: y = df.loc[:,output_column]
[In]: print (X.shape, y.shape)
[Out]: (316200, 3) (316200,)

[In]: from sklearn.model_selection import train_test_split
[In]: from sklearn.linear_model import LogisticRegression

[In]:X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3, random_state=555, stratify=y)

[In]: print(np.sum(y_train))
[In]: 7140

[In]: print(np.sum(y_test))
[Out]: 3060

```

现在我们已经形成了训练和测试数据集，我们可以继续进行模型训练了。

Note

在理想的 ML 场景中，在模型训练之前建议进行适当的数据探索和特征工程。

![img/493063_1_En_4_Chapter/493063_1_En_4_Figd_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Figd_HTML.jpg)

```py
[In]:logreg=LogisticRegression(class_weight='balanced').fit(X_train,y_train)
[In]: logreg.score(X_test, y_test)
[Out]: 0.93

[In]: predictions=logreg.predict(X_test)

[In]: from sklearn.metrics import confusion_matrix
[In]: from sklearn.metrics import classification_report

[In]:print(classification_report(y_test,predictions,target_names=["Non Converted", "Converted"]))

[Out]:

```

我们可以观察到，模型的整体准确率没有那么差，召回率也不错。根据具体需要，可以进一步提高精度。使用 Docker 运行 ML 的整个过程的第一步到此结束。

### 步骤 2:导出训练好的模型

既然我们已经训练好了模型，我们需要使用 pickle/joblib 保存它，以便在以后的预测中重用它。在本练习中，我们将看到使用 ML 模型的两种预测。

*   单一客户预测

*   群体预测(多个客户)

我们有一个单独的测试数据集，可以预测一组客户，而不仅仅是一个客户。让我们看看当我们使用 Docker 运行应用程序进行预测时，结果是什么样的。

```py
[In]: import pickle
[In]: pickle_out = open("logreg.pkl","wb")
[In]: pickle.dump(logreg, pickle_out)
[In]: pickle_out.close()

```

让我们加载训练好的模型，看看它是否能很好地预测测试数据以及单个客户的值。

```py
[In]: pickle_in = open("logreg.pkl","rb")
[In]: model=pickle.load(pickle_in)

```

下面是对单个客户的预测:

```py
[In]: model.predict([[45,0,5]])[0]
[Out]: 0

```

以下是对一组客户的预测:

```py
[In]: df_test=pd.read_csv('test_data.csv')
[In]: predictions=model.predict(df_test)
[In]: print(list(predictions))
[Out]: [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]

```

正如我们所观察到的，该模型似乎在为单个客户以及一组客户进行预测。现在我们可以进入下一步，构建一个 Flask 应用程序来运行这个模型。

### 步骤 3:创建一个包含 UI 的 Flask 应用程序

在前一章中，我们介绍了如何使用 Flask 框架轻松部署 ML 模型。类似地，在这种情况下，我们将构建一个 Flask 应用程序和 Flasgger。我们首先导入运行 Flask 应用程序所需的库。

```py
[In]: from flask import Flask, request
[In]: import numpy as np
[In]: import pickle
[In]: import pandas as pd
[In]: import flasgger
[In]: from flasgger import Swagger

```

我们创建了 Flask 应用程序，并将其包装在 Swagger 周围。它做了所有繁重的工作来以布局良好的方式表示结果。这可以节省大量编写 HTML 和 CSS 的时间和精力。

```py
[In]: app=Flask(__name__)
[In]: Swagger(app)

```

接下来，我们加载用于预测的训练模型。由于我们将进行两种类型的预测(单个客户和一组客户)，我们将需要使用 get 请求和 post 请求在我们的应用程序中创建两个独立的函数。对于单客户预测，我们将使用 get 请求，因为我们将从用户处获取输入值，而对于组预测，我们将使用 post 请求来发布预测的测试数据集。这里要记住的一件关键事情是向应用程序提供关于模型中使用的要素的参数信息，以正确地进行预测。最后一部分是提供运行这个应用程序的本地主机 IP 地址。

```py
[In]: pickle_in = open("logreg.pkl","rb")
[In]: model=pickle.load(pickle_in)

[In]: @app.route('/predict',methods=["Get"])
[In]: def predict_class():

    """Predict if Customer would buy the product or not.
    ---
    parameters:
      - name: age
        in: query
        type: number
        required: true
      - name: new_user
        in: query
        type: number
        required: true
      - name: total_pages_visited
        in: query
        type: number
        required: true

    responses:
        500:
            description: Prediction

    """
    age=int(request.args.get("age"))
new_user=int(request.args.get("new_user"))
total_pages_visited=int(request.args.get("total_pages_visited"))
    prediction=model.predict([[age,new_user,total_pages_visited]])
print(prediction[0])
return "Model prediction is"+str(prediction)

[In]: @app.route('/predict_file',methods=["POST"])
[In]: def prediction_test_file():

    """Prediction on multiple input test file

.
    ---
    parameters:
      - name: file
        in: formData
        type: file
        required: true

    responses:
        500:
            description: Test file Prediction

    """
df_test=pd.read_csv(request.files.get("file"))
    prediction=model.predict(df_test)

    return str(list(prediction))

[In]: if __name__=='__main__':
            app.run(debug=True,host='0.0.0.0')

```

创建 Flask 应用程序和 UI 层的第 3 步到此结束。我们现在准备进入 Docker 并构建一个映像来运行这个应用程序。

### 步骤 4:构建 Docker 映像

我们现在将创建一个 Docker 文件，并提及使用 Docker 运行此应用程序的所有步骤。我们首先向需要从 Docker Hub 中提取的 Docker 服务器提供基本映像(如果本地还没有)。

```py
FROM continuumio/anaconda3:4.4.0

```

下一步，我们将所有文件和内容从本地目录(我们构建 ML 模型和 Flask 应用程序的地方)复制到 Docker 目录(我们也可以创建一个新的或当前的 Docker 目录)。在这种情况下，我们创建一个名为`usr/ML/app`的新目录。

```py
COPY . /usr/ML/app

```

下一个命令是公开 Docker 的端口 5000 来运行这个应用程序。基本上，当请求来自用户时，主机系统会将这个请求路由到 Docker 的端口 5000，应用程序将在那里运行。我们还必须在主机系统和 Docker 容器之间进行显式端口映射，同时运行容器来正确路由请求和访问预测。

```py
EXPOSE 5000

```

下一个命令是将 Docker 的当前工作目录更改为我们已经从本地系统复制了所有文件的目录(Flask/ML model/data 等。).

```py
WORKDIR /usr/ML/app

```

下一步是安装所有的依赖项和所需的库，以便成功运行应用程序。我们有一个`requirement.txt`文件，其中包含所需的库和版本。

```py
RUN pip install -r requirements.txt

```

Docker 文件中的最后一个命令总是启动命令，在这种情况下，我们希望 Docker 运行我们在上一步中构建的 Flask 应用程序。

```py
CMD python flask_api.py

```

这个命令列表完成了我们的 Docker 文件，现在可以将其转换成 Docker 映像并作为容器运行，这是下一步。

### 步骤 5:运行 Docker 容器

在流程的这一步中，我们从上一步中创建的 Docker 文件构建 Docker 定制映像，并运行容器。我们必须转到终端中所有文件都存在的同一个目录中。在终端中，我们运行`docker build`命令从 Dockerfile 构建 Docker 映像。

```py
[In]: docker build -t ml_app_docker .

```

可以将图像标记为特定的名称，以帮助运行容器。在这种情况下，我们将其标记为`ml_app_docker`。一旦 Docker 映像开始构建，Docker 内部就会发生一系列的步骤。第一步是 Docker 服务器将寻找基本映像。如果基本映像在本地系统中不可用，Docker 服务器会从 Docker Hub 中提取映像，根据映像大小可能需要一些时间。如图 [4-15](#Fig15) 所示，从 Docker Hub 中获取基础映像。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig15_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig15_HTML.jpg)

图 4-15

从 Docker 文件构建 Docker 映像

一旦基本映像被完全提取出来，Docker 就会用该基本映像创建一个临时容器。它是临时容器的原因是 Docker 应用下一步并构建一个新容器来满足下一个需求。如图 [4-16](#Fig16) 所示，我们可以观察到，在每个阶段结束时，Docker 都会向我们显示一个新的容器 ID，在运行 Dockerfile 中的最后一个命令后，它会向我们提供最终的容器 ID。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig16_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig16_HTML.jpg)

图 4-16

Docker 服务器信息

文件`requirements.txt`包含了所有的依赖项和库，因此 Docker 也会安装所有的依赖项和库，如图 [4-17](#Fig17) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig17_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig17_HTML.jpg)

图 4-17

安装依赖项

一旦 docker 文件中的所有命令都被执行，我们就有了从 docker 文件构建的最终图像，如图 [4-18](#Fig18) 所示，我们可以启动容器来运行我们的 ML 应用程序。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig18_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig18_HTML.jpg)

图 4-18

最终 Docker 图像

这里要记住的关键是进行显式端口映射，以便将请求从主机路由到 Docker 端口。我们利用`-p`并将主机端口 5000 映射到 Docker 容器端口 5000。

```py
[In]: docker container run -p 5000:5000 ml_app_docker

[Out]:

```

如图 [4-19](#Fig19) 所示，app 成功启动，一切都在 Docker 容器内运行。要访问该应用程序，我们只需前往`http://localhost://5000/apidocs`加载 Swagger UI 页面，如图 [4-20](#Fig20) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig20_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig20_HTML.jpg)

图 4-20

访问 ml-app 的 Swagger API

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig19_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig19_HTML.jpg)

图 4-19

访问正在运行的 ml-app

应用程序中有两个选项卡。

*   得到

*   邮政

基于 get 请求的预测适用于单客户预测，而 Post 选项卡适用于测试数据预测(客户组)。单击 Get 选项卡后，我们可以看到提供输入参数的选项，需要根据这些参数进行预测。这些参数与我们在模型培训中使用的以及在 Flask 应用程序代码中调用的参数相同。右上角包含一个“试用”选项卡，允许我们填写输入参数的值，如图 [4-21](#Fig21) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig21_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig21_HTML.jpg)

图 4-21

获取请求

我们可以为一个测试客户填写所有三个参数的值，如图 [4-21](#Fig21) 所示，然后点击执行选项卡。在执行调用时，请求会发送到应用程序，然后由模型进行预测。模型预测的结果显示在页面的预测部分。它还提供了访问结果的替代方法，例如使用`curl`命令或 URL，如图 [4-22](#Fig22) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig22_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig22_HTML.jpg)

图 4-22

模型预测法

下一个可以完成的预测是通过 post 请求对一组客户(测试数据)进行预测。我们需要上传如图 [4-23](#Fig23) 所示的包含相同参数的测试数据文件(必须是相似的格式)。模型进行预测，执行后显示结果，如图 [4-24](#Fig24) 所示。

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig24_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig24_HTML.jpg)

图 4-24

多重预测

![img/493063_1_En_4_Chapter/493063_1_En_4_Fig23_HTML.jpg](img/493063_1_En_4_Chapter/493063_1_En_4_Fig23_HTML.jpg)

图 4-23

上传测试数据

### 步骤 6:停止/终止正在运行的容器

运行应用程序后剩下的最后一步是停止正在运行的容器。这可以使用运行容器上的`docker stop`或`kill`命令来完成。我们可以使用`docker ps`命令查看正在运行的容器列表，并可以选择正在运行的容器 ID 来停止它。

```py
[In]: docker ps
[In]:docker kill <Container_ID>

```

## 结论

在这一章中，我们回顾了 Docker 及其生态系统的基础知识。我们还讨论了不同的 Docker 命令以及构建定制 Docker 映像的过程。我们还使用 Docker 部署了一个机器学习应用程序，并将其托管在 Flask 应用程序上。*