# 1.机器学习基础

机器学习可以大致分为监督学习和非监督学习。根据定义，术语“受监督的”意味着“机器”(系统)在某种东西的帮助下学习——通常是有标签的训练数据。

训练数据(或数据集)是系统学习推断的基础。这个过程的一个例子是向系统显示一组猫和狗的图像以及这些图像的相应标签(这些标签表示该图像是猫的还是狗的)，并让系统破译猫和狗的特征。

类似地，无监督学习是将数据分组到相似类别的过程。这样的一个例子是将一组狗和猫的图像输入到系统中，而不提及哪个图像属于哪个类别，并且让系统基于图像的相似性将这两种类型的图像分组到不同的桶中。

在本章中，我们将讨论以下内容:

*   回归和分类的区别
*   培训、验证和测试数据的需求
*   精确度的不同衡量标准

## 回归和分类

让我们假设我们正在预测某个地区在夏季销售的可乐的数量。该值介于某些值之间，比如说每周 100 万到 120 万台。通常，回归是预测这种连续变量的一种方式。

另一方面，分类或预测是对没有明显结果的事件进行预测，例如，一天是晴天还是雨天。

线性回归是预测连续变量的技术的典型例子，而逻辑回归是预测离散变量的典型技术。还有许多其他技术，包括决策树、随机森林、GBM、神经网络等等，可以帮助预测连续和离散的结果。

### 培训和测试数据

典型地，在回归中，我们处理泛化/过度拟合的问题。当模型如此复杂以至于它完美地拟合所有的数据点，导致最小可能的错误率时，过度拟合问题就出现了。过度拟合数据集的典型示例如图 [1-1](#Fig1) 所示。

![A463052_1_En_1_Fig1_HTML.jpg](A463052_1_En_1_Fig1_HTML.jpg)

图 1-1

An overfitted dataset

从图中的数据集，您可以看到直线并不完全符合所有的数据点，而曲线则完全符合这些点，因此曲线在数据点上的误差最小。

但是，与新数据集中的曲线相比，直线更有可能具有更高的概化能力。因此，在实践中，回归/分类是模型的可推广性和模型的复杂性之间的权衡。

模型的概化程度越低，“看不见的”数据点的错误率就越高。

这种现象可以在图 [1-2](#Fig2) 中观察到。随着模型复杂性的增加，看不见的数据点的错误率不断降低，直到某一点，之后它又开始增加。然而，随着模型复杂性的增加，训练数据集的错误率不断降低，最终导致过度拟合。

![A463052_1_En_1_Fig2_HTML.jpg](A463052_1_En_1_Fig2_HTML.jpg)

图 1-2

Error rate in unseen data points

看不见的数据点是不用于训练模型，但用于测试模型的准确性的点，因此被称为测试数据或测试数据。

### 对验证数据集的需求

拥有固定的训练和测试数据集的主要问题是，测试数据集可能与训练数据集非常相似，而新的(未来的)数据集可能与训练数据集不太相似。未来数据集与训练数据集不相似的结果是，未来数据集的模型精度可能非常低。

对问题的直觉通常出现在数据科学竞赛和像 Kaggle ( [`www.kaggle.com`](http://www.kaggle.com) )这样的黑客马拉松中。公共排行榜并不总是与私人排行榜相同。通常，对于测试数据集，竞赛组织者不会告诉用户测试数据集的哪些行属于公共排行榜，哪些属于私人排行榜。本质上，随机选择的测试数据集子集进入公共排行榜，其余的进入私有排行榜。

人们可以将私人排行榜视为用户不知道其准确性的测试数据集，而对于公共排行榜，用户被告知模型的准确性。

潜在的情况是，人们在公共排行榜的基础上过度适应，而私人排行榜可能是略有不同的数据集，不能高度代表公共排行榜的数据集。

问题可以从图 [1-3](#Fig3) 中看出。

![A463052_1_En_1_Fig3_HTML.jpg](A463052_1_En_1_Fig3_HTML.jpg)

图 1-3

The problem illustrated

在这种情况下，您会注意到，在公共排行榜和私人排行榜之间进行比较时，用户从排名 17 下降到排名 47。交叉验证是一种有助于避免这个问题的技术。让我们详细检查一下工作情况。

如果我们只有一个训练和测试数据集，假设模型看不到测试数据集，除非我们有第三个数据集，否则我们将无法提出超参数的组合(超参数可以被认为是一个旋钮，我们可以通过改变它来提高模型的准确性)。验证是第三个数据集，可用于查看超参数改变时模型的准确性。通常，在数据集中 100%的数据点中，60%用于训练，20%用于验证，其余 20%用于测试数据集。

验证数据集的另一个想法是这样的:假设您正在构建一个模型来预测客户是否可能在未来两个月内流失。数据集的大部分将用于训练模型，其余部分可用于测试数据集。但是在我们将在后续章节中讨论的大多数技术中，你会注意到它们涉及到超参数。

随着我们不断改变超参数，模型的精度变化很大，但除非有另一个数据集，否则我们无法确定精度是否在提高。原因如下:

1.  我们不能在训练模型的数据集上测试模型的准确性。
2.  我们不能使用测试数据集精度的结果来最终确定理想的超参数，因为实际上，模型看不到测试数据集。

因此，需要第三个数据集——验证数据集。

### 精确度的测量

在典型的线性回归(预测连续值)中，有几种方法可以测量模型的误差。通常，在测试数据集上测量误差，因为在训练数据集(构建模型的数据集)上测量误差会产生误导，因为模型已经看到了数据点，如果我们只在训练数据集上测试模型的准确性，我们将无法对未来数据集的准确性发表任何意见。这就是为什么总是在不用于构建模型的数据集上测量误差。

#### 绝对误差

绝对误差定义为预测值和实际值之间的差值的绝对值。让我们想象一个如下的场景:

<colgroup><col align="left"> <col align="left"> <col align="left"> <col align="left"> <col align="left"></colgroup> 
|   | 实际价值 | 预报值 | 错误 | 绝对误差 |
| :-- | :-- | :-- | :-- | :-- |
| 数据点 1 | One hundred | One hundred and twenty | Twenty | Twenty |
| 数据点 2 | One hundred | Eighty | –20 | Twenty |
| 全部的 | Two hundred | Two hundred | Zero | Forty |

在这种情况下，我们可能会错误地看到总误差为 0(因为一个误差为+20，另一个误差为–20)。如果我们假设模型的总体误差为 0，我们就忽略了这样一个事实，即该模型在单个数据点上效果不佳。

为了避免正误差和负误差相互抵消从而导致最小误差的问题，我们考虑模型的绝对误差，在这种情况下是 40，绝对误差率是 40 / 200 = 20%

#### 均方根误差

解决误差符号不一致问题的另一种方法是求误差的平方(负数的平方是正数)。上面讨论的场景可以翻译如下:

<colgroup><col align="left"> <col align="left"> <col align="left"> <col align="left"> <col align="left"></colgroup> 
|   | 实际价值 | 预报值 | 错误 | 平方误差 |
| :-- | :-- | :-- | :-- | :-- |
| 数据点 1 | One hundred | One hundred and twenty | Twenty | four hundred |
| 数据点 2 | One hundred | Eighty | –20 | four hundred |
| 全部的 | Two hundred | Two hundred | Zero | eight hundred |

现在总的平方误差是 800，均方根误差(RMSE)是(800 / 2)的平方根，也就是 20。

#### 混淆矩阵

绝对误差和 RMSE 适用于预测连续变量。然而，预测具有离散结果的事件是一个不同的过程。离散事件预测以概率的形式发生-模型的结果是某个事件发生的概率。在这种情况下，尽管理论上可以使用绝对误差和 RMSE，但还有其他相关的度量标准。

混淆矩阵计算模型预测事件结果的实例数量，并将其与实际值进行比较，如下所示:

*   灵敏度或真阳性率或回忆=真阳性/(总阳性)= TP/ (TP + FN)
*   特异性或真阴性率=真阴性/(总阴性)= TN / (FP + TN)
*   精度或正预测值= TP / (TP + FP)
*   召回= TP / (TP+FN)
*   准确度= (TP + TN) / (TP + FN + FP + TN)
*   F1 得分= 2TP/ (2TP + FP + FN)

<colgroup><col align="left"> <col align="left"> <col align="left"></colgroup> 
|   | 预期欺诈 | 预测非欺诈 |
| :-- | :-- | :-- |
| 实际欺诈 | 真阳性(TP) | 假阴性(FN) |
| 实际无欺诈 | 假阳性 | 真阴性(TN) |

### AUC 值和 ROC 曲线

假设您正在为一个运营团队提供咨询，该团队手动审查电子商务交易，以确定它们是否是欺诈。

*   与这一过程相关的成本是审查所有交易所需的人力。
*   与成本相关的好处是，由于人工审查，欺诈性交易的数量被预先阻止。
*   与上述设置相关的总体利润是通过防止欺诈节省的资金减去人工审查的成本。

在这种情况下，模型可以如下派上用场:我们可以提出一个模型，为每项交易打分。每笔交易都根据欺诈的可能性进行评分。这样，所有不太可能是欺诈的交易都不需要由人工审查者进行审查。因此，该模式的好处是减少需要审查的交易数量，从而减少审查交易所需的人力资源，并降低与审查相关的费用。但是，由于一些交易没有经过审查，无论欺诈的可能性有多小，仍然可能有一些欺诈没有被发现，因为一些交易没有经过审查。

在这种情况下，如果模型通过减少要审查的交易(希望是不太可能是欺诈交易的交易)的数量来提高整体利润，那么它可能是有帮助的。

计算曲线下面积(AUC)的步骤如下:

1.  对每笔交易进行评分，以计算欺诈的可能性。(评分基于预测模型——在第 [3](03.html) 章中有更多详细信息。)
2.  按概率降序排列事务。

在有序数据集的顶部应该有非常少的非欺诈数据点，在有序数据集的底部应该有非常少的欺诈数据点。AUC 值因数据集中存在此类异常而受到惩罚。

现在，让我们假设总共有 1，000，000 笔交易需要审查，根据历史记录，平均有 1%的交易是欺诈性的。

*   受试者工作特征(ROC)曲线的 x 轴是考虑的累计点数(交易)。
*   y 轴是捕获的欺诈交易的累计数量。

一旦我们对数据集进行排序，直观上所有的高概率交易都是欺诈交易，低概率交易不是欺诈交易。当我们查看最初的几笔交易时，捕获的欺诈累积数量会增加，在某个点之后，它会饱和，因为交易的进一步增加不会增加欺诈交易。

x 轴上审查的累计交易和 y 轴上捕获的累计欺诈的图表类似于图 [1-4](#Fig4) 。

![A463052_1_En_1_Fig4_HTML.jpg](A463052_1_En_1_Fig4_HTML.jpg)

图 1-4

Cumulative frauds captured when using a model

在这种情况下，我们总共有 1，000，000 笔交易中的 10，000 笔欺诈交易。这是平均 1%的欺诈率，也就是说，每 100 笔交易中就有一笔是欺诈性的。

如果我们没有任何模型，我们的随机猜测会慢慢增加，如图 [1-5](#Fig5) 所示。

![A463052_1_En_1_Fig5_HTML.jpg](A463052_1_En_1_Fig5_HTML.jpg)

图 1-5

Cumulative frauds captured when transactions are randomly sampled

在图 [1-5](#Fig5) 中，可以看到这条线将整个数据集分成了大致相等的两部分——线下的面积等于总面积的 0.5 倍。为方便起见，如果我们假设地块的总面积为 1 个单位，那么由随机猜测模型生成的线下总面积将为 0.5。

基于预测模型和随机猜测捕获的累积欺诈的比较如图 [1-6](#Fig6) 所示。

![A463052_1_En_1_Fig6_HTML.jpg](A463052_1_En_1_Fig6_HTML.jpg)

图 1-6

Comparison of cumulative frauds

注意，在这种情况下，由预测模型产生的曲线下面积(AUC)大于 0.5。

因此，AUC 越高，模型的预测能力越好。

## 无监督学习

到目前为止，我们已经看到了监督学习，其中有一个因变量(我们试图预测的变量)和一个自变量(我们用来预测因变量值的变量)。

然而，在某些情况下，我们只有独立变量——例如，在我们必须根据某些特征对客户进行分组的情况下。在这些情况下，无监督学习技术就派上了用场。

有两种主要类型的无监督技术:

*   基于聚类的方法
*   主成分分析

聚类是对行进行分组的方法，而 PCA 是对列进行分组的方法。我们可以认为聚类有助于将给定的客户分配到一个或另一个组中(因为每个客户通常代表数据集中的一行)，而 PCA 有助于对列进行分组(或者，减少数据的维度/变量)。

尽管聚类有助于细分客户，但它也是我们建模过程中一个强大的预处理步骤(你将在第 [11](11.html) 章中读到更多相关内容)。主成分分析可以通过减少维数来帮助加速模型建立过程，从而减少要估计的参数的数量。

在本书中，我们将讨论大多数监督和非监督算法，如下所示:

1.  我们首先在 Excel 中手工编码它们。
2.  我们在 r 中实现。
3.  我们用 Python 实现。

附录中概述了 Excel、R 和 Python 的基础知识。

## 构建模型的典型方法

在上一节中，我们看到了一个运营团队在真实场景中实施预测模型的成本效益分析场景。在这一节中，我们将探讨在构建预测模型时应该考虑的一些要点。

### 数据是从哪里获取的？

通常，数据在数据库、CSV 或文本文件的表格中可用。在数据库中，不同的表可能捕获不同的信息。例如，为了理解欺诈性交易，我们可能会将交易表与客户人口统计表连接起来，以便从数据中获得洞察力。

### 需要提取哪些数据？

预测练习的输出与进入模型的输入一样好。获得正确输入的关键部分是更好地理解我们试图预测的驱动因素/特征——在我们的案例中，是更好地理解欺诈交易的特征。

在这里，数据科学家通常会戴上管理顾问的帽子。他们研究可能推动他们试图预测的事件的因素。他们可以通过接触一线工作人员(例如，手动审查交易的欺诈风险调查人员)来了解他们在调查交易时关注的关键因素。

### 数据预处理

输入数据并不总是每次都是干净的。在构建模型之前，可能需要处理多个问题:

*   数据中缺少值:当变量(数据点)未被记录时，或者当跨不同表的联接导致不存在的值时，数据中缺少值。缺失值可以通过几种方式进行估算。最简单的方法是用该列的平均值/中值替换缺失值。替换缺失值的另一种方法是基于事务中可用的其余变量添加一些智能。这种方法被称为识别 K-最近邻(更多信息见第 [13](13.html) 章)。
*   数据中的异常值:输入变量中的异常值会导致基于回归技术的低效优化(第[章第 2](02.html) 节详细讨论了异常值的影响)。通常异常值是通过将变量限制在某个百分点值(例如 95%)来处理的。
*   变量转换:可用的变量转换如下:
    *   缩放变量:在基于梯度下降的技术的情况下缩放变量通常会导致更快的优化。
    *   对数/平方变换:对数/平方变换在输入变量与因变量具有非线性关系的情况下非常方便。

### 特征交互

考虑这样一种情况，当一个人是男性并且年龄很小的时候，他在泰坦尼克号上幸存的几率很高。典型的基于回归的技术不会考虑这样的特征交互，而基于树的技术会。特征交互是基于变量组合创建新变量的过程。请注意，通常情况下，通过更好地理解业务(我们试图预测的事件),可以了解特性交互。

### 特征生成

要素生成是从数据集中查找附加要素的过程。例如，用于预测欺诈性交易的特征将是自给定交易的最后一次交易以来的时间。这样的特性不是直接可用的，而只能通过理解我们试图解决的问题来获得。

### 构建模型

一旦数据到位，预处理步骤完成，下一步就是建立预测模型。多种机器学习技术将有助于建立预测模型。关于主要机器学习技术的细节将在其余章节中探讨。

### 生产模型

一旦最终的模型就位，模型的生产就因用例而异。例如，数据科学家可以进行离线分析，查看客户的历史购买记录，并得出一个产品列表，通过电子邮件发送给特定客户，作为推荐。在另一种情况下，在线推荐系统实时工作，数据科学家可能必须将模型提供给数据工程师，然后数据工程师在生产中实现该模型，以实时生成推荐。

### 构建、部署、测试和迭代

总的来说，建立一个模型不是一次性的工作。你需要展示从前一个流程转移到一个新流程的价值。在这样的场景中，您通常会遵循 A/B 测试或测试/控制方法，在这种方法中，模型仅针对全部可能的事务/客户中的一小部分进行部署。然后将这两个组进行比较，以查看模型的部署是否确实导致了企业想要实现的度量的改进。一旦模型显示出前景，它就扩展到更多的总可能交易/客户。一旦达成共识，认为该模型是有前途的，它被接受为最终解决方案。否则，数据科学家会使用来自之前 A/B 测试实验的新信息进行重复。

## 摘要

在这一章中，我们研究了机器学习的基本术语。我们还讨论了在评估模型时可以使用的各种误差度量。我们讨论了利用机器学习算法解决业务问题的各个步骤。