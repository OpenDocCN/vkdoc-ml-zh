# 9.卷积神经网络

在第 [7](07.html) 章中，我们看了一个传统的神经网络(NN)。传统神经网络的局限性之一是它不是平移不变的，也就是说，图像右上角的猫图像与图像中心有猫的图像的处理方式不同。卷积神经网络(CNN)被用来处理这样的问题。

鉴于 CNN 可以处理图像中的转换，它被认为更有用，并且 CNN 架构事实上是当前对象分类/检测中最先进的技术之一。

在本章中，您将学习以下内容:

*   CNN 的工作细节
*   CNN 如何克服神经网络的缺点
*   卷积和池对解决图像翻译问题的影响
*   如何用 Python 实现 CNN，以及 R

为了进一步更好地理解 CNN 的必要性，让我们从一个例子开始。比方说，我们想对一幅图像中是否有垂直线进行分类(也许是为了判断该图像是否代表 1)。为了简单起见，我们假设图像是 5 × 5 的图像。书写垂直线(或 1)的几种方法如下:

![A463052_1_En_9_Figa_HTML.png](A463052_1_En_9_Figa_HTML.png)

我们还可以检查数字 1 在 MNIST 数据集中的不同书写方式。图 [9-1](#Fig1) 中显示了一个为写入的 1 突出显示的像素图像。

![A463052_1_En_9_Fig1_HTML.jpg](A463052_1_En_9_Fig1_HTML.jpg)

图 9-1

Image of pixels corresponding to images with label 1

在图像中，像素越红，越经常有人在上面写字；越蓝意味着像素被写入的次数越少。中间的像素是最红的，很可能是因为大多数人会在那个像素上写字，不管他们用来写 1 的角度是什么——垂直线还是向左或向右倾斜。在下一节中，您会注意到，当图像平移几个单位时，神经网络预测不准确。在后面的章节中，我们将了解 CNN 如何解决图像翻译的问题。

## 传统神经网络的问题是

在刚才提到的场景中，只有当中间周围的像素被高亮显示而图像中的其余像素没有被高亮显示时，传统的神经网络才会将图像高亮显示为 1(因为大多数人都高亮显示了中间的像素)。

为了更好地理解这个问题，让我们来看一下我们在第 [7](07.html) 章中看过的代码(在 github 中代码可以作为“传统 NN.ipynb 的问题”获得):

![A463052_1_En_9_Figc_HTML.jpg](A463052_1_En_9_Figc_HTML.jpg)

1.  Download the dataset and extract the train and test datasets:

    ![A463052_1_En_9_Figb_HTML.jpg](A463052_1_En_9_Figb_HTML.jpg)

    ```
    from keras.datasets import mnist
    import matplotlib.pyplot as plt
    %matplotlib inline
    # load (downloaded if needed) the MNIST dataset
    (X_train, y_train), (X_test, y_test) = mnist.load_data()
    # plot 4 images as gray scale
    plt.subplot(221)
    plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))
    plt.subplot(222)
    plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))
    plt.subplot(223)
    plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))
    plt.subplot(224)
    plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))
    # show the plot
    plt.show()

    ```

2.  导入相关包:

    ```
    import numpy as np
    from keras.datasets import mnist
    from keras.models import Sequential
    from keras.layers import Dense
    from keras.layers import Dropout
    from keras.layers import Flatten
    from keras.layers.convolutional import Conv2D
    from keras.layers.convolutional import MaxPooling2D
    from keras.utils import np_utils
    from keras import backend as K

    ```

3.  只取标签 1 对应的训练集:

    ```
    X_train1 = X_train[y_train==1]

    ```

4.  对数据集进行整形和归一化:

    ```
    num_pixels = X_train.shape[1] * X_train.shape[2]
    X_train = X_train.reshape(X_train.shape[0],num_pixels ).astype('float32')
    X_test = X_test.reshape(X_test.shape[0],num_pixels).astype('float32')

    X_train = X_train / 255
    X_test = X_test / 255

    ```

5.  一次热编码标签:

    ```
    y_train = np_utils.to_categorical(y_train)
    y_test = np_utils.to_categorical(y_test)
    num_classes = y_train.shape[1]

    ```

6.  构建模型并运行:

    ```
    model = Sequential()
    model.add(Dense(1000, input_dim=num_pixels, activation="relu"))
    model.add(Dense(num_classes, activation="softmax"))
    model.compile(loss='categorical_crossentropy', optimizer="adam", metrics=[''accuracy'])
    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=1024, verbose=1)

    ```

让我们画出平均 1 个标签的样子:

```
pic=np.zeros((28,28))
pic2=np.copy(pic)
for i in range(X_train1.shape[0]):
  pic2=X_train1[i,:,:]
  pic=pic+pic2
pic=(pic/X_train1.shape[0])
plt.imshow(pic)

```

图 [9-2](#Fig2) 显示结果。

![A463052_1_En_9_Fig2_HTML.jpg](A463052_1_En_9_Fig2_HTML.jpg)

图 9-2

Average 1 image

### 场景 1

在这种情况下，创建了一个新图像(图 [9-3](#Fig3) ，其中原始图像向左平移了 1 个像素:

![A463052_1_En_9_Fig3_HTML.jpg](A463052_1_En_9_Fig3_HTML.jpg)

图 9-3

Average 1 image translated by 1 pixel to the left

```
for i in range(pic.shape[0]):
  if i<20:
    pic[:,i]=pic[:,i+1]
plt.imshow(pic)

```

让我们继续使用构建的模型预测图 [9-3](#Fig3) 中图像的标签:

![A463052_1_En_9_Figd_HTML.jpg](A463052_1_En_9_Figd_HTML.jpg)

```
model.predict(pic.reshape(1,784))

```

我们将错误的预测 8 视为输出。

### 场景 2

创建了一个新图像(图 [9-4](#Fig4) )，其中的像素不是从原始平均 1 图像转换而来的:

![A463052_1_En_9_Fig4_HTML.jpg](A463052_1_En_9_Fig4_HTML.jpg)

图 9-4

Average 1 image

```
pic=np.zeros((28,28))
pic2=np.copy(pic)
for i in range(X_train1.shape[0]):
  pic2=X_train1[i,:,:]
  pic=pic+pic2
pic=(pic/X_train1.shape[0])
plt.imshow(pic)

```

该图像的预测如下:

![A463052_1_En_9_Fige_HTML.jpg](A463052_1_En_9_Fige_HTML.jpg)

```
model.predict(pic.reshape(1,784))

```

我们看到输出为 1 的正确预测。

### 场景 3

创建新图像(图 [9-5](#Fig5) )，其中原始平均 1 图像的像素向右移动 1 个像素:

![A463052_1_En_9_Fig5_HTML.jpg](A463052_1_En_9_Fig5_HTML.jpg)

图 9-5

Average 1 image translated by 1 pixel to the right

```
pic=np.zeros((28,28))
pic2=np.copy(pic)
for i in range(X_train1.shape[0]):
  pic2=X_train1[i,:,:]
  pic=pic+pic2
pic=(pic/X_train1.shape[0])
pic2=np.copy(pic)
for i in range(pic.shape[0]):
  if ((i>6) and (i<26)):
    pic[:,i]=pic2[:,(i-1)]
plt.imshow(pic)

```

让我们继续使用构建的模型预测上面图像的标签:

![A463052_1_En_9_Figf_HTML.jpg](A463052_1_En_9_Figf_HTML.jpg)

```
model.predict(pic.reshape(1,784))

```

我们有一个输出为 1 的正确预测。

### 场景 4

创建新图像(图 [9-6](#Fig6) )，其中原始平均 1 图像的像素向右移动 2 个像素:

![A463052_1_En_9_Fig6_HTML.jpg](A463052_1_En_9_Fig6_HTML.jpg)

图 9-6

Average 1 image translated by 2 pixels to the right

```
pic=np.zeros((28,28))
pic2=np.copy(pic)
for i in range(X_train1.shape[0]):
  pic2=X_train1[i,:,:]
  pic=pic+pic2
pic=(pic/X_train1.shape[0])
pic2=np.copy(pic)
for i in range(pic.shape[0]):
  if ((i>6) and (i<26)):
    pic[:,i]=pic2[:,(i-2)]
plt.imshow(pic)

```

我们将使用构建的模型预测图像的标签:

![A463052_1_En_9_Figg_HTML.jpg](A463052_1_En_9_Figg_HTML.jpg)

```
model.predict(pic.reshape(1,784))

```

我们看到一个错误的预测 3 作为输出。

从前面的场景中，您可以看到传统的神经网络在数据转换时无法产生良好的结果。这些场景需要不同的网络处理方式来解决翻译差异。这就是卷积神经网络(CNN)派上用场的地方。

## 理解 CNN 中的卷积

你已经对典型的神经网络的工作原理有了很好的了解。在这一节，我们来探讨一下 CNN 中卷积这个词是什么意思。卷积是两个矩阵之间的乘法，其中一个矩阵较大，另一个较小。

要查看卷积，请考虑以下示例。

矩阵 A 如下:

![A463052_1_En_9_Figh_HTML.png](A463052_1_En_9_Figh_HTML.png)

矩阵 B 如下:

![A463052_1_En_9_Figi_HTML.png](A463052_1_En_9_Figi_HTML.png)

在执行卷积时，可以把它想象成在较大矩阵上滑动较小矩阵:当较小矩阵在较大矩阵的整个区域上滑动时，我们可能会得到 9 个这样的乘法。注意，它不是矩阵乘法:

1.  较大矩阵的{1，2，5，6}乘以较小矩阵的{1，2，3，4}。1 × 1 + 2 × 2 + 5 × 3 + 6 × 4 = 44
2.  较大矩阵的{2，3，6，7}乘以较小矩阵的{1，2，3，4 }:2×1+3×2+6×3+7×4 = 54
3.  较大矩阵的{3，4，7，8}乘以较小矩阵的{1，2，3，4 }:3×1+4×2+7×3+8×4 = 64
4.  较大矩阵的{5，6，9，10}乘以较小矩阵的{1，2，3，4 }:5×1+6×2+9×3+10×4 = 84
5.  较大矩阵的{6，7，10，11}乘以较小矩阵的{1，2，3，4 }:6×1+7×2+10×3+11×4 = 94
6.  较大矩阵的{7，8，11，12}乘以较小矩阵的{1，2，3，4 }:7×1+8×2+11×3+12×4 = 104
7.  较大矩阵的{9，10，13，14}乘以较小矩阵的{1，2，3，4 }:9×1+10×2+13×3+14×4 = 124
8.  较大矩阵的{10，11，14，15}乘以较小矩阵的{1，2，3，4 }:10×1+11×2+14×3+15×4 = 134
9.  较大矩阵的{11，12，15，16}乘以较小矩阵的{1，2，3，4 }:11×1+12×2+15×3+16×4 = 144

前面步骤的结果将是一个矩阵，如下所示:

![A463052_1_En_9_Figj_HTML.png](A463052_1_En_9_Figj_HTML.png)

按照惯例，较小的矩阵被称为滤波器或内核，并且较小的矩阵值是通过梯度下降(稍后将详细介绍梯度下降)在统计上得到的。过滤器内的值可以被认为是成分权重。

### 从卷积到激活

在传统的神经网络中，隐藏层不仅将输入值乘以权重，还将非线性应用于数据—它通过激活函数传递值。类似的活动也发生在典型的 CNN 中，卷积通过激活函数传递。CNN 支持我们目前看到的传统激活函数:sigmoid，ReLU，Tanh。

对于前面的输出，请注意，当通过 ReLU 激活函数时，输出保持不变，因为所有的数字都是正数。

### 从卷积激活到池化

到目前为止，我们已经了解了卷积是如何工作的。在本节中，我们将考虑卷积后的下一个典型步骤:池化。

假设卷积步骤的输出如下(我们不考虑前面的例子，这是一个说明池的新例子，基本原理将在后面的部分解释):

![A463052_1_En_9_Figk_HTML.jpg](A463052_1_En_9_Figk_HTML.jpg)

在这种情况下，卷积步骤的输出是一个 2 × 2 矩阵。最大池考虑 2 × 2 块并给出最大值作为输出，同样，如果卷积步骤的输出是一个更大的矩阵，如下所示:

![A463052_1_En_9_Figl_HTML.jpg](A463052_1_En_9_Figl_HTML.jpg)

最大池将大矩阵分成大小为 2 × 2 的非重叠块，如下所示:

![A463052_1_En_9_Figm_HTML.jpg](A463052_1_En_9_Figm_HTML.jpg)

从每个块中，只选择具有最高值的元素。因此，对前面矩阵的最大池化操作的输出如下:

![A463052_1_En_9_Fign_HTML.jpg](A463052_1_En_9_Fign_HTML.jpg)

注意，实际上，没有必要总是使用 2 × 2 滤波器。

涉及的其他类型的池是总和和平均。同样，在实践中，与其他类型的池相比，我们看到了很多最大池。

### 卷积和池化有什么帮助？

在我们之前看到的 MNIST 例子中，传统神经网络的缺点之一是每个像素都与不同的权重相关联。因此，如果除了原始像素之外的相邻像素变得高亮，输出将不会非常准确(场景 1 的示例，其中 1 稍微位于中间的左侧)。

现在解决这种情况，因为像素共享在每个滤波器内构成的权重。所有像素乘以构成过滤器的所有权重，并且在汇集层中，仅选择被激活最高的值。这样，无论高亮显示的像素是在中心还是稍微远离中心，输出通常都不是预期值。然而，当突出显示的像素远离中心时，问题仍然存在。

## 用代码创建 CNN

从前面的传统神经网络场景中，我们看到，如果像素向左平移 1 个单位，神经网络将不起作用。实际上，我们可以认为卷积步骤是识别模式的步骤，合并步骤是导致翻译差异的步骤。

N 个汇集步骤导致至少 N 个单位的平移不变性。考虑下面的例子，我们在卷积后应用一个池化步骤(代码在 github 中作为“使用 CNN.ipynb 的改进”提供):

1.  Import and reshape the data to fit a CNN:

    ![A463052_1_En_9_Figo_HTML.jpg](A463052_1_En_9_Figo_HTML.jpg)

    ```
    (X_train, y_train), (X_test, y_test) = mnist.load_data()
    X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[1],1 ).astype('float32')
    X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[1],1).astype('float32')

    X_train = X_train / 255
    X_test = X_test / 255

    y_train = np_utils.to_categorical(y_train)
    y_test = np_utils.to_categorical(y_test)
    num_classes = y_test.shape[1]
    Step 2: Build a model
    model = Sequential()
    model.add(Conv2D(10, (3,3), input_shape=(28, 28,1), activation="relu"))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(1000, activation="relu"))
    model.add(Dense(num_classes, activation="softmax"))
    model.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy'])
    model.summary()

    ```

2.  Fit the model:

    ![A463052_1_En_9_Figp_HTML.jpg](A463052_1_En_9_Figp_HTML.jpg)

    ```
    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=1024, verbose=1)

    ```

对于前一个卷积，其中一个卷积后跟一个池层，如果像素向左或向右平移 1 个单位，则输出预测效果良好，但当像素平移超过 1 个单位时，输出预测效果不佳(图 [9-7](#Fig7) ):

![A463052_1_En_9_Fig7_HTML.jpg](A463052_1_En_9_Fig7_HTML.jpg)

图 9-7

Average 1 image translated by 1 pixel to the left

```
pic=np.zeros((28,28))
pic2=np.copy(pic)
for i in range(X_train1.shape[0]):
  pic2=X_train1[i,:,:]
  pic=pic+pic2
pic=(pic/X_train1.shape[0])
for i in range(pic.shape[0]):
  if i<20:
    pic[:,i]=pic[:,i+1]
plt.imshow(pic)

```

让我们继续预测图 [9-7](#Fig7) 的标签:

![A463052_1_En_9_Figq_HTML.jpg](A463052_1_En_9_Figq_HTML.jpg)

```
model.predict(pic.reshape(1,28,28,1))

```

我们看到输出为 1 的正确预测。

在下一个场景中(图 [9-8](#Fig8) ，我们将像素向左移动 2 个单位:

![A463052_1_En_9_Fig8_HTML.jpg](A463052_1_En_9_Fig8_HTML.jpg)

图 9-8

Average 1 image translated by 2 pixels to the left

```
pic=np.zeros((28,28))
pic2=np.copy(pic)
for i in range(X_train1.shape[0]):
  pic2=X_train1[i,:,:]
  pic=pic+pic2
pic=(pic/X_train1.shape[0])
for i in range(pic.shape[0]):
  if i<20:
    pic[:,i]=pic[:,i+2]
plt.imshow(pic)

```

让我们根据之前构建的 CNN 模型来预测图 [9-8](#Fig8) 的标签:

![A463052_1_En_9_Figr_HTML.jpg](A463052_1_En_9_Figr_HTML.jpg)

```
model.predict(pic.reshape(1,28,28,1))

```

当图像向左平移 2 个像素时，我们有不正确的预测。

请注意，当模型中卷积池层的数量与图像中的平移量相同时，预测是正确的。但是，如果与图像中的转换相比，卷积池层较少，则预测更有可能不正确。

## CNN 的工作细节

让我们用 Python 构建 toy CNN 代码，然后在 Excel 中实现输出，这样可以加强我们的理解(代码在 github 中以“CNN simple example.ipynb”的形式提供):

1.  导入相关包:

    ```
    # import relevant packages
    from keras.datasets import mnist
    import matplotlib.pyplot as plt
    %matplotlib inline
    import numpy as np
    from keras.datasets import mnist
    from keras.models import Sequential
    from keras.layers import Dense
    from keras.layers import Dropout
    from keras.utils import np_utils
    from keras.layers import Flatten
    from keras.layers.convolutional import Conv2D
    from keras.layers.convolutional import MaxPooling2D
    from keras.utils import np_utils
    from keras import backend as K
    from keras import regularizers

    ```

2.  创建一个简单的数据集:

    ```
    # Create a simple dataset
    X_train=np.array([[[1,2,3,4],[2,3,4,5],[5,6,7,8],[1,3,4,5]],[[-1,2,3,-4],[2,-3,4,5],[-5,6,-7,8],[-1,-3,-4,-5]]])
    y_train=np.array([0,1])

    ```

3.  通过将每个值除以数据集中的最大值来归一化输入:

    ```
    X_train = X_train / 8

    ```

4.  对输出进行一次热编码:

    ```
    y_train = np_utils.to_categorical(y_train)

    ```

5.  一旦只有两个大小为 4 × 4 的输入和两个输出的简单数据集就绪，让我们首先将输入整形为所需的格式(即:样本数、图像高度、图像宽度、图像通道数):

    ```
    X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[1],1 ).astype('float32')

    ```

6.  Build a model:

    ![A463052_1_En_9_Figs_HTML.jpg](A463052_1_En_9_Figs_HTML.jpg)

    ```
    model = Sequential()
    model.add(Conv2D(1, (3,3), input_shape=(4,4,1), activation="relu"))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(10, activation="relu"))
    model.add(Dense(2, activation="softmax"))
    model.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy'])
    model.summary()

    ```

7.  Fit the model:

    ![A463052_1_En_9_Figt_HTML.jpg](A463052_1_En_9_Figt_HTML.jpg)

    ```
    model.fit(X_train, y_train, epochs=100, batch_size=2, verbose=1)

    ```

上述模型的各层如下:

![A463052_1_En_9_Figu_HTML.jpg](A463052_1_En_9_Figu_HTML.jpg)

```
model.layers

```

各层对应的名称和形状如下:

![A463052_1_En_9_Figv_HTML.jpg](A463052_1_En_9_Figv_HTML.jpg)

```
names = [weight.name for layer in model.layers for weight in layer.weights]
weights = model.get_weights()

for name, weight in zip(names, weights):
    print(name, weight.shape)

```

对应于给定层的权重可以提取如下:

![A463052_1_En_9_Figw_HTML.jpg](A463052_1_En_9_Figw_HTML.jpg)

```
model.layers[0].get_weights()

```

第一个输入的预测可以计算如下:

![A463052_1_En_9_Figx_HTML.jpg](A463052_1_En_9_Figx_HTML.jpg)

```
model.predict(X_train[0].reshape(1,4,4,1))

```

现在我们知道前面预测的概率为 0 是 0.89066，让我们通过在 Excel 中匹配前面的预测(在 github 中作为“CNN simple example.xlsx”提供)来验证我们对 CNN 的直觉。

第一个输入及其相应的缩放版本，以及卷积权重和偏差(来自模型)，如下所示:

![A463052_1_En_9_Figy_HTML.jpg](A463052_1_En_9_Figy_HTML.jpg)

卷积的输出如下(请检查“CNN simple example.xlsx”文件中 L4 至 M5 的单元格):

![A463052_1_En_9_Figz_HTML.jpg](A463052_1_En_9_Figz_HTML.jpg)

卷积的计算按照以下公式:

![A463052_1_En_9_Figaa_HTML.jpg](A463052_1_En_9_Figaa_HTML.jpg)

在卷积层之后，我们如下执行最大池化:

![A463052_1_En_9_Figab_HTML.jpg](A463052_1_En_9_Figab_HTML.jpg)

一旦执行了池化，所有的输出都是扁平的(按照我们模型中的规范)。然而，假设我们的池层只有一个输出，扁平化也会产生一个输出。

在下一步中，展平的层连接到隐藏的密集层(在我们的模型规范中有 10 个神经元)。对应于每个神经元的权重和偏差如下:

![A463052_1_En_9_Figac_HTML.jpg](A463052_1_En_9_Figac_HTML.jpg)

矩阵乘法和乘法后的 ReLU 激活如下:

![A463052_1_En_9_Figad_HTML.jpg](A463052_1_En_9_Figad_HTML.jpg)

上述输出的公式如下:

![A463052_1_En_9_Figae_HTML.jpg](A463052_1_En_9_Figae_HTML.jpg)

现在让我们看看从隐藏层到输出层的计算。请注意，每个输入有两个输出(每行的输出在维度上有两列:概率为 0 和概率为 1)。从隐藏层到输出层的权重如下:

![A463052_1_En_9_Figaf_HTML.jpg](A463052_1_En_9_Figaf_HTML.jpg)

现在，每个神经元都连接到两个权重(其中每个权重都将其连接到两个输出)，让我们看看从隐藏层到输出层的计算:

![A463052_1_En_9_Figag_HTML.jpg](A463052_1_En_9_Figag_HTML.jpg)

输出层的计算如下:

![A463052_1_En_9_Figah_HTML.jpg](A463052_1_En_9_Figah_HTML.jpg)

现在我们有了一些输出值，让我们来计算输出的 softmax 部分:

![A463052_1_En_9_Figai_HTML.jpg](A463052_1_En_9_Figai_HTML.jpg)

现在，输出将与我们在 keras 模型的输出中看到的完全相同:

![A463052_1_En_9_Figaj_HTML.jpg](A463052_1_En_9_Figaj_HTML.jpg)

因此，我们对前面章节中的直觉进行了验证。

## 深入研究卷积/内核

为了了解内核/过滤器是如何帮助我们的，让我们来看另一个场景。从 MNIST 数据集，让我们以这样的方式修改目标，即我们只对预测图像是 1 还是不是 1 感兴趣:

```
(X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[1],1 ).astype('float32')
X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[1],1).astype('float32')

X_train = X_train / 255
X_test = X_test / 255

X_train1 = X_train[y_train==1]

y_train = np.where(y_train==1,1,0)
y_test = np.where(y_test==1,1,0)
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)
num_classes = y_test.shape[1]

```

我们将提出一个简单的 CNN，其中只有两个卷积滤波器:

![A463052_1_En_9_Figak_HTML.jpg](A463052_1_En_9_Figak_HTML.jpg)

```
model = Sequential()
model.add(Conv2D(2, (3,3), input_shape=(28, 28,1), activation="relu"))
model.add(Flatten())
model.add(Dense(1000, activation="relu"))
model.add(Dense(num_classes, activation="softmax"))
model.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy'])
model.summary()

```

现在，我们将继续运行模型，如下所示:

![A463052_1_En_9_Figal_HTML.jpg](A463052_1_En_9_Figal_HTML.jpg)

```
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=1024, verbose=1)

```

我们可以通过以下方式提取对应于滤波器的权重:

```
model.layers[0].get_weights()

```

让我们使用上一步中获得的权重手动卷积并应用激活(图 [9-9](#Fig9) ):

![A463052_1_En_9_Fig9_HTML.jpg](A463052_1_En_9_Fig9_HTML.jpg)

图 9-9

Average filter activations when 1 label images are passed

```
from scipy import signal
from scipy import misc
import numpy as np
import pylab
for j in range(2):
    gradd=np.zeros((30,30))
    for i in range(6000):
        grad = signal.convolve2d(X_train1[i,:,:,0], model.layers[0].get_weights()[0].T[j][0])+model.layers[0].get_weights()[1][j]
        grad = np.where(grad<0,0,grad)
        gradd=grad+gradd
    grad2=np.where(gradd<0,0,gradd)
    pylab.imshow(grad2/6000)
    pylab.gray()
    pylab.show()

```

在图中，请注意左边的滤镜比右边的滤镜更能激活 1 图像。本质上，第一个过滤器有助于预测更多的标签 1，而第二个过滤器增强了对其余标签的预测。

## 从卷积和汇集到扁平化:全连接层

到目前为止，我们看到的输出是图像。在传统的神经网络中，我们将每个像素视为一个独立的变量。这正是我们将要在展平过程中执行的操作。

图像的每个像素都是展开的，因此这个过程被称为展平。例如，卷积和合并后的输出图像如下所示:

![A463052_1_En_9_Figam_HTML.jpg](A463052_1_En_9_Figam_HTML.jpg)

展平的输出如下所示:

![A463052_1_En_9_Figan_HTML.jpg](A463052_1_En_9_Figan_HTML.jpg)

### 从一个完全连接的层到另一个

在典型的神经网络中，输入层连接到隐藏层。以类似的方式，在 CNN 中，全连接层连接到通常具有更多单元的另一个全连接层。

### 从全连接层到输出层

与传统的神经网络架构类似，隐藏层连接到输出层，并通过 sigmoid 激活来获得作为概率的输出。根据要解决的问题，还选择了适当的损失函数。

## 连接点:前馈网络

以下是我们到目前为止所执行的步骤的回顾:

1.  盘旋
2.  联营
3.  变平
4.  隐蔽层
5.  计算输出概率

典型的 CNN 外观如图 [9-10](#Fig10) 所示(最著名的——以发明人自己开发的 LeNet 为例):

图 [9-10](#Fig10) 中的子样本相当于我们之前看到的最大池步骤。

## CNN 的其他细节

在图 [9-10](#Fig10) 中，我们看到 conv1 步骤有六个通道或原始图像的卷积。让我们详细看看这个:

1.  假设我们有一个 28 × 28 的灰度图像。六个大小为 3 × 3 的过滤器将生成大小为 26 × 26 的图像。因此，我们只剩下六幅大小为 26 × 26 的图像。
2.  典型的彩色图像有三个通道(RGB)。为了简单起见，我们可以假设第一步中的输出图像有六个通道——六个滤镜一个通道(尽管我们不能像三通道版本那样将它们命名为 RGB)。在这一步中，我们将分别对六个通道中的每一个通道执行最大池化。这将产生六个尺寸为 13 × 13 的图像(通道)。
3.  在下一个卷积步骤中，我们将 13 × 13 图像的六个通道乘以维度为 3 × 3 × 6 的权重。这是一个在三维图像上卷积的三维权重矩阵(其中图像的尺寸为 13 × 13 × 6)。这将导致每个滤波器的图像尺寸为 11 × 11。假设我们已经考虑了十种不同的权重矩阵(准确地说是立方体)。这将产生尺寸为 11 × 11 × 10 的图像。
4.  每个 11 × 11 图像(数量为 10)的最大池将产生一个 5 × 5 的图像。请注意，当对具有奇数维的图像执行最大池化时，池化会产生向下舍入的图像，也就是说，11/2 向下舍入为 5。

![A463052_1_En_9_Fig10_HTML.png](A463052_1_En_9_Fig10_HTML.png)

图 9-10

A LeNet

跨距是对原始图像进行卷积的滤波器从一个步骤移动到下一个步骤的量。例如，如果跨距值为 2，则两个连续卷积之间的距离为 2 个像素。当跨距值为 2 时，乘法将如下进行，其中 A 是较大的矩阵，B 是滤波器:

![A463052_1_En_9_Figao_HTML.jpg](A463052_1_En_9_Figao_HTML.jpg)

第一个卷积将介于:

![A463052_1_En_9_Figap_HTML.jpg](A463052_1_En_9_Figap_HTML.jpg)

第二个卷积将介于:

![A463052_1_En_9_Figaq_HTML.png](A463052_1_En_9_Figaq_HTML.png)

第三个卷积将介于:

![A463052_1_En_9_Figar_HTML.png](A463052_1_En_9_Figar_HTML.png)

最终卷积将在以下两者之间:

![A463052_1_En_9_Figas_HTML.png](A463052_1_En_9_Figas_HTML.png)

注意，对于这里给定维数的矩阵，当步长为 2 时，卷积的输出是 2 × 2 矩阵。

Padding

请注意，当在图像上执行卷积时，结果图像的大小会减小。解决尺寸缩小问题的一种方法是在原始图像的四个边框上填充零。这样，28 × 28 的图像将被转换成 30 × 30 的图像。因此，当 30 × 30 图像通过 3 × 3 滤波器进行卷积时，结果图像将是 28 × 28 图像。

## CNN 中的反向传播

CNN 中的反向传播以类似于典型 NN 的方式进行，其中计算少量改变权重对总权重的影响。但是在 NN 中，我们用权重的过滤器/矩阵来代替权重，这些过滤器/矩阵需要更新以最小化总损失。

有时，假设 CNN 中通常有数百万个参数，进行正则化会有所帮助。CNN 中的正则化可以使用丢弃方法或 L1 和 L2 正则化来实现。通过选择不更新某些权重(通常是随机选择的总权重的 20%)并在整个数量的时期内训练整个网络来完成丢弃。

## 把所有的放在一起

以下代码实现了一个三卷积池层，然后是展平和一个完全连接的层:

```
 (X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[1],1 ).astype('float32')
X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[1],1).astype('float32')

X_train = X_train / 255
X_test = X_test / 255

y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)
num_classes = y_test.shape[1]

```

在下一步中，我们构建模型，如下所示:

![A463052_1_En_9_Figat_HTML.jpg](A463052_1_En_9_Figat_HTML.jpg)

```
model = Sequential()
model.add(Conv2D(32, (3,3), input_shape=(28, 28,1), activation="relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, (3,3), activation="relu"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(1000, activation="relu"))
model.add(Dense(num_classes, activation="softmax"))
model.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy'])
model.summary()

```

最后，我们拟合模型，如下所示:

```
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=1024, verbose=1)

```

请注意，使用前面的代码训练的模型的准确性约为 98.8%。但是请注意，尽管该模型在测试数据集上工作得最好，但是从测试 MNIST 数据集平移或旋转的影像将不会被正确分类(通常，CNN 只能在影像按照卷积池层数平移时提供帮助)。这可以通过查看预测来验证，此时平均 1 幅图像向左平移 2 个像素一次，在另一种情况下，向左平移 3 个像素，如下所示:

![A463052_1_En_9_Figau_HTML.jpg](A463052_1_En_9_Figau_HTML.jpg)

```
pic=np.zeros((28,28))
pic2=np.copy(pic)
for i in range(X_train1.shape[0]):
  pic2=X_train1[i,:,:,0]
  pic=pic+pic2
pic=(pic/X_train1.shape[0])
for i in range(pic.shape[0]):
  if i<20:
    pic[:,i]=pic[:,i+2]
model.predict(pic.reshape(1,28,28,1))

```

请注意，在这种情况下，图像向左平移 2 个单位，预测是准确的:

![A463052_1_En_9_Figav_HTML.jpg](A463052_1_En_9_Figav_HTML.jpg)

```
pic=np.zeros((28,28))
pic2=np.copy(pic)
for i in range(X_train1.shape[0]):
  pic2=X_train1[i,:,:,0]
  pic=pic+pic2
pic=(pic/X_train1.shape[0])
for i in range(pic.shape[0]):
  if i<20:
    pic[:,i]=pic[:,i+3]
model.predict(pic.reshape(1,28,28,1))

```

请注意，在这里，当图像平移的像素比卷积池层多时，预测不准确。这个问题可以通过使用数据扩充来解决，这是下一节的主题。

## 日期增加

从技术上讲，翻译后的图像与从原始图像生成的新图像是一样的。可以使用 keras 中的`ImageDataGenerator`功能生成新数据:

```
from keras.preprocessing.image import ImageDataGenerator
shift=0.2
datagen = ImageDataGenerator(width_shift_range=shift)
datagen.fit(X_train)
i=0
for X_batch,y_batch in datagen.flow(X_train,y_train,batch_size=100):
  i=i+1
  print(i)
  if(i>500):
    break
  X_train=np.append(X_train,X_batch,axis=0)
  y_train=np.append(y_train,y_batch,axis=0)
print(X_train.shape)

```

根据这段代码，我们从原始数据中生成了 50，000 次随机洗牌，其中像素被洗牌 20%。

当我们现在绘制 1 的图像时(图 [9-11](#Fig11) )，请注意图像有一个更宽的分布:

![A463052_1_En_9_Fig11_HTML.jpg](A463052_1_En_9_Fig11_HTML.jpg)

图 9-11

Average 1 post data augmentation

```
y_train1=np.argmax(y_train,axis=1)
X_train1=X_train[y_train1==1]
pic=np.zeros((28,28))
pic2=np.copy(pic)
for i in range(X_train1.shape[0]):
  pic2=X_train1[i,:,:,0]
  pic=pic+pic2
pic=(pic/X_train1.shape[0])
plt.imshow(pic)

```

现在，即使我们不对中心左侧或右侧的几个像素进行卷积合并，预测也会起作用。但是，对于远离中心的像素，一旦使用卷积和合并图层构建模型，正确的预测就会出现。

因此，当使用 CNN 模型时，数据扩充有助于进一步概括图像边界上的图像变化，即使卷积池图层较少。

## 在 R 中实现 CNN

为了在 R 中实现 CNN，我们将利用我们在 R 中用来实现神经网络的同一个包— `kerasR`(在 github 中代码为“kerasr_cnn_code.r”):

```
# Load, split, transform and scale the MNIST dataset
mnist <- load_mnist()

X_train <- array(mnist$X_train, dim = c(dim(mnist$X_train), 1)) / 255
Y_train <- to_categorical(mnist$Y_train, 10)
X_test <- array(mnist$X_test, dim = c(dim(mnist$X_test), 1)) / 255
Y_test <- to_categorical(mnist$Y_test, 10)

# Build the model
model <- Sequential()
model$add(Conv2D(filters = 32, kernel_size = c(3, 3),input_shape = c(28, 28, 1)))
model$add(Activation("relu"))
model$add(MaxPooling2D(pool_size=c(2, 2)))
model$add(Flatten())
model$add(Dense(128))
model$add(Activation("relu"))
model$add(Dense(10))
model$add(Activation("softmax"))
# Compile and fit the model
keras_compile(model,  loss = 'categorical_crossentropy', optimizer = Adam(),metrics='categorical_accuracy')
keras_fit(model, X_train, Y_train, batch_size = 1024, epochs = 5, verbose = 1,validation_data = list(X_test,Y_test))

```

前面的代码产生了大约 97%的准确率。

## 摘要

在本章中，我们看到了卷积如何帮助我们识别感兴趣的结构，以及合并如何帮助确保图像被识别，即使在原始图像中发生了转换。鉴于 CNN 能够通过卷积和池化来适应图像转换，它能够提供比传统神经网络更好的结果。