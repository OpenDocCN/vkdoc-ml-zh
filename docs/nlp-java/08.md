

# 八、文本和文档分类

在本章中，我们将演示如何使用各种**自然语言处理**(**NLP**)API 来执行文本分类。这不要与文本聚类混淆。聚类涉及不使用预定义类别的文本识别。相反，分类使用预定义的类别。在这一章中，我们将着重于文本分类，其中标签被分配给文本以指定其类型。

用于执行文本分类的一般方法从模型的训练开始。该模型被验证，然后用于分类文档。我们将重点关注该流程的培训和使用阶段。

文档可以根据任意数量的属性进行分类，例如主题、文档类型、出版时间、作者、使用的语言和阅读水平。一些分类方法需要人工标记样本数据。

情感分析是一种分类。它关注的是确定文本试图向读者传达什么，通常是以积极或消极的态度。我们将研究几种可用于执行这种类型分析的技术。

我们将在本章中讨论以下主题:

*   如何使用分类
*   理解情感分析
*   文本分类技术
*   使用 API 对文本进行分类



# 如何使用分类

对文本进行分类有多种用途:

*   垃圾邮件检测
*   作者归属
*   情感分析
*   年龄和性别识别
*   确定文档的主题
*   语言识别

垃圾邮件是大多数电子邮件用户的不幸现实。如果一封电子邮件可以被归类为垃圾邮件，那么它可以被移动到垃圾邮件文件夹。可以分析文本消息，并且可以使用某些属性来将该电子邮件指定为垃圾邮件。这些属性可能包括拼写错误、缺少合适的收件人电子邮件地址以及不标准的 URL。

分类已被用来确定文件的作者。这已经在历史文献上执行过，例如《联邦党人文集》和《T2 原色》这本书，作者是用分类技术识别的。

情感分析是一种确定一段文本的态度的技术。电影评论一直是这种分析的热门领域，但它几乎可以用于任何产品评论。这有助于公司更好地评估他们的产品是如何被感知的。通常，一个消极或积极的属性被分配给文本。情感分析也称为意见提取/挖掘和主观性分析。消费者信心和股票市场的表现可以从推特和其他来源预测。

分类可用于确定文本作者的年龄和性别，并提供对其作者的更多了解。通常，代词、限定词和名词短语的数量被用来识别作者的性别。女性倾向于使用更多的代词，男性倾向于使用更多的限定词。

当我们需要组织大量文档时，确定文本的主题是很有用的。搜索引擎非常关注这种活动，但它也被简单地用于将文档放在不同的类别中——例如，在标签云中。标签云是反映每个单词出现的相对频率的一组单词。

下图是 IBM Word Cloud Generator 生成的标签云的例子([`www . softpedia . com/get/Office-Tools/Other-Office-Tools/IBM-Word-Cloud-Generator . shtml`](http://www.softpedia.com/get/Office-tools/Other-Office-Tools/IBM-Word-Cloud-Generator.shtml))，可以在[`upload . wikimedia . org/Wikipedia/commons/9/9e/Foundation-l _ Word _ Cloud _ without _ headers _ and _ quotes . png`](http://upload.wikimedia.org/wikipedia/commons/9/9e/Foundation-l_word_cloud_without_headers_and_quotes.png)找到:

![](img/00032.jpeg)

使用分类技术来支持对文档所使用的语言的识别。这种分析对于许多 NLP 问题非常有用，在这些问题中我们需要应用特定的语言模型。



# 理解情感分析

对于情绪分析，我们关心的是谁对某个特定的产品或话题有什么样的感觉。例如，这可以告诉我们，一个特定城市的公民对一个运动队的表现有积极或消极的感觉。他们对团队表现的看法可能和对管理的看法不同。

情感分析可以用于自动确定关于产品的某些方面或属性的情感，然后以某种有意义的方式显示结果。

凯利蓝皮书([`www.kbb.com/toyota/camry/2014-toyota-camry/?)对 2014 款凯美瑞的回顾说明了这一点 r=471659652516861060`](https://www.kbb.com/toyota/camry/2014/se/?vehicleid=419855) )，如下截图所示:

![](img/00033.jpeg)

如果您向下滚动，可以找到关于该型号的专家评论，如下所示:

![](img/00034.jpeg)

属性(如总体评分和值)以条形图和数值的形式显示。这些值的计算可以使用情感分析来自动执行。

情感分析可以应用于一个句子、一个子句或者整个文档。情感分析可以是正面的，也可以是负面的，或者它可以是使用数字值的评级，比如 1 到 10。更复杂的态度类型是可能的。

使过程更加复杂的是，在单个句子或文档中，可以针对不同的主题表达不同的情感。

我们如何知道哪些词有哪些类型的情感？这个问题可以用情感词典来回答。在这种情况下，词典是包含不同单词情感的字典。《普通问询者》
([`www.wjh.harvard.edu/~inquirer/`](http://www.wjh.harvard.edu/~inquirer/))就是这样一部词典。它包含 1915 个被认为是肯定的单词。它还包含一个表示其他属性的单词列表，如痛苦、快乐、力量和动机。还有其他可供使用的词典，如 MPQA 主观性线索词典([`mpqa.cs.pitt.edu/`](http://mpqa.cs.pitt.edu/))。

有时，可能需要建立一个词典。这通常是使用半监督学习来完成的，其中使用一些标记的例子或规则来引导词汇构建过程。当正在使用的词典的领域与我们正在处理的问题领域的领域不匹配时，这是很有用的。

我们不仅对获得积极或消极的情绪感兴趣，我们还对确定情绪的属性感兴趣——有时称为目标。考虑下面的例子:

“旅途很艰难，但乘务员做得很好，让我们很舒服。”

这句话包含两种情绪:粗糙和舒适。第一个是负的，第二个是正的。积极情绪的目标或属性是工作，消极情绪的目标是旅行。



# 文本分类技术

分类与获取一个特定的文档并确定它是否属于其他几个文档组之一有关。有两种对文本进行分类的基本技术:

*   基于规则的分类
*   监督机器学习

基于规则的分类使用单词和其他属性的组合，这些属性是围绕专家制定的规则组织的。这些可能非常有效，但创建它们是一个耗时的过程。

**监督机器学习** ( **SML** )采用一组带注释的训练文档来创建模型。该模型通常被称为分类器。有很多不同的机器学习技术，包括朴素贝叶斯、**支持向量机** ( **SVM** )、*k*-最近邻。

我们并不关心这些方法是如何工作的，但是感兴趣的读者将会找到无数的扩展这些和其他技术的资料。



# 使用 API 对文本进行分类

我们将使用 OpenNLP、Stanford API 和 LingPipe 来演示各种分类方法。我们将花更多的时间在 LingPipe 上，因为它提供了几种不同的分类方法。



# 使用 OpenNLP

`DocumentCategorizer`接口指定了可用于支持分类过程的方法。该接口由`DocumentCategorizerME`类实现。该课程将使用最大熵框架将文本分类到预定义的类别中。在本节中，我们将执行以下操作:

*   演示如何训练模型
*   说明如何使用该模型



# 训练 OpenNLP 分类模型

首先，我们必须训练我们的模型，因为 OpenNLP 没有预构建的模型。这个过程包括创建一个训练数据文件，然后使用`DocumentCategorizerME`模型来执行实际的训练。创建的模型
通常保存在一个文件中以备后用。

培训文件格式由一系列行组成，每行代表一个文档。这一行的第一个词是类别。类别后面是由空格分隔的文本。下面是一个`dog`类别的例子:

```java
dog The most interesting feature of a dog is its ...
```

为了演示训练过程，我们创建了`en-animals.train`文件，其中我们创建了两个类别:猫和狗。对于训练文本，我们使用了维基百科的部分内容。对于狗([`en.wikipedia.org/wiki/Dog`](http://en.wikipedia.org/wiki/Dog)，我们用*作为宠物*部分。对于猫([`en.wikipedia.org/wiki/Cats_and_humans`](http://en.wikipedia.org/wiki/Cats_and_humans))，我们用了*宠物*段加上*驯养品种*段的第一段。我们还删除了部分中的数字引用。

下面的代码显示了每一行的第一部分:

```java
dog The most widespread form of interspecies bonding occurs ... 
dog There have been two major trends in the changing status of  ... 
dog There are a vast range of commodity forms available to  ... 
dog An Australian Cattle Dog in reindeer antlers sits on Santa's lap ... 
dog A pet dog taking part in Christmas traditions ... 
dog The majority of contemporary people with dogs describe their  ... 
dog Another study of dogs' roles in families showed many dogs have  ... 
dog According to statistics published by the American Pet Products  ... 
dog The latest study using Magnetic resonance imaging (MRI) ... 
cat Cats are common pets in Europe and North America, and their  ... 
cat Although cat ownership has commonly been associated  ... 
cat The concept of a cat breed appeared in Britain during ... 
cat Cats come in a variety of colors and patterns. These are physical  ... 
cat A natural behavior in cats is to hook their front claws periodically  ... 
cat Although scratching can serve cats to keep their claws from growing  ... 
```

创建训练数据时，使用足够大的样本量非常重要。我们使用的数据不足以进行某些分析。然而，正如我们将看到的，它在正确识别类别方面做得很好。

`DoccatModel`类支持文本的分类和归类。使用基于注释文本的`train`方法来训练模型。`train`方法使用一个表示语言的字符串和一个保存训练数据的`ObjectStream<DocumentSample>`实例。`DocumentSample`实例保存带注释的文本及其类别。

在下面的示例中，`en-animal.train`文件用于训练模型。它的输入流被用来创建一个`PlainTextByLineStream`实例，然后被转换成一个`ObjectStream<DocumentSample>`实例。然后应用`train`方法。代码包含在一个`try-with-resources`块中以处理异常。我们还创建了一个输出流，我们将使用它来持久化模型:

```java
DoccatModel model = null; 
try (InputStream dataIn =  
            new FileInputStream("en-animal.train"); 
        OutputStream dataOut =  
            new FileOutputStream("en-animal.model");) { 
    ObjectStream<String> lineStream 
        = new PlainTextByLineStream(dataIn, "UTF-8"); 
    ObjectStream<DocumentSample> sampleStream =  
        new DocumentSampleStream(lineStream);             
    model = DocumentCategorizerME.train("en", sampleStream); 
    ... 
} catch (IOException e) { 
// Handle exceptions   
} 
```

输出如下，为了简洁起见，已经缩短了:

```java
    Indexing events using cutoff of 5

      Computing event counts...  done. 12 events
      Indexing...  done.
    Sorting and merging events... done. Reduced 12 events to 12.
    Done indexing.
    Incorporating indexed data for training...  
    done.
      Number of Event Tokens: 12
          Number of Outcomes: 2
        Number of Predicates: 30
    ...done.
    Computing model parameters ...
    Performing 100 iterations.
      1:  ... loglikelihood=-8.317766166719343  0.75
      2:  ... loglikelihood=-7.1439957443937265  0.75
      3:  ... loglikelihood=-6.560690872956419  0.75
      4:  ... loglikelihood=-6.106743124066829  0.75
      5:  ... loglikelihood=-5.721805583104927  0.8333333333333334
      6:  ... loglikelihood=-5.3891508904777785  0.8333333333333334
      7:  ... loglikelihood=-5.098768040466029  0.8333333333333334
    ...
     98:  ... loglikelihood=-1.4117372921765519  1.0
     99:  ... loglikelihood=-1.4052738190352423  1.0
    100:  ... loglikelihood=-1.398916120150312  1.0

```

使用`serialize`方法保存模型，如下面的代码所示。模型被保存到`en-animal.model`文件中，就像在前面的`try-with-resources block`中打开的一样:

```java
OutputStream modelOut = null; 
modelOut = new BufferedOutputStream(dataOut); 
model.serialize(modelOut);
```



# 使用文档分类器对文本进行分类

一旦创建了一个模型，我们就可以使用`DocumentCategorizerME`类对文本进行分类。我们需要读取模型，创建一个`DocumentCategorizerME`类的实例，然后调用`categorize`方法返回一个概率数组，告诉我们文本最适合哪个类别。

因为我们是从文件中读取，所以需要处理异常，如下所示:

```java
try (InputStream modelIn =  
        new FileInputStream(new File("en-animal.model"));) { 
    ... 
} catch (IOException ex) { 
    // Handle exceptions 
} 
```

通过`InputStream`，我们创建了`DoccatModel`和`DocumentCategorizerME`类的实例，如下所示:

```java
DoccatModel model = new DoccatModel(modelIn); 
DocumentCategorizerME categorizer =  
    new DocumentCategorizerME(model); 
```

使用字符串作为参数调用`categorize`方法。这将返回一个 double 值数组，其中每个元素都具有文本属于某个类别的可能性。`DocumentCategorizerME`类的`getNumberOfCategories`方法返回模型处理的类别数。`DocumentCategorizerME`类的`getCategory`方法返回给定类别的索引。

我们在下面的代码中使用了这些方法来显示每个类别及其相应的可能性:

```java
double[] outcomes = categorizer.categorize(inputText); 
for (int i = 0; i<categorizer.getNumberOfCategories(); i++) { 
    String category = categorizer.getCategory(i); 
    System.out.println(category + " - " + outcomes[i]); 
} 
```

为了测试，我们使用了维基百科中《绿野仙踪》(【http://en.wikipedia.org/wiki/Toto_%28Oz%29】)中多萝西的狗托托的部分文章。我们用了经典著作*的第一句话*一节，在这里声明:

```java
String toto = "Toto belongs to Dorothy Gale, the heroine of "  
        + "the first and many subsequent books. In the first " 
        + "book, he never spoke, although other animals, native " 
        + "to Oz, did. In subsequent books, other animals " 
        + "gained the ability to speak upon reaching Oz or " 
        + "similar lands, but Toto remained speechless."; 
```

为了测试一只猫，我们使用了位于 https://en.wikipedia.org/wiki/Tortoiseshell_cat 的[的维基百科文章中*玳瑁和印花布*部分的第一句话，如下所示:](https://en.wikipedia.org/wiki/Tortoiseshell_cat)

```java
String calico = "This cat is also known as a calimanco cat or " 
        + "clouded tiger cat, and by the abbreviation 'tortie'. " 
        + "In the cat fancy, a tortoiseshell cat is patched " 
        + "over with red (or its dilute form, cream) and black " 
        + "(or its dilute blue) mottled throughout the coat.";  
```

使用`toto`的文本，我们得到以下输出。这表明该文本应放在`dog`类别中:

```java
    dog - 0.5870711529777994
    cat - 0.41292884702220056  
```

使用`calico`会产生以下结果:

```java
    dog - 0.28960436044424276
    cat - 0.7103956395557574
```

我们可以使用`getBestCategory`方法只返回最佳类别。此方法使用结果数组并返回一个字符串。`getAllResults`方法将以字符串的形式返回所有结果。这两种方法说明如下:

```java
System.out.println(categorizer.getBestCategory(outcomes)); 
System.out.println(categorizer.getAllResults(outcomes)); 
```

输出如下所示:

```java
cat
dog[0.2896]  cat[0.7104]
```



# 使用斯坦福 API

斯坦福 API 支持几个分类器。我们将研究使用`ColumnDataClassifier`类进行一般分类，使用`StanfordCoreNLP`管道进行情感分析。斯坦福 API 支持的分类器有时很难使用。通过`ColumnDataClassifier`类，我们将演示如何对盒子的大小进行分类。通过管道，我们将说明如何确定短文本短语的正面或负面情绪。分类器可以从[`www-nlp.stanford.edu/wiki/Software/Classifier`](http://www-nlp.stanford.edu/wiki/Software/Classifier)下载。



# 使用 ColumnDataClassifier 类进行分类

该分类器使用具有多个值的数据来描述数据。在本演示中，我们将使用一个训练文件来创建一个分类器。然后我们将使用一个测试文件来评估分类器的性能。该类使用属性文件来配置创建过程。

我们将创建一个分类器，试图根据它的尺寸来分类一个盒子。有三种可能的类别:小型、中型和大型。盒子的高度、宽度和长度将被表示为浮点数。它们用于描述箱子的特征。

属性文件指定参数信息，并提供有关训练和测试文件的数据。可以指定许多可能的属性。对于这个例子，我们将只使用几个更相关的属性。

我们将使用下面的属性文件，另存为`box.prop`。第一组属性处理包含在训练和测试文件中的特性的数量。因为我们使用了三个值，所以指定了三个`realValued`列。`trainFile`和`testFile`属性指定了各自文件的位置和名称:

```java
useClassFeature=true 
1.realValued=true 
2.realValued=true 
3.realValued=true 
trainFile=.box.train 
testFile=.box.test 
```

培训和测试文件使用相同的格式。每一行由一个类别和其后的定义值组成，每一行由一个制表符分隔。`box.train`训练文件包含 60 个条目，而`box.test`文件包含 30 个条目。这些文件可以从[`github . com/packt publishing/Natural-Language-Processing-with-Java-Second-Edition/`](https://github.com/PacktPublishing/Natural-Language-Processing-with-Java-Second-Edition/)或者从 GitHub 资源库下载。下面的代码显示了`box.train`文件的第一行。品类小；其高度、宽度和长度分别为`2.34`、`1.60`和`1.50`:

```java
small  2.34  1.60  1.50
```

创建分类器的代码如下面的代码所示。使用属性文件作为构造函数的参数创建了一个`ColumnDataClassifier`类的实例。`Classifier`接口的一个实例由`makeClassifier`方法返回。这个接口支持三种方法，我们将演示其中的两种。`readTrainingExamples`方法从训练文件中读取训练数据:

```java
ColumnDataClassifier cdc =  
    new ColumnDataClassifier("box.prop"); 
Classifier<String, String> classifier =  
    cdc.makeClassifier(cdc.readTrainingExamples("box.train")); 
```

当执行时，我们得到大量的输出。我们将在这一部分讨论更相关的部分。输出的第一部分重复了属性文件的各个部分:

```java
    3.realValued = true
    testFile = .box.test
    ...
    trainFile = .box.train
```

下一部分显示数据集的数量，以及关于各种要素的信息，如下所示:

```java
    Reading dataset from box.train ... done [0.1s, 60 items].
    numDatums: 60
    numLabels: 3 [small, medium, large]
    ...
    AVEIMPROVE     The average improvement / current value
    EVALSCORE      The last available eval score
    Iter ## evals ## <SCALING> [LINESEARCH] VALUE TIME |GNORM| {RELNORM} AVEIMPROVE EVALSCORE

```

然后，分类器对数据进行迭代以创建分类器:

```java
    Iter 1 evals 1 <D> [113M 3.107E-4] 5.985E1 0.00s |3.829E1| {1.959E-1} 0.000E0 - 
    Iter 2 evals 5 <D> [M 1.000E0] 5.949E1 0.01s |1.862E1| {9.525E-2} 3.058E-3 - 
    Iter 3 evals 6 <D> [M 1.000E0] 5.923E1 0.01s |1.741E1| {8.904E-2} 3.485E-3 - 
    ...
    Iter 21 evals 24 <D> [1M 2.850E-1] 3.306E1 0.02s |4.149E-1| {2.122E-3} 1.775E-4 - 
    Iter 22 evals 26 <D> [M 1.000E0] 3.306E1 0.02s
    QNMinimizer terminated due to average improvement: | newest_val - previous_val | / |newestVal| < TOL 
    Total time spent in optimization: 0.07s
```

此时，分类器就可以使用了。接下来，我们使用测试文件来验证分类器。我们从使用`ObjectBank`类的`getLineIterator`方法从文本文件中获取一行开始。这个类支持将读入的数据转换成更标准化的形式。`getLineIterator`方法以分类器可以使用的格式一次返回一行。此流程的循环如下所示:

```java
for (String line :  
        ObjectBank.getLineIterator("box.test", "utf-8")) { 
    ... 
} 
```

在 for-each 语句中，从该行创建一个`Datum`实例，然后使用它的`classOf`方法返回预测的类别，如下面的代码所示。`Datum`接口支持包含特性的对象。当用作`classOf`方法的参数时，由分类器确定的类别被返回:

```java
Datum<String, String> datum = cdc.makeDatumFromLine(line); 
System.out.println("Datum: {"  
    + line + "]\tPredicted Category: "  
    + classifier.classOf(datum)); 
```

当执行这个序列时，测试文件的每一行都被处理，并且显示预测的类别，如下面的代码所示。这里只显示了前两行和后两行。分类器能够正确分类所有测试数据:

```java
    Datum: {small  1.33  3.50  5.43]  Predicted Category: medium
    Datum: {small  1.18  1.73  3.14]  Predicted Category: small
    ...
    Datum: {large  6.01  9.35  16.64]  Predicted Category: large
    Datum: {large  6.76  9.66  15.44]  Predicted Category: large

```

为了测试一个单独的条目，我们可以使用`makeDatumFromStrings`方法来创建一个`Datum`实例。在下面的代码序列中，创建了一个一维字符串数组，其中每个元素表示一个框的数据值。第一个条目“类别”为空。然后，`Datum`实例被用作`classOf`方法的参数来预测它的类别:

```java
String sample[] = {"", "6.90", "9.8", "15.69"}; 
Datum<String, String> datum =  
    cdc.makeDatumFromStrings(sample); 
System.out.println("Category: " + classifier.classOf(datum)); 
```

此处显示了该序列的输出。它正确地对盒子进行分类:

```java
Category: large
```



# 使用斯坦福管道进行情感分析

在本节中，我们将说明如何使用斯坦福 API 来执行情感分析。我们将使用`StanfordCoreNLP`管道对不同的文本进行分析。

我们将使用三种不同的文本，如下面的代码中所定义的。`review`字符串是来自烂番茄([`www.rottentomatoes.com/m/forrest_gump/`](http://www.rottentomatoes.com/m/forrest_gump/))的关于电影*阿甘正传*的影评:

```java
String review = "An overly sentimental film with a somewhat " 
    + "problematic message, but its sweetness and charm " 
    + "are occasionally enough to approximate true depth " 
    + "and grace. "; 

String sam = "Sam was an odd sort of fellow. Not prone " 
    + "to angry and not prone to merriment. Overall, " 
    + "an odd fellow."; 

String mary = "Mary thought that custard pie was the " 
    + "best pie in the world. However, she loathed " 
    + "chocolate pie."; 
```

为了执行这个分析，我们需要使用一个情感`annotator`，如下面的代码所示。这也需要使用`tokenize`、`ssplit`和`parse`标注器。`parse`注释器提供了更多关于文本的结构信息，这将在第十章、*使用解析器提取关系*中详细讨论:

```java
Properties props = new Properties(); 
props.put("annotators", "tokenize, ssplit, parse, sentiment"); 
StanfordCoreNLP pipeline = new StanfordCoreNLP(props); 
```

该文本用于创建一个`Annotation`实例，然后用作执行实际工作的`annotate`方法的参数，如下所示:

```java
Annotation annotation = new Annotation(review); 
pipeline.annotate(annotation); 
```

下面的数组包含不同可能情绪的字符串:

```java
String[] sentimentText = {"Very Negative", "Negative",  
    "Neutral", "Positive", "Very Positive"};
```

`Annotation`类的`get`方法返回一个实现`CoreMap`接口的对象。在这种情况下，这些对象表示将输入文本拆分成句子的结果，如下面的代码所示。对于每个句子，获得一个代表树形结构的`Tree`对象的实例，该树形结构包含对情感文本的解析。`getPredictedClass`方法向`sentimentText`数组返回一个索引，反映测试的情绪:

```java
for (CoreMap sentence : annotation.get( 
        CoreAnnotations.SentencesAnnotation.class)) { 
    Tree tree = sentence.get( 
        SentimentCoreAnnotations.AnnotatedTree.class); 
    int score = RNNCoreAnnotations.getPredictedClass(tree); 
    System.out.println(sentimentText[score]); 
} 
```

当使用`review`字符串执行代码时，我们得到以下输出:

```java
Positive  
```

这篇课文由三个句子组成。每个的输出如下，显示了每个句子的情感:

```java
Neutral
Negative
Neutral  
```

正文`mary`由两个句子组成。每个的输出如下:

```java
Positive
Neutral  
```



# 使用 LingPipe 对文本进行分类

在本节中，我们将使用 LingPipe 来演示一些分类任务，包括使用训练好的模型进行一般的文本分类、情感分析和语言识别。我们将涵盖以下分类主题:

*   使用`Classified`类训练文本
*   使用其他培训类别的培训模型
*   使用 LingPipe 分类文本
*   使用 LingPipe 执行情感分析
*   识别使用的语言

本节中描述的几个任务将使用以下声明。LingPipe 附带了几个类别的训练数据。`categories`数组包含用 LingPipe 打包的类别的名称:

```java
String[] categories = {"soc.religion.christian", 
    "talk.religion.misc","alt.atheism","misc.forsale"}; 
```

`DynamicLMClassifier`类用于执行实际的分类。它是使用`categories`数组创建的，为它提供要使用的类别的名称。`nGramSize`值指定序列中连续项目的数量，这些项目在模型中用于分类目的:

```java
int nGramSize = 6; 
DynamicLMClassifier<NGramProcessLM> classifier =  
    DynamicLMClassifier.createNGramProcess( 
        categories, nGramSize); 
```



# 使用分类类训练文本

使用 LingPipe 的一般文本分类包括使用训练文件训练`DynamicLMClassifier`类，然后使用该类执行实际的分类。LingPipe 附带了几个训练数据集，可以在名为`demos/data/fourNewsGroups/4news-train`的 LingPipe 目录中找到。我们将使用这些数据集来说明培训过程。这个例子是在[`alias-I . com/lingpipe/demos/tutorial/classify/read-me . html`](http://alias-i.com/lingpipe/demos/tutorial/classify/read-me.html)找到的过程的简化版本。

我们首先声明`trainingDirectory`:

```java
String directory = ".../demos"; 
File trainingDirectory = new File(directory  
    + "/data/fourNewsGroups/4news-train"); 
```

在`trainingDirectory`中，有四个子目录，它们的名称列在`categories`数组中。在每个子目录中，都有一系列带有数字名称的文件。这些文件包含处理子目录名称的新闻组(【http://qwone.com/~jason/20Newsgroups/】T2)数据。

训练模型的过程包括通过`DynamicLMClassifier`类的`handle`方法使用每个文件和类别。该方法将使用该文件为该类别创建一个训练实例，然后用该实例扩充模型。这个过程使用嵌套的`for`循环。

外部的`for`循环使用目录名创建一个`File`对象，然后对其应用`list`方法。`list`方法返回目录中的文件列表。这些文件的名称存储在`trainingFiles`数组中，将在内部`for`循环中使用:

```java
for (int i = 0; i < categories.length; ++i) { 
    File classDir =  
        new File(trainingDirectory, categories[i]); 
    String[] trainingFiles = classDir.list(); 
    // Inner for-loop 
} 
```

内部的`for`循环，如下面的代码所示，将打开每个文件并从文件中读取文本。`Classification`类表示具有指定类别的分类。它与文本一起用来创建一个`Classified`实例。`DynamicLMClassifier`类的`handle`方法用新信息更新模型:

```java
for (int j = 0; j < trainingFiles.length; ++j) { 
    try { 
        File file = new File(classDir, trainingFiles[j]); 
        String text = Files.readFromFile(file, "ISO-8859-1"); 
        Classification classification =  
            new Classification(categories[i]); 
        Classified<CharSequence> classified =  
            new Classified<>(text, classification); 
        classifier.handle(classified); 
    } catch (IOException ex) { 
        // Handle exceptions 
    } 
} 
```

You can alternatively use the `com.aliasi.util.Files` class instead in `java.io.File`; otherwise, the `readFromFile` method will not be available.

该分类器可以序列化以备后用，如下面的代码所示。`AbstractExternalizable`类是一个支持对象序列化的实用类。它有一个静态的`compileTo`方法，接受一个`Compilable`实例和一个`File`对象。它将对象写入文件，如下所示:

```java
try { 
    AbstractExternalizable.compileTo( (Compilable) classifier, 
        new File("classifier.model"));
```

```java
} catch (IOException ex) { 
    // Handle exceptions 
} 
```

分类器的加载将在本章后面的*使用 LingPipe* 对文本进行分类部分进行说明。



# 使用其他培训类别

其他新闻组数据可以在 http://qwone.com/~jason/20Newsgroups/找到。这些数据集合可用于为其他模型定型，如下表所列。虽然只有 20 个类别，但它们可以成为有用的培训模型。有三种不同的下载方式。有些已经过排序，有些则删除了重复数据:

| **新闻组** |
| `comp.graphics` | `sci.crypt` |
| `comp.os.ms-windows.misc` | `sci.electronics` |
| `comp.sys.ibm.pc.hardware` | `sci.med` |
| `comp.sys.mac.hardware` | `sci.space` |
| `comp.windows.x` | `misc.forsale` |
| `rec.autos` | `talk.politics.misc` |
| `rec.motoXrcycles` | `talk.politics.guns` |
| `rec.sport.baseball` | `talk.politics.mideast` |
| `rec.sport.hockey` | `talk.religion.misc` |
| `alt.atheism` |  |



# 使用 LingPipe 分类文本

为了对文本进行分类，我们将使用`DynamicLMClassifier`类的`classify`方法。我们将用两个不同的文本序列来演示它的用法:

*   `forSale`:这是来自[`www.homes.com/for-sale/`](http://www.homes.com/for-sale/)，在这里我们使用了第一个完整的句子
*   `martinLuther`:这是来自[`en.wikipedia.org/wiki/Martin_Luther`](http://en.wikipedia.org/wiki/Martin_Luther)，我们用的是第二段的第一句话

这些字符串在此处声明:

```java
String forSale =  
    "Finding a home for sale has never been " 
    + "easier. With Homes.com, you can search new " 
    + "homes, foreclosures, multi-family homes, " 
    + "as well as condos and townhouses for sale. " 
    + "You can even search our real estate agent " 
    + "directory to work with a professional " 
    + "Realtor and find your perfect home."; 
String martinLuther =  
    "Luther taught that salvation and subsequently " 
    + "eternity in heaven is not earned by good deeds " 
    + "but is received only as a free gift of God's " 
    + "grace through faith in Jesus Christ as redeemer " 
    + "from sin and subsequently eternity in Hell."; 
```

要重用前一节中序列化的分类器，请使用`AbstractExternalizable`类的`readObject`方法，如以下代码所示。我们将使用`LMClassifier`类而不是`DynamicLMClassifier`类。它们都支持`classify`方法，但是`DynamicLMClassifier`类不容易序列化:

```java
LMClassifier classifier = null; 
try { 
    classifier = (LMClassifier)  
        AbstractExternalizable.readObject( 
            new File("classifier.model")); 
} catch (IOException | ClassNotFoundException ex) { 
    // Handle exceptions 
} 
```

在下面的代码序列中，我们将应用`LMClassifier`类的`classify`方法。这将返回一个`JointClassification`实例，我们用它来确定最佳匹配:

```java
JointClassification classification =  
    classifier.classify(text); 
System.out.println("Text: " + text); 
String bestCategory = classification.bestCategory(); 
System.out.println("Best Category: " + bestCategory);
```

对于`forSale`文本，我们得到以下输出:

```java
    Text: Finding a home for sale has never been easier. With Homes.com, you can search new homes, foreclosures, multi-family homes, as well as condos and townhouses for sale. You can even search our real estate agent directory to work with a professional Realtor and find your perfect home.
    Best Category: misc.forsale

```

对于`martinLuther`文本，我们得到以下输出:

```java
    Text: Luther taught that salvation and subsequently eternity in heaven is not earned by good deeds but is received only as a free gift of God's grace through faith in Jesus Christ as redeemer from sin and subsequently eternity in Hell.
    Best Category: soc.religion.christian

```

他们都对文本进行了正确的分类。



# 使用 LingPipe 进行情感分析

情感分析的执行方式与普通文本分类非常相似。一个区别是，它只使用两个类别:积极和消极。

我们需要使用数据文件来训练我们的模型。我们将通过使用为电影开发的情感数据([`www . cs . Cornell . edu/people/pabo/movie-review-data/review _ polarity . tar . gz`](http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz))来使用在[`alias-I . com/ling pipe/demos/tutorial/sensation/read-me . html`](http://alias-i.com/lingpipe/demos/tutorial/sentiment/read-me.html)执行的情感分析的简化版本。这些数据是从 IMDb 电影档案馆中的 1000 条正面和 1000 条负面电影评论中得出的。

这些评论需要下载和提取。将提取一个`txt_sentoken`目录及其两个子目录:`neg`和`pos`。这两个子目录都包含电影评论。尽管这些文件中的一部分可以保留以评估所创建的模型，但是我们将使用所有这些文件来简化解释。

我们将从使用 LingPipe 对文本部分进行分类的*中声明的变量的重新初始化开始。`categories`数组被设置为两个元素的数组来保存这两个类别。使用新的类别数组和大小为`8`的`nGramSize`给`classifier`变量分配一个新的`DynamicLMClassifier`实例:*

```java
categories = new String[2]; 
categories[0] = "neg"; 
categories[1] = "pos"; 
nGramSize = 8; 
classifier = DynamicLMClassifier.createNGramProcess( 
    categories, nGramSize); 
```

正如我们前面所做的，我们将基于培训文件中的内容创建一系列实例。我们不会详细检查下面的代码，因为它与使用分类类部分的*培训文本中的代码非常相似。主要区别在于只需要处理两个类别:*

```java
String directory = "..."; 
File trainingDirectory = new File(directory, "txt_sentoken"); 
for (int i = 0; i < categories.length; ++i) { 
    Classification classification =  
        new Classification(categories[i]); 
    File file = new File(trainingDirectory, categories[i]); 
    File[] trainingFiles = file.listFiles(); 
    for (int j = 0; j < trainingFiles.length; ++j) { 
        try { 
            String review = Files.readFromFile( 
                trainingFiles[j], "ISO-8859-1"); 
            Classified<CharSequence> classified =  
                new Classified<>(review, classification); 
            classifier.handle(classified); 
        } catch (IOException ex) { 
            ex.printStackTrace(); 
        } 
    } 
} 
```

该模型现在可以使用了。我们将使用电影*阿甘正传*的评论:

```java
String review = "An overly sentimental film with a somewhat " 
    + "problematic message, but its sweetness and charm " 
    + "are occasionally enough to approximate true depth " 
    + "and grace. "; 
```

我们使用`classify`方法来执行实际工作。它返回一个`Classification`实例，其`bestCategory`方法返回最佳类别，如下所示:

```java
Classification classification = classifier.classify(review); 
String bestCategory = classification.bestCategory(); 
System.out.println("Best Category: " + bestCategory); 
```

执行时，我们得到以下输出:

```java
Best Category: pos  
```

这种方法也适用于其他类别的文本。



# 使用 LingPipe 的语言识别

LingPipe 附带了一个名为`langid-leipzig.classifier`的模型，它针对几种语言进行了训练，可以在`demos/models`目录中找到。下表包含支持的语言列表。这个模型是使用从莱比锡语料库(【http://corpora.uni-leipzig.de/】)中获得的训练数据开发的。另一个好工具可以在 http://code.google.com/p/language-detection/[找到:](http://code.google.com/p/language-detection/)

| **语言** | **缩写** | **语言** | **缩写** |
| 加泰罗尼亚语 | 猫 | 意大利的 | 它 |
| 丹麦的 | 男高中生 | 日本人 | 治安官 |
| 英语 | 在中 | 韩国的 | 韩国 |
| 爱沙尼亚语 | 电子工程师 | 挪威的 | 不 |
| 芬兰人的 | 船方不负担装货费用 | 索布人的 | 吸收 |
| 法语 | 神父 | 瑞典的 | 如果 |
| 德国人 | (加在动词之前）表示“否定”，“相反”；(加在名词之前构成动词)表示“除去”，“除掉” | 土耳其的 | tr |

为了使用这个模型，我们基本上使用了本章前面的*使用 LingPipe* 对文本进行分类一节中使用的相同代码。我们从《阿甘正传》(T2)的同一个电影评论开始:

```java
String text = "An overly sentimental film with a somewhat " 
    + "problematic message, but its sweetness and charm " 
    + "are occasionally enough to approximate true depth " 
    + "and grace. "; 
System.out.println("Text: " + text); 
```

使用`langid-leipzig.classifier`文件创建`LMClassifier`实例:

```java
LMClassifier classifier = null; 
try { 
    classifier = (LMClassifier)  
        AbstractExternalizable.readObject( 
            new File(".../langid-leipzig.classifier")); 
} catch (IOException | ClassNotFoundException ex) { 
    // Handle exceptions 
}
```

使用`classify`方法，然后应用`bestCategory`方法，以获得最佳的语言匹配，如下所示:

```java
Classification classification = classifier.classify(text); 
String bestCategory = classification.bestCategory(); 
System.out.println("Best Language: " + bestCategory); 
```

输出如下，选择英语作为语言:

```java
    Text: An overly sentimental film with a somewhat problematic message, but its sweetness and charm are occasionally enough to approximate true depth and grace. 
    Best Language: en
```

以下代码示例使用瑞典语的瑞典语维基百科条目的第一句([`sv.wikipedia.org/wiki/Svenska`](http://sv.wikipedia.org/wiki/Svenska))作为文本:

```java
text = "Svenska är ett östnordiskt språk som talas av cirka " 
    + "tio miljoner personer[1], främst i Finland " 
    + "och Sverige."; 
```

如此处所示，输出正确选择了瑞典语:

```java
    Text: Svenska är ett östnordiskt språk som talas av cirka tio miljoner personer[1], främst i Finland och Sverige.
    Best Language: se

```

训练可以使用我们在以前的 LingPipe 模型中使用的相同方法进行。执行语言识别时的另一个考虑是文本可以用多种语言书写。这可能会使语言检测过程变得复杂。



# 摘要

在这一章中，我们讨论了围绕文本分类的问题，并研究了执行这一过程的几种方法。文本的分类对于许多活动都是有用的，例如检测垃圾电子邮件、确定文档的作者、执行性别识别以及执行语言识别。

我们还演示了如何执行情感分析。这种分析关注的是确定一篇文章在本质上是积极的还是消极的。还可以使用该过程来评估其他情感属性。

我们使用的大多数方法都要求我们首先基于训练数据创建一个模型。通常，这个模型需要用一组测试数据来验证。一旦模型被创建，它通常很容易使用。

在下一章中，第九章，*主题建模*我们将研究解析过程以及它如何有助于从文本中提取关系。