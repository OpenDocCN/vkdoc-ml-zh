# 3.如何在医疗保健中实现机器学习

我们现在着眼于拥有巨大潜力的医疗保健领域。为此，我们需要仔细检查第 [2](02.html) 章图 [2-2](https://doi.org/10.1007/978-1-4842-3787-8_2Fig#2) 中的技术映射图。图中的某些区域处于阶段 1，技术成熟度较低。虽然这些都有潜力，但它们并没有给我们带来巨大的机会，因为技术目前还不能支持这些领域的发展。例如，个性化医疗是非常新的，必须进行大量的研究，包括使用人工智能，以使其进入下一阶段。这种研究必须与医疗保健行业紧密联系，以便更快地被采用。接下来是流行病爆发预测的第 2 阶段，该阶段有一些成功和失败，需要解决隐私问题才能进入第 3 阶段。真正的潜力在于第三阶段的领域，该技术已经进入辅助应用阶段。

## 潜力巨大的医疗保健研究领域

我不会讨论图 [2-2](https://doi.org/10.1007/978-1-4842-3787-8_2Fig#2) 的第三阶段专栏中使用的所有技术，但我会讨论那些拥有巨大潜力的技术。医疗保健中最有前途的三个领域是:

1.  **数字健康记录**

2.  **疾病诊断**

3.  **放射科**

数字健康记录拥有巨大的潜力，原因有三:首先，随着世界人口的增加，医生的病人数量也在增加；第二，每个病人的数据量也会增加。最后，医生只有掌握了患者的完整病历，才能做出正确的治疗决定。数字健康记录拥有巨大潜力还有另一个原因。机器学习和人工智能的进步允许以快速有效的方式分析数据。未来的医院或医疗保健机构将访问数字健康记录或患者记录，当患者授权医疗保健机构查看其记录时，这些记录将被数字化并可供所有医疗保健机构访问。本质上，我们将有**个联网的医院，**个除了存储病人的私人数据之外，还能访问普通的电子病人健康记录。在美国，任何执业医生都必须保留电子病历。然而，这些数据在医院、政府或任何其他想要治疗患者的机构或个人之间是不可用和不共享的。因此，在未来，将会有一个通用的患者数据库的变化，这将使任何由患者和该国政府授权的医疗机构能够访问共同的病例记录。可能阻碍这种数据共享机制的主要挑战涉及对数据隐私的担忧。然而，如果中央节点机构和政府能够保证数据的适当授权和安全，那么很快就有可能建立这样一个病历数据库，并可能导致建立全球数字健康记录系统。

在不久的将来，我们可以看到技术领域正在开发更好的记录共享机制，将数据隐私和安全等问题抛在脑后。因此，医院不再各自为政，而是开始以相互联系的方式工作。在一个假设的场景中，可能有一个患者，他在接受了特定医院的治疗后，对所给予的治疗线不满意，想要改变他们的医院或医疗保健机构。在这种情况下，他们只需同意与新医院共享所有医疗诊断报告，一旦完成，患者即将入住的新医院将自动访问这些数据。另一个挑战是目前不允许互联医院的概念，那就是不相连的诊断中心。诊断中心是实验室，满足病人的需要，完成他们的实验室测试，如血液或尿液测试。他们根据实验室测试的结果给出报告。因此，在实验室测试完成后，他们会生成大量数据，以测量值的形式显示在报告中。为患者生成的每个报告中的数据目前是通过以 PDF 文件的形式打印报告或通过在纸上打印报告来完成的。没有诊断中心可以上传患者报告的中央机制，并且在医疗保健行业中没有当前的基准可以使他们使用相同的标准来发布他们的报告。所有这些都必须标准化，包括实验室测试报告的格式和中央数据库，患者的电子记录将在那里得到更新。为了从阶段 3 过渡到阶段 4，或者甚至从中等技术成熟度过渡到高技术成熟度，数字健康记录将需要标准化所有上述内容。

现在让我们看看疾病诊断。这一领域有巨大的潜力，因为我们有医生，但在某些地区医生的数量很少。一些人认为医疗保健领域聊天机器人的发展不同于疾病诊断。然而，当我与我们的专家交谈时，他们证实了聊天机器人将成为疾病诊断和病人护理系统的一部分。

任何使用机器学习或人工智能开发的疾病诊断系统都需要具有与人类医生相同的能力。这是技术的狭义应用，也是速赢。我现在引用 Devi Shetty 博士的话，他是班加罗尔 Narayana Health 的主席，来自我在本书前面提到的 XIME Bangalore 会议，“智能软件比医生更聪明。只有 6000 种疾病，其中 1000 种是常见的。这些疾病有大约 50，000 种**症状和体征**。有**十万种化验报告**。任何软件都可以很容易地将这些匹配起来以诊断疾病，这需要医生多年的练习。“除了 Devi Shetty 博士所说的，任何机器人软件都需要理解医生是如何工作的。它也可以包括研究外科医生的日志，等等。，才能获得这样的专业知识。我们需要机器进行疾病诊断的主要原因是:

1.  美国每年有 19.5 万名病人死于医疗诊断错误。

2.  **人类无法处理大量信息，分析这些信息，并将其应用于特定的疾病诊断**

3.  与医生相比，克隆一个专家机器人既便宜又快捷，而克隆专家人类医生在许多国家是被法律禁止的。

4.  诊断的准确性至关重要，因为错误的诊断会增加患者的医疗成本。使用机器学习，我们可以根据机器人或机器对诊断准确性的反馈进行跟踪、测量、优化、学习和改进。

5.  为了增加医疗保健对患者的价值，降低患者的诊断成本是绝对必要的。

6.  价值=在治疗上花费的每一美元的患者健康结果。

如果由于错误的诊断导致病人健康状况不佳，那么医疗保健的价值就会下降。如果病人的健康结果是好的，那么所提供的医疗保健的价值就会上升。因此，我们使用机器学习来增加患者医疗保健的价值是极其重要的。

现在让我们看看放射学及其在医疗保健发展中的潜力。

## 放射学中常见的机器学习应用

下面是一个列表:

1.  **医学图像分割**

2.  **登记**

3.  **计算机辅助检测和诊断**

4.  **大脑功能或活动分析**

5.  **来自 FMR 图像的神经疾病诊断**

6.  **使用** **自然语言处理(NLP)** 的基于内容的图像检索系统，用于 CT 或 MRI 图像和放射学报告的文本分析

机器学习的主要目的是帮助放射科医生对放射学数据做出智能决策，如传统的**射线照片、CT、MRI 和 PET 图像以及放射学报告**。

***在我看来，我们即将看到应用机器学习和人工智能第四阶段的出现。基于机器学习的自动放射学疾病检测*** ***和诊断系统将会有快速的进步。这项技术存在于实验室中，并显示出与训练有素、经验丰富的放射科医生相当的测试结果，因此这项技术进入生产应该只需要几年时间，就可以创造出机器人放射科医生[***[***1***](#Par101)***]。***

## 使用医疗保健数据集

现在，我们将研究一个带有医疗数据集的非常小的 python 代码实现。这将使读者能够理解机器学习在医疗保健领域的实际应用。我已经使用 Python 3.x 运行了这段代码，安装一些必需的 Python 库的过程在下面的练习中给出。我在这里展示的所有练习都是使用 spyder 3.x IDE 运行的，并且经过测试可以在 iPython 内核上运行，所有源代码都可以从我的 github 配置文件( [`https://github.com/puneetmathurDS/`](https://github.com/puneetmathurDS/) )中下载。

在我们开始研究机器学习并将预测模型应用于各种数据集之前，我想提醒读者注意，练习中使用的数据不属于我的任何客户，也不来自现实世界中的真实患者。与世界上任何数据集的任何相似之处都仅仅是巧合。本书的作者或出版商对该数据集的真实性或隐私不承担任何责任。发布这个医疗数据集的目的是让读者了解如何在生产环境中对医疗数据集应用机器学习。此数据集不能用于任何其他目的，如临床试验或任何生产或商业相关的电子或其他活动。

### 机器学习发展的生命周期

在继续查看数据集和构建机器学习模型之前，让我们首先看看什么是典型的机器学习生命周期，并了解它在我们的短应用程序中的实现。这是我向读者展示的一个通用生命周期模型；这可以应用于任何机器学习应用程序的开发，不仅是在医疗保健行业，也可以在零售，金融或其他部门。遵循一步一步的方法可以确保在应用程序中执行机器学习的人不会迷路或错过过程的任何重要部分，并且能够按照专业标准完成他们的应用程序。这种模式没有任何参考价值；因为它是基于我多年来为客户开发机器学习应用程序的经验知识，所以我给出了这个生命周期过程。

在图 [3-1](#Fig1) 中，我们可以看到机器学习的生命周期从识别业务需求开始。这种业务需求是任何机器学习应用程序的关键，因为它为生命周期开发期间的资源需求提供了理由。业务需求也是我们在生命周期的不同阶段回顾的东西，以便实现项目的团队不会忘记最初的目标。

![../images/464968_1_En_3_Chapter/464968_1_En_3_Fig1_HTML.png](../images/464968_1_En_3_Chapter/464968_1_En_3_Fig1_HTML.png)

图 3-1

机器学习生命周期通用框架

下一步是创建机器学习解决方案架构。在此过程中，机器学习工程师和数据科学团队着手创建一个模板，基于该模板将创建机器学习应用程序。正是在这个阶段，业务需求的概念化和业务需求到技术架构的转换发生了。这也是生命周期的一部分，机器学习应用程序的架构师会回到业务中，以便更好地了解他们的需求，并开始将其转化为可实现的解决方案。

下一个阶段是数据准备阶段，这是一个非常重要的阶段，因为我们需要从数据中确定需要什么样的数据，以确定数据的来源。一旦我们知道构建这个机器学习解决方案需要什么数据，我们就可以知道这样的数据是否存在于构建应用的组织内部，或者它需要来自组织外部。数据准备的下一个阶段是获取数据，构建机器学习解决方案的团队需要获取数据。如果整个数据集很大，那么至少可以使用一个样本数据集，在此基础上构建解决方案。需要从内部和外部来源获取数据。这里最重要的任务是确定数据可用的格式，比如 csv、XML、JSON、Oracle 数据库或 DB2 数据库等平面文件。实施团队根据什么是结构化数据的来源，什么是非结构化数据的来源进行分类。机器学习中对非结构化数据和结构化数据的处理是非常不同的，因此其识别同样重要。在数据准备的下一步中，我们执行数据争论，这主要涉及清理数据。在这里，所有对我们的业务解决方案需求没有任何价值的数据都被删除，只有解决业务需求所需的数据被保留。

数据清理完成后，我们进行机器学习周期的下一步，即探索性数据分析。在探索性数据分析中，我们查看数据的基本统计数据，如平均值、中值和众数，以及不同标签之间的相关性，并确定数据是由数字变量还是分类变量组成，等等。这种探索性的数据分析为模型构建提供了方向。例如，算法的选择取决于变量的种类。在样本中，我们可能有带有分类变量的数据集，如基于其他标签预测的性别(男性或女性)。在这种情况下，我们可能必须使用非定量算法来建立模型。下一步是建立模型，它与探索性数据分析密切相关。在这个过程中，我们进行描述性统计分析，确定我们将使用哪种建模技术，然后建立一个基准预测模型。我们对数据集使用其他方法和算法，并尝试解释和找到创建预测模型的最佳算法。一旦模型的识别完成，下一步就是创建模型验证。我们使用更接近生产的阶段数据集，并观察我们的模型如何表现；如果它给出了好的结果，那么这个模型就被部署和实现了。在这之后，反馈被用来查看它是否满足了它被构建的业务需求。如果有新的业务需求或模型需要处理业务要求的一些事情，那么我们再次回到解决方案架构数据准备、EDA 模型和构建模型的流程，然后我们进行模型验证。本质上，这是一个循环过程，一直持续到机器学习应用程序终止。

## 实施患者电子健康记录数据集

我们已经查看了整个机器学习应用程序开发生命周期，现在让我们在患者电子健康记录数据集中实现它。该数据集是平面文件的形式，可从以下 URL 获得: [`http://www.PuneetMathur.me/Book009/Diabetes_Dataset.csv`](http://www.PuneetMathur.me/Book009/Diabetes_Dataset.csv) 。我们现在来看看清单 [3-1](#PC1) 中的代码，这些代码是关于加载和分析电子健康记录数据集的 python 代码。

```
# -*- coding: utf-8 -*-
"""
Created on Thu Mar 15 23:46:06 2018

@author: PUNEETMATHUR
"""
#Importing python libraries
import pandas as pd
import os
os.getcwd()

#Reading dataset from flat file
fname="Diabetes_Dataset.csv"
patients= pd.read_csv(fname, low_memory=False)
df= pd.DataFrame(patients)

#Look at the first record
print(df.head(1))

Listing 3-1Code for Loading Electornic Health Record Data Set

```

在清单 [3-1](#PC1) 给出的 Python 代码中，我已经加载了所需的 Python 库。首先，我已经加载了 Pandas 库来加载 csv 平面文件。这是处理 csv 和 JSON 平面文件最有效的库。接下来，我加载了操作系统库来识别当前的工作目录。如果您已经从数据集和 Python 脚本 ElectronicHealthRecord.py 所在的目录启动了 Python，那么您不需要更改目录；否则，您可以使用操作系统包中的 curdir()函数来更改它。你可以从我的 github 档案( [`http://www.PuneetMathur.me/Book009/`](http://www.PuneetMathur.me/Book009/) )下载这个。

表 3-1

探索数据集

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"> <col class="tcol5 align-left"> <col class="tcol6 align-left"> <col class="tcol7 align-left"> <col class="tcol8 align-left"></colgroup> 
| 

患者 ID

 | 

性别

 | 

年龄

 | 

糖尿病类型

 | 

糖尿病状况

 | 

a1c 测试

 | 

收缩压

 | 

心脏舒张期

 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 5.557686412 | 女性的 | Twenty-nine | 类型 2 | one | Eight point eight one | One hundred and forty-seven | Ninety-three |

现在我们进入下一步:数据准备。为此，我们需要探究并查看下图 [3-2](#PC2) 中数据的形状和大小()。

```
print(df.size)
8632
print(df.shape)
(664, 13)
print(df.columns)
Index(['Patient ID', 'Gender', 'Age', 'Type of diabetes', 'Diabetes status',
       'A1cTEST', 'BPSystolic', 'BPDiastolic', 'HeartRateBPM', 'BMI',
       'FrozenShoulder', 'CarpalTunnelSynd', 'DupuytrensCont'],
      dtype='object')

Listing 3-2Exploring the Shape and Size of Data Set

```

在清单 [3-2](#PC2) 中，我们可以看到 df.size 语句给出的数据集中总共有 8632 个单元格。我们总共有 664 行和 13 列由 df.shape 语句给出。按 df.columns 语句列出，我们看到从性别、年龄、糖尿病类型、糖尿病状态、糖化试验等开始的各种列。现在让我们看一下数据字典，它描述了每一列及其值。

“患者 ID”:这是唯一的患者 ide，由十进制值表示。

'性别':男性或女性。

“年龄”:以年为单位，给出了患者开始治疗时的总年龄。

“糖尿病类型”:1 型或 2 型是我们正在追踪的两种类型的糖尿病。

“糖尿病状态”:这是宣布一个人是否患有糖尿病的预测值列。0 表示没有糖尿病，1 表示患者有糖尿病。

' A1cTEST ':测试结果以百分比表示。正常:血红蛋白 A1c 水平的正常范围在 4%到 5.6%之间。糖尿病前期:血红蛋白 A1c 水平在 5.7%到 6.4%之间意味着你患糖尿病的几率更高。糖尿病:6.5%或更高的水平意味着你有糖尿病。

“收缩压”:成年人的正常血压收缩压低于 140 毫米汞柱，舒张压低于 90 毫米汞柱。

“舒张压”:成年人的正常血压收缩压低于 140 毫米汞柱，舒张压低于 90 毫米汞柱。

“心率 BPM”:成年人的正常静息心率范围是每分钟 60 到 100 次。

身体质量指数:身体质量指数低于 18.5 公斤/平方米表明你体重过轻。你可能需要增加体重。如果你的身体质量指数是 19 到 24.9 公斤/平方米，你是一个健康的体重，应该努力保持下去。25 到 29 公斤/平方米的身体质量指数被定义为超重。为了你的健康着想，减肥是个好主意，或者至少是为了防止体重进一步增加。身体质量指数超过 30 公斤/平方米被定义为肥胖，意味着你的健康处于危险之中。减肥会改善你的健康。

“FrozenShoulder”:是/否由医生根据对患者的身体检查来决定。

“腕管综合症”:在体检医生确定结果后是/否。谷歌[ [1](#Par101) ]字典对腕管综合征的定义是:

> *腕管综合征*

> *名词*

> 由于通过手腕前部通道穿过腕骨的主要神经受压而引起的手和手指疼痛。它可能是由持续的重复运动或液体潴留引起的。

DupuytrensCont ':是/否医生在体检和测试结果后决定。

> 受影响的手指无法完全伸直，这可能会使日常活动变得复杂，例如将手放入口袋、戴上手套或握手。杜普伊特伦挛缩主要影响无名指和小指，最常发生在北欧血统的老年男性[ [*2*](#Par102) *]。*

既然我们已经理解了这个数据集的数据字典，现在让我们仔细看看这个数据，清理它，然后在下面的清单 [3-3](#PC3) 中探索它。为此，我们将使用 Python 库和函数。这些通常与机器学习算法一起使用，所以你必须熟悉它们并更详细地理解它们。

```
#You can use the Describe method to see; however, since our columns are more
#We will use individual functions to do EDA
print(dfworking.describe)
df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 664 entries, 0 to 663
Data columns (total 13 columns):
Patient ID          664 non-null float64
Gender              664 non-null object
Age                 664 non-null int64
Type of diabetes    664 non-null object
Diabetes status     664 non-null int64
A1cTEST             664 non-null float64
BPSystolic          663 non-null float64
BPDiastolic         663 non-null float64
HeartRateBPM        663 non-null float64
BMI                 663 non-null float64
FrozenShoulder      664 non-null object
CarpalTunnelSynd    664 non-null object
DupuytrensCont       664 non-null object
dtypes: float64(6), int64(2), object(5)
memory usage: 67.5+ KB

Listing 3-3Code for Checking Missing Values

```

我们注意到在清单 [3-3](#PC3) 中没有一列有 null 或空值。然而，在现实世界中，你可能很少会发现这是真的。肯定需要清理数据。对于每个列空值，您可以做三件事。第一种方法是删除整行。数字 2 是用平均值替换行。第三是保持行不变。无论您如何决定您的数据，您都需要仔细分析，看看它将如何影响您的整体结果。删除行或列会导致丢失没有缺失值的列中的宝贵信息。它还有助于了解给定列中丢失的值的百分比。这有助于我们做出深思熟虑的决定。我们现在将进入探索性数据分析的下一步。你会注意到我已经通过删除清单 [3-4](#PC4) 中的 PatientID 列使用了 df.working dataframe。这是一个很好的做法，因为它保留了原始的 Pandas 数据帧，而不是删除它。例如，您可以将这些行写成:df- df.drop("Patiend ID "，axis=1)。更容易实现；然而，当您在代码执行过程中发现您采用的代码执行路径不起作用或没有给出任何有意义的结果时，您将需要返回并采用原始数据帧 df，然后进行另一轮代码执行。但是您可能已经丢失了 df.dataframe 中的原始值。因此，我建议您使用另一个数据帧，该数据帧将是工作数据帧，并且作为机器学习应用程序中的编码最佳实践，不要接触原始数据帧。事实上，您应该在您的代码中使用一个替代的 dataframe 名称，只要您可能需要返回到 dataframe 状态，以便查看结果对于满足业务目标是否有意义。现在让我们对数据集做一些探索性的数据分析，如下面的代码清单 [3-4](#PC4) 所示。

```
#Now using a dfworking dataframe to maintain original data in df pandas dataframe
dfworking=df.drop('Patient ID',axis=1)
dfworking.mean()
Out[146]:
Age                 38.899096
Diabetes status      0.240964
A1cTEST              5.890858
BPSystolic         116.278522
BPDiastolic         93.130680
HeartRateBPM        91.812971
BMI                 23.870348
dfworking.median()
Out[148]:
Age                 30.000000
Diabetes status      0.000000
A1cTEST              5.600000
BPSystolic         100.720000
BPDiastolic         91.539001
HeartRateBPM        91.000000
BMI                 24.000000

Listing 3-4Code and Results of EDA

```

现在我们有了 EDA 的代码和结果，我们需要解释并看看我们的数据告诉我们什么。在我们的数据集中，一个人的平均年龄是 39 岁。普通患者的 A1ac 测试百分比为**5.89%，这意味着患者样本处于糖尿病前期**。平均收缩压是 116。8，也就是说一般患者血压正常。舒张压是 93。平均而言，这意味着它略高于我们数据集中舒张压标准的基准血压舒张压水平约 90 mmHG。平均每分钟心率(bpm)为 91.8，在 60 至 100 bpm 标准范围内。平均身体质量指数是 23 岁。这表明普通患者具有健康的体重。所以这些是从研究我们数据集的统计矩中得到的重要发现。在查看了数据集中的统计数据之后，我们现在来看另一个定义数据集中变量之间关系的统计度量。请注意，我们的预测指标是糖尿病状态，即 0 表示无糖尿病，1 表示患者有糖尿病。中位数也是一个要寻找的重要状态，通常在数据中有异常值时使用。如果一列或变量的中值和平均值之间存在巨大差异，则表明数据中存在异常值。然而，在我们的数据集中，当我们比较列表 [3-5](#PC5) 中给出的平均值和中值之间的变量值时，我们发现年龄与 30 岁的平均值有差异，对于其余的列，差异可以忽略。

现在，我们将检查数据集是否存在异常值。我们将首先看看这些列中的数据是如何分布的。这将使我们对数据的传播有所了解。在代码清单 [3-5](#PC5) 中，我现在使用标准差向您展示数据的分布。

```
dfworking.std()
Out[160]:
Age                19.109127
Diabetes status     0.427991
A1cTEST             1.833379
BPSystolic         27.826840
BPDiastolic         5.112349
HeartRateBPM        3.649444
BMI                 1.990809

Listing 3-5
Spread of Data

```

我们知道标准差是每个观察值与平均值[ [3](#Par103) ]的差异的汇总度量。

在我们的数据中，我们可以看到 19 岁年龄的标准偏差，这意味着从 39 岁的平均年龄有大约 19 年的差距。我们将忽略糖尿病状态数，因为它没有任何意义，因为它是 0 或 1 的二进制值，并且该值是 0.4，介于 0 和 1 之间。我们将查看 A1c 测试标准偏差，它与平均值相差 1.8%。同样的，收缩压是 27。这意味着高血压有更多的变异，这就是我们样本患者的问题所在。血压舒张压的标准差为 5，当我们将其与血压收缩压的标准差相比时，这似乎不是很高。心率 bpm 标准差为 3.64，也可以忽略不计，身体质量指数为 2 值得关注，这也意味着我们有体重指数变异较高的患者。现在让我们更深入地研究我们的数据，更仔细地观察它是如何传播的，以及我们可以从中解读什么。为此，我们将使用最大值/最小值、分位数峰度和偏度函数，它们是 pandas 数据框的一部分。在代码清单 [3-6](#PC6) 中，我们查看数据集中数值变量的最大值。

```
dfworking.max()
Out[167]:
Gender                 Male
Age                      79
Type of diabetes     Type 2
Diabetes status           1
A1cTEST               10.99
BPSystolic              212
BPDiastolic             126
HeartRateBPM            113
BMI                 30.9951
FrozenShoulder          Yes
CarpalTunnelSynd        Yes
DupuytrensCont          Yes
dtype: object
dfworking.min()
Out[168]:
Gender               Female
Age                      10
Type of diabetes       None
Diabetes status           0
A1cTEST                2.02
BPSystolic           100.01
BPDiastolic              87
HeartRateBPM             88
BMI                 17.1278
FrozenShoulder           No
CarpalTunnelSynd         No
DupuytrensCont           No

Listing 3-6Checking Spread of Variables in Data Set

```

年龄的最大值是 79，这意味着该样本中年龄最大的患者是 79 岁。最常见的糖尿病类型是 1 型，糖尿病状态是 1，a1c 测试百分比最大值是 10，这是非常高的。血压收缩压值 212，也很高，舒张压值 126，也很高。心率 bpm 最大值 113，也偏高。身体质量指数最大值是 31，这是超重，其余项目有分类值。与最大值类似，我们也有最小值。在这个样本数据集中，患者的最小年龄是 10 岁。最低糖尿病状态为 0，这意味着患者没有糖尿病。100 测试的最小值是 2。这低于正常的血红蛋白 A1c 水平。血压收缩压的最小值是 100。这低于 140 毫米汞柱，对成年人来说是正常的。血压舒张最小值为 87，如果患者的血压低于 90 mmHg，也认为是正常的。如果心率 bpm 在 60 到 100 bpm 的范围内，则认为它是正常的，这里我们有最小值 88，这在正常范围内。身体质量指数最小值是 17。这意味着患者体重过轻，因为低于 18.4。其余的列值是分类的。

### 检测异常值

现在我们进入检测异常值的任务。除非我们知道每个变量或列在数据集中是否有异常值，否则任何严肃的数据分析都无法进行。为了检测异常值，我们需要首先定义它是什么。这是一个关于离群值计算方法的争论问题；然而，我采用常用的 1.5 倍四分位距的截止值。通过使用熊猫数据框中的最大值和最小值函数，可以知道任何列的数据集范围。为了计算异常值，我将首先取下面清单 [3-7](#PC7) 和 [3-8](#PC8) 中数字列的最大值和最小值。

```
dfworking.max()
Out[203]:
Gender                 Male
Age                      79
Type of diabetes     Type 2
Diabetes status           1
A1cTEST               10.99
BPSystolic              212
BPDiastolic             126
HeartRateBPM            113
BMI                 30.9951
FrozenShoulder          Yes
CarpalTunnelSynd        Yes
DupuytrensCont          Yes
dtype: object

Listing 3-7Calculating Maximum Values

```

我们在清单 [3-7](#PC7) 中看到，年龄的最大值是 79，100 测试的最大百分比是 10.9，收缩压是 212，舒张压是 126，心率 bpm 是 113，身体质量指数是 30.99。类似地，我们在清单 [3-8](#PC8) 中看到年龄的最小值是 10，对于 100%的测试百分比是 2.2。收缩压为 100.0，舒张压为 87，心率 bpm 为 88，身体质量指数为 17.12。

```
dfworking.min()
Gender               Female
Age                      10
Type of diabetes       None
Diabetes status           0
A1cTEST                2.02
BPSystolic           100.01
BPDiastolic              87
HeartRateBPM             88
BMI                 17.1278
FrozenShoulder           No
CarpalTunnelSynd         No
DupuytrensCont           No

Listing 3-8Calculating Minimum Values

```

让我们拿起年龄栏来帮助理解这一栏的范围。我们已经看到，对于年龄，最大值是 79，最小值是 10。所以在我们的患者中，最小的 10 岁，最大的 79 岁。所以我们的区间是 79 减 10，也就是 69 年。因此，我们正在测量年龄范围为 69 岁的患者的健康记录。

现在我们知道了最大值和最小值，并且计算了数据的范围，我们需要查看这个年龄列的四分位数范围。四分位数间距是数据集的第一个四分位数和第三个四分位数之间的差值。它用于描述数据集[ [4](#Par104) ]内数据的分布情况。在代码清单 [3-9](#PC9) 中，我们现在来看数值数据集的第一个四分位数。

```
dfworking.quantile(0.25)
Out[206]:
Age                 29.000000
Diabetes status      0.000000
A1cTEST              5.177500
BPSystolic         100.375000
BPDiastolic         91.107946
HeartRateBPM        91.000000
BMI                 23.000000

Listing 3-9Measuring 1st Quartile of Our Data Set

```

清单 [3-9](#PC9) 和 [3-10](#PC10) 向您展示了一种快速计算我们数据集中第一个四分位数和第三个四分位数的方法。我们看到，在第一个四分位数中，年龄为 29，A1c 试验为 5.1，收缩压为 100，舒张压为 91.2，心率 bpm 为 91，身体质量指数为 23。在清单 [3-10](#PC10) 中，我们现在来看看数据集的第三个四分位数。

```
dfworking.quantile(0.75)
Out[210]:
Age                 49.000000
Diabetes status      0.000000
A1cTEST              6.000000
BPSystolic         122.355000
BPDiastolic         92.070602
HeartRateBPM        92.000000
BMI                 24.441247

Listing 3-10Measuring 3rd Quartile of Our Data Set

```

为了确定数据集中每个变量的异常值的阈值，在清单 [3-11](#PC11) 中，我展示了计算这些阈值的代码。

```
dfworking.quantile(0.25)*1.5
Out[214]:
Age                 43.500000
Diabetes status      0.000000
A1cTEST              7.766250
BPSystolic         150.562500
BPDiastolic        136.661919
HeartRateBPM       136.500000
BMI                 34.500000
Name: 0.25, dtype: float64

dfworking.quantile(0.75)*1.5
Out[215]:
Age                 73.500000
Diabetes status      0.000000
A1cTEST              9.000000
BPSystolic         183.532500
BPDiastolic        138.105902
HeartRateBPM       138.000000
BMI                 36.661871

Listing 3-11Measuring Outlier Threshold Values of Our Data Set

```

在清单 [3-11](#PC11) 中，给出了每列的第一个分位数乘以 1.5 个阈值。对于年龄列，下限是 43.5，第三个分位数是 73.5。我们可以看到，数据实际上向我们表明，任何低于年龄 43.5 的第一个分位数值的年龄都是异常值。类似地，年龄列中任何大于 73.5 的值也是异常值。类似地，对于 A1c 测试，异常值的阈值下限是 7.7，A1c 测试的阈值上限是 9。样本中任何低于下阈值 7.7 或高于上阈值 9.4 的值都是异常值。同样，对于收缩压，任何低于 150.5 而高于 183 的值都是异常值。对于舒张压，我们知道这个范围远小于下限(136 点)和上限(138 点)。类似地，我们有心率 bpm，其下限为 136.5，上限为 138。即使对于身体质量指数来说，该值也遵循舒张压和心率 bpm，具有其阈值之间的较低范围，因为较低阈值是 34，而身体质量指数的较高阈值是 36.6。为了更好地理解数据集中的这种分布，我现在向您展示一个图表，使用箱线图来表示清单 [3-12](#PC12) 中的变量。在代码清单 [3-12](#PC12) 中，我现在向您展示如何查看我们 6 列中每一列的数据分布的可视化。

```
#Horizontal default boxplot chart
dfworking.boxplot(figsize=(10, 6))
#Vertical Boxplot chart
dfworking.plot.box(vert=False)
#Boxplot by selecting only the required columns
dfworking.boxplot(column=['A1cTEST','BPSystolic','BPDiastolic','HeartRateBPM','BMI','Age'],figsize=(10, 6))

Listing 3-12Visualization of the spread of data for each of our 6 columns.

```

图 [3-2](#Fig2) 直观地向我们展示了变量的方框图。年龄显示了均匀的分布，并且在视觉上没有显示任何异常值；然而，对于 A1c 测试，我们可以看到该百分比位于非常窄的范围内。在下限阈值和上限阈值上，我们可以看到一些异常值散落在图上。对于 BP 收缩压，我们可以看到异常值位于 150+的范围内。对于血压舒张期，我们可以看到一些阈值下限范围内的异常值，但大多数位于阈值上限范围内。这与心率 bpm 和身体质量指数列类似。从视觉上可以看出，舒张压和心率 bpm 与身体质量指数之间的共同差异表明它们的范围很窄。然而，对于 BP 收缩压，该范围非常高，因此在用于计算四分位数范围然后计算异常阈值的函数分位数中是明显的。我决定保留异常值是基于这样一个事实，即在像 BP systolic 这样的列变量中，这是本研究中的关键变量之一，如果我删除异常值以上的值，那么我将剩下更少有意义的数据来分析。通过使用代码 dfworking['BPSystolic']。loc[df[' BP systolic ']>= 183.562500。count()，我们得到的值是 35，这表明在这个列变量中有 5.3%的异常值，这是非常显著的。因此，我们将保留异常数据进行分析。然而，我们需要选择一个对异常值稳健的分类算法，比如决策树[ [5](#Par105) ]。

![../images/464968_1_En_3_Chapter/464968_1_En_3_Fig2_HTML.jpg](../images/464968_1_En_3_Chapter/464968_1_En_3_Fig2_HTML.jpg)

图 3-2

电子患者健康记录数据集的箱线图

现在，我们了解了数据的分布情况，并通过命令直观地看到了数据的分布情况。让我们看看我们的列变量的另外两个度量:偏斜度和峰度。这将为我们提供关于数据曲线的形状和大小的具体信息。在清单 [3-13](#PC13) 中，我们可以看到偏斜度和峰度的值。

```
dfworking.skew()
Age                0.878405
A1cTEST            0.344770
BPSystolic         1.720338
BPDiastolic        3.693222
HeartRateBPM       3.327100
BMI                1.098987
dfworking.kurtosis()
Age                -0.286342
A1cTEST             0.461561
BPSystolic          1.948725
BPDiastolic        15.712615
HeartRateBPM       13.172057
BMI                 5.468543

Listing 3-13Skew and Kurtosis Values of Our Variables in Our Data Set

```

在我们研究偏斜度和峰度之前，我想提醒读者正态分布曲线具有均值=众数=中位数的性质。然而，通过观察数据集变量的偏斜度和峰度，我们试图了解它们与正态曲线有多接近或有多不同。这也可以通过情节直观地看到，我们将在后面做；然而，偏斜度和峰度数值也有助于我们理解数据集的分布。我不会深入讨论计算偏斜度和峰度的公式，因为我希望读者了解这一点，或者参考互联网上的一些好的参考资料。偏斜度(或偏斜度)是通过数学方法计算的，是我们首先得到的数字的结果。如果偏斜度大于 0，那么我们说分布是正偏斜的；然而，如果我们计算的偏斜数小于 0，那么我们说分布是负偏斜的。如果偏斜的数量等于 0，则称该分布是对称的。负偏态分布有一个长的左尾巴，正偏态分布有一个长的右尾巴。有了这些知识，我们现在开始解释数据集中每一列的结果。年龄列的值为 0.8，这意味着这个可变年龄是正偏的，并且沿着右尾分布。稍后，我们将通过可视化来验证我们对变量的数字数据分析。对于 A1c 测试偏度，我们的值为 0.34，这意味着它更接近于正态曲线；然而，它稍微有点偏正。对于收缩压，我们的值为 1.2，这显然意味着数据是正偏的。舒张压也具有非常高的正值 3.9，这表明它也是高度正偏的。心率 bpm 的值也是 3.3，这也意味着它是高度正偏的。身体质量指数也是正面倾斜的。

接下来我们转向峰度，它显示了分布的厚度。如果一个数据分布有更多的峰值，则称之为左分布或薄分布，称之为厚尾分布。在这样的分布中，与正态分布相比，出现极端结果的可能性更大。峰度公式计算值等于 3 的正态分布的邪恶程度。过多的峰度意味着变量的分布值将高于 3，而较少的峰度意味着它将低于 3。如果峰度值小于 3，那么它也表示一种称为中峰度的分布类型；然而，中峰度分布的范围是介于 0 和 3 之间的峰度值。如果峰度值小于 0，则称之为扁峰度。平顶分布的故事更短更薄，中央峰更低更宽。年龄的峰度是负值 0.2。A1c 测试是 0.4 的正值，但低于 3 的值。血压收缩压值为 1.9，但低于 3 且大于 0。血压舒张压 15.1，心率 BPM 13.1。身体质量指数是 5.4。我们已经注意到，如果峰度数值小于 0，那么这样的分布是平峰度的，这意味着它的尾部更短更细，并且它的中心峰值通常更低更宽。我们有介于 0 和 3 之间的变量 A1c 测试和 BP 收缩压，表明这些变量的分布是中等的。我们数据集中的三个变量，舒张压、心率 bpm 和身体质量指数，具有超过 3 的峰度值，表明这些变量的数据分布是尖峰的。尾巴更长更粗，中央的峰更高更尖。

在图 [3-3](#Fig3) 中，您可以看到使用 Pandas dataframe 的最高方法的数据集中变量的可视化输出。

![../images/464968_1_En_3_Chapter/464968_1_En_3_Fig3_HTML.jpg](../images/464968_1_En_3_Chapter/464968_1_En_3_Fig3_HTML.jpg)

图 3-3

可视化数据集中变量的分布

```
dfworking.hist(figsize=(10, 6))

```

我们可以通过图 [3-3](#Fig3) 中的可视化来确认偏度和峰度的数值解释。在下面的代码清单 [3-14](#PC15) 中，我们使用 dataframe dfworking 的 corr()函数查看相关系数结果。

```
dfworking.corr()

                     Age   Diabetes status   A1cTEST  BPSystolic  BPDiastolic \
Age            1.000000        -0.006059  0.011436   0.013097      0.028190
Diabetes status -0.006059         1.000000  0.816808   0.902857      0.560962
A1cTEST        0.011436         0.816808  1.000000   0.827919      0.591827
BPSystolic     0.013097         0.902857  0.827919   1.000000      0.735363
BPDiastolic    0.028190         0.560962  0.591827   0.735363      1.000000
HeartRateBPM  -0.052383         0.151831  0.147737   0.168413      0.058129
BMI            0.027911         0.181897  0.167908   0.181927      0.130275

                 HeartRateBPM       BMI
Age                 -0.052383  0.027911
Diabetes status      0.151831  0.181897
A1cTEST              0.147737  0.167908
BPSystolic           0.168413  0.181927
BPDiastolic          0.058129  0.130275
HeartRateBPM         1.000000  0.107147
BMI                  0.107147  1.000000

Listing 3-14
Correlation Coefficient Results

```

接下来是计算，看看变量之间是否有某种关系。为此，我们将使用 Pandas dataframe 的 corr()函数，这将使我们能够查看这些变量之间的相关性。为了提醒读者如何解释相关结果，两个变量之间的相关值等于 1 意味着完美的线性正关系，如果它是负的，则意味着变量之间的负线性关系。如果相关系数值等于 0，那么就说两个变量之间没有真正的线性关系。从 0 到 1 或-1 交错在 0.34 到 0.3 之间的值被称为具有弱线性关系。介于 0.5 和-0.5 之间的值被称为具有适度的正或负线性关系。介于-0.7 和+0.7 之间的值被认为与我们的数据集[ [6](#Par106) ]有很强的正或负线性关系。有了这些信息，我们现在可以快速分析对数据集应用相关函数的结果。

当我们查看清单 [3-14](#PC15) 时，我们的主要动机是取出那些至少具有中等或强的变量，如果可能的话，还有一个完美的线性关系。因此，我们在寻找相关系数从正负 0.5 到 0.12 尽可能接近 1 或 1 的变量。我们可以看到，年龄变量与其他变量没有任何显著的线性关系；然而，当我们观察糖尿病状态的预测变量时，它似乎与 A1c 试验呈 0.8 的正相关，与收缩压呈 0.9 的正相关。与血压舒张压(0.5)有中度关系。可以理解，A1c 试验与预测变量糖尿病状态(0.8)、收缩压(0.83)和舒张压(0.59)有很强的关系。收缩压和舒张压的正相关系数为 0.74。舒张压与糖尿病状态呈中度正相关，预测变量为 0.5。心率 bpm 似乎与我们数据集中的任何变量都没有任何显著的相关性。身体质量指数的情况也是如此，它似乎与我们的任何数据集都没有任何关联。

现在，我们能够看到那些看起来有某种关系的重要变量，直观地观察它们，并理解它们是如何放置的。举例来说，在图 [3-4](#Fig4) 中，散点图显示了列变量 A1c 测试和 BP 收缩压之间的直观关系。

![../images/464968_1_En_3_Chapter/464968_1_En_3_Fig4_HTML.jpg](../images/464968_1_En_3_Chapter/464968_1_En_3_Fig4_HTML.jpg)

图 3-4

A1cTest 和 BP 收缩压变量之间的散点图

```
dfworking.plot.scatter(x='A1cTEST', y="BPSystolic",s=dfworking['A1cTEST']*2)

```

在图 [3-4](#Fig4) 中，我们看到了两个变量之间的某种模式。我们看到有几组群集被放置用于 A1c 测试；随着结果的上升，患者被分组到特定的聚类模式中，这些模式显示出阶梯状的上升趋势。它从 100 BP 的收缩压开始，超过 200 BP 的收缩压，并从 A1c 测试值的 2%以上开始。通过可视化早期检测这种模式在机器学习中非常重要。我们可以尝试实施某些分类技术，将患者分为视觉上对我们有吸引力的这几组。

探索性数据分析的最后一步是查看包含分类变量(包括预测变量糖尿病状态)的列。我们的数据集中有六个分类变量列。第一个是性别，将我们的数据集分为男性或女性。下一个分类栏是糖尿病的类型。在我们的数据集中，没有 1 型糖尿病患者；然而，我们也有没有糖尿病或二型糖尿病的病人。糖尿病状态列是预测变量，其值也是分类的，其中 0 表示没有糖尿病，1 表示患者有糖尿病。肩周炎由医生通过人工检查确定，有“是”或“否”的值:“是”表示患者有肩周炎，“否”表示患者没有肩周炎。在腕管综合征中，它与冻结肩相同，其中 yes 表示患者患有腕管综合征，no 表示患者没有这种疾病。对于袢掌腱膜挛缩症，也有“是”和“否”两栏，其中“是”表示患者患有该疾病，“否”表示患者没有该疾病。现在，我将使用基于这些分类变量的交叉列表，来看看我们的数据集是如何针对这些列进行分类的。在代码清单 [3-15](#PC17) 中，我们查看了数据集中的性别分类。

```
my_tab = pd.crosstab(index=df["Gender"], columns="Count")      # Name the count column

my_tab=my_tab.sort_values('Count', ascending=[False])
print(my_tab)
col_0   Count
Gender
Female    351
Male      313

Listing 3-15Gender Classification in the Data Set

```

在清单 [3-15](#PC17) 中，我们可以看到，在我们的数据集中，总共 664 名患者中有 351 名女性，男性患者有 313 名，因此按性别划分，53%的患者为女性。这也可以在图 [3-5](#Fig5) 给出的图表中直观地看到。

![../images/464968_1_En_3_Chapter/464968_1_En_3_Fig5_HTML.jpg](../images/464968_1_En_3_Chapter/464968_1_En_3_Fig5_HTML.jpg)

图 3-5

性别分类数据可视化

```
data_counts = pd.DataFrame(my_tab)
pd.DataFrame(data_counts).transpose().plot(kind='bar', stacked=False)

```

现在我们来看下一列，即清单 [3-16](#PC19) 中的糖尿病类型。

```
my_tab = pd.crosstab(index=df["Type of diabetes"], columns="Count")      # Name the count column

my_tab=my_tab.sort_values('Count', ascending=[False])
print(my_tab)
col_0             Count
Type of diabetes
None                504
Type 2              160

Listing 3-16Type of Diabetes Classification

```

我们可以看到数据集中 24%的患者患有二型糖尿病，504 名患者没有糖尿病。计算百分比的原因对于任何分类列都很重要，因为我们需要确定我们是否正在处理一个罕见的事件。如果我们正在处理一个罕见的事件，我们需要使用单变量分析来处理模型的建立。图 [3-6](#Fig6) 给出了糖尿病类型栏的直观表示。

![../images/464968_1_En_3_Chapter/464968_1_En_3_Fig6_HTML.jpg](../images/464968_1_En_3_Chapter/464968_1_En_3_Fig6_HTML.jpg)

图 3-6

糖尿病类型分类可视化

接下来，我们来看看清单 [3-17](#PC20) 中的列冻结肩。

```
my_tab = pd.crosstab(index=df["FrozenShoulder"], columns="Count")      # Name the count column

my_tab=my_tab.sort_values('Count', ascending=[False])
print(my_tab)
col_0           Count
FrozenShoulder
No                533
Yes               131

Listing 3-17Classification of Frozen Shoulder Disease in Our Data Set

```

在列表 [3-17](#PC20) 中，我们可以看到我们数据集中 19.1%的患者患有肩周炎，533 名患者没有肩周炎。由于这个百分比高于 10 %,我们现在可以确定肩周炎不是我们预测的罕见事件。冻结肩的数据可视化如图 [3-7](#Fig7) 所示。

![../images/464968_1_En_3_Chapter/464968_1_En_3_Fig7_HTML.jpg](../images/464968_1_En_3_Chapter/464968_1_En_3_Fig7_HTML.jpg)

图 3-7

冻结肩疾病分类可视化

```
data_counts = pd.DataFrame(my_tab)
pd.DataFrame(data_counts).transpose().plot(kind='bar', stacked=False)
Out[316]: <matplotlib.axes._subplots.AxesSubplot at 0x243ae851278>

```

```
my_tab = pd.crosstab(index=df["CarpalTunnelSynd"], columns="Count")      # Name the count column

my_tab=my_tab.sort_values('Count', ascending=[False])
print(my_tab)
col_0             Count
CarpalTunnelSynd
No                  546
Yes                 118

Listing 3-18Carpal Tunnel Syndrome Classification

```

现在让我们看看腕管综合症。在图 [3-8](#Fig8) 中，我们可以看到交叉列表的代码，以及自称患有腕管综合征的人数和未被诊断为腕管综合征的人数。我们的样本中有 17%被诊断患有这种疾病。总共有 118 人，其中 546 人没有这种症状。

![../images/464968_1_En_3_Chapter/464968_1_En_3_Fig8_HTML.jpg](../images/464968_1_En_3_Chapter/464968_1_En_3_Fig8_HTML.jpg)

图 3-8

腕管综合征可视化

```
data_counts = pd.DataFrame(my_tab)
pd.DataFrame(data_counts).transpose().plot(kind='bar', stacked=False)
Out[319]: <matplotlib.axes._subplots.AxesSubplot at 0x243ae6a45c0>

```

这种分类的可视化如图 [3-8](#Fig8) 所示。

现在让我们来看看掌腱膜挛缩症及其分类，如图 [3-8](#Fig8) 所示。在代码列表 [3-19](#PC24) 中，我们使用交叉列表来查看杜普伊特伦挛缩症患者的分类。

```
my_tab = pd.crosstab(index=df["DupuytrensCont"], columns="Count")      # Name the count column

my_tab=my_tab.sort_values('Count', ascending=[False])
print(my_tab)
col_0          Count
DupuytrensCont
No               544
Yes              120

Listing 3-19Dupuytren’s Contracture Classification

```

被诊断患有掌腱膜挛缩症的患者占我们数据集的 18 %, 544 名患者没有这种疾病。我结束了对所有分类列的分析，因为我们已经探索了我们的数据集，并对其进行了充分的分析，以开始构建预测模型。

### 数据准备

现在，我们已经完成了探索性的数据分析，并在构建模型之前继续实际的数据准备工作。我在表格 [3-2](#Tab2) 中给出了我们需要做的一些步骤及其目的。我们在表中看到有四个步骤。首先是将数据划分为目标变量和特征；我们这样做是为了避免计算带有特征的目标变量。这在机器学习中很常见，需要避免。第二步是标准化数据，这样做是为了建立一致性或标准化尺度来衡量我们数据集中的所有变量。下一步是创建虚拟变量，主要目的是将所有分类变量转换成虚拟变量，比如性别(男性或女性)。我们可以说性别 0 等于男性，性别 1 等于女性。20 代表男性，1 代表女性，因此数字编码是我们在这一特定步骤中需要做的。数据准备的最后一步是数据的混洗和分割，这两个步骤都是为了增加一定程度的随机性并删除数据中的任何病毒。一旦我们完成了这四个步骤，我们将能够开始建立我们的预测模型。对于每个步骤，我将向您展示我们数据集的代码和结果，以及如何进行数据准备。

表 3-2

数据准备步骤

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

数据准备步骤

 |
| --- |
| 

没有#

 | 

工作

 | 

描述

 |
| --- | --- | --- |
| one | 将数据分为目标变量和特征。 | 我们需要将数据分为特征和目标变量，以确保我们不会将目标变量算作特征；否则，我们的预测模型会给出错误的结果。 |
| Two | 标准化数据。 | 我们需要将数据标准化，因为这将所有的变量带到一个共同的尺度上。俗话说，你不能把橘子和苹果相提并论。我们的变量也是如此。它们是具有不同测量尺度的不同测量，例如血压收缩压不同于心率 bpm 的尺度。 |
| three | 虚拟变量 | Python 中的 Scikit 库的一个局限性是它只能处理数值数据，而不能处理分类数据。消除这种限制的一种方法是将数据集中的分类变量(如冻结肩列)转换为数字编码格式。 |
| four | 洗牌和分割数据。 | 我们现在打乱数据以引入随机因素，然后将其分为训练和测试，以消除数据中的偏差。 |

清单 [3-20](#PC25) 中给出了步骤 1 的代码。

```
#Data Preparation Steps
#Step 1 Split data into features and target variable
# Split the data into features and target label
diabetics = pd.DataFrame(dfworking['Diabetes status'])
features = pd.DataFrame(dfworking.drop('Diabetes status', axis = 1))
diabetics.columns
features.columns
features.columns
Out[352]:
Index(['Gender', 'Age', 'Type of diabetes', 'A1cTEST', 'BPSystolic',
       'BPDiastolic', 'HeartRateBPM', 'BMI', 'FrozenShoulder',
       'CarpalTunnelSynd', 'DupuytrensCont'],
      dtype='object')

Listing 3-20Step 1 of Data Preparation

```

在清单 [3-20](#PC25) 中，在实现步骤 1 的代码时，我们看到 features dataframe 没有列 diabetes status，这是我们的目标变量。我创建了两个数据框:糖尿病数据框，它是预测值或目标变量熊猫数据框；特征数据框，它没有糖尿病状态列。我使用了熊猫数据框的拖放方法来删除糖尿病状态列。现在我们进入第二步:标准化数据。这可以从清单 [3-22](#PC27) 中看出。为了实现这一点，我将使用 sklearn.preprocessing 库并从中导入 MinMaxScaler 来标准化我们的数据集。请注意，这种标准化只适用于数字变量，而不适用于分类变量或虚拟变量。

```
dfworking.dtypes
dfworking.dtypes
Out[355]:
Gender               object

Age                   int64

Type of diabetes     object
Diabetes status       int64

A1cTEST             float64

BPSystolic          float64

BPDiastolic         float64

HeartRateBPM          int64

BMI                 float64

FrozenShoulder       object
CarpalTunnelSynd     object
DupuytrensCont       object

Listing 3-21Numerical Columns in Our Working Data Set

```

我们可以在清单 [3-21](#PC26) 中看到，年龄 A1c 测试、收缩压、舒张压、心率 bpm 和身体质量指数列是数字。我们将忽略糖尿病状态列，因为它是患者的分类变量，其中 0 表示没有糖尿病，1 表示患者患有糖尿病。在清单 [3-22](#PC27) 中，我提供了提取这些数字特征的代码，然后对它们应用标准化标量。

```
# Import sklearn.preprocessing.StandardScaler
from sklearn.preprocessing import MinMaxScaler

# Initialize a scaler, then apply it to the features
scaler = MinMaxScaler()
numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']
features_raw[numerical] = scaler.fit_transform(dfworking[numerical])

# Show an example of a record with scaling applied
display(features_raw[numerical].head(n = 1))
        Age   A1cTEST  BPSystolic  BPDiastolic  HeartRateBPM           BMI
0  0.275362  0.756968    0.419591     0.153846      0.028571   0.545713 No Yes           Yes

Listing 3-22Step 2 of Data Preparation

```

在清单 [3-22](#PC27) 中，我们可以看到一个已经被缩放的特征的示例记录。请注意，我还没有将分类变量转换成虚拟变量，这是清单 [3-23](#PC28) 中给出的下一步。

```
# Step 3 One-hot encode the 'features_raw' data using pandas.get_dummies()
features = pd.get_dummies(features_raw)

#Checking output
display(features.head(1),diabetics.head(1))

# Print the number of features after one-hot encoding
encoded = list(features.columns)
print("{} total features after one-hot encoding.".format(len(encoded)))

# See the encoded feature names
print(encoded)
display(features.head(1),diabetics.head(1))
        Age   A1cTEST  BPSystolic  BPDiastolic  HeartRateBPM        BMI  \
0  0.275362  0.756968    0.419591     0.153846      0.028571   0.545713

   Gender_Female  Gender_Male  Type of diabetes_None  Type of diabetes_Type 2  \
0             1           0                     0                       1

   FrozenShoulder_No     FrozenShoulder_Yes  CarpalTunnelSynd_No  \
0                  1                      0                    0

   CarpalTunnelSynd_Yes  DupuytrensCont_No     DupuytrensCont_YEs  \
0                     1                  0                      0

   DupuytrensCont_Yes
0                  1
   Diabetes status
0                1
encoding.".format(len(encoded)))
17 total features after one-hot encoding.
print(encoded)
['Age', 'A1cTEST', 'BPSystolic', 'BPDiastolic', 'HeartRateBPM', 'BMI', 'Gender_Female', 'Gender_Male', 'Type of diabetes_None', 'Type of diabetes_Type 2', 'FrozenShoulder_No', 'FrozenShoulder_Yes', 'CarpalTunnelSynd_No', 'CarpalTunnelSynd_Yes', 'DupuytrensCont_No', 'DupuytrensCont_YEs', 'DupuytrensCont_Yes']

Listing 3-23Step 3: Dummy variables

```

从图 [3-3](#Fig3) 我们可以看到热编码的代码。我已经使用了熊猫库中的 get_dummies()函数将原始特征转换成最终的基于虚拟的特征。然后，您可以看到 get_dummies 函数如何自动创建虚拟变量的输出；例如，它创建了一个性别为女性的和一个性别为男性的。完成后，我们查看总共有多少个特性被热编码，发现共有 17 个。最后，打印编码后，我们看一下数据集中的所有列。下一步和第四步也是最后一步是洗牌和分割数据。在清单 [3-24](#PC29) 中，我们可以看到生成第一次洗牌和拆分，然后是训练和测试拆分的代码。

```
#Step 4 Shuffle & Split Final Dataset
# Import train_test_split
from sklearn.cross_validation import train_test_split
from sklearn.utils import shuffle

# Shuffle and split the data into training and testing subsets
features=shuffle(features,  random_state=0)
diabetics=shuffle(diabetics,  random_state=0)
# Split the 'features' and 'income' data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features, diabetics, test_size = 0.2, random_state = 0)
print("Training set has {} samples.".format(X_train.shape[0]))
print("Testing set has {} samples.".format(X_test.shape[0]))
Training set has 531 samples.
Testing set has 133 samples.

Listing 3-24Step 4 of Data Preparation

```

清单 [3-24](#PC29) 显示了代码和结果，首先随机改组特性和目标变量，然后将其分成训练和测试数据集。我们可以看到，为训练集创建了 531 个，为测试集创建了 133 个，总共 664 个。至此，我们的数据准备步骤就完成了。我们现在进入机器学习生命周期的模型构建验证和实现阶段。在代码清单 [3-25](#PC30) 中，我现在向你展示如何使用 7 种分类算法来构建一个模型。

```
#Loading model Libraries
from sklearn import model_selection
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier

# prepare models
#Using seed to maintain reproducability and consistent results
seed = 7
models = []
models.append(('LR', LogisticRegression()))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC()))
models.append(('RFC', RandomForestClassifier()))

Listing 3-25Model Building Initializing the Classifier Algorithms

```

清单 [3-25](#PC30) 显示了分类器建模初始化的算法。我已经初始化了七个公共类。我将使用逻辑回归、决策树分类器、k 近邻分类器、线性判别分析原因、朴素贝叶斯分类器、SVC 和随机森林分类器。在清单 [3-26](#PC31) 中，你可以看到我已经从 Python 库 SKlearn 加载了这些算法，然后我通过逐个初始化它们来准备这些模型。现在，下一步是为所有模型的字典运行一个循环，运行 kfold 交叉验证，然后将结果加载到结果数据字典中，并显示每个算法或分类器的平均值和标准偏差。接下来，我以图形的形式展示了每种算法的算法比较结果。这是使用 matplot 库显示的。

表 3-3

分类器算法准确性

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

分类器算法

 | 

准确

 | 

神学博士。

 |
| --- | --- | --- |
| 实验室反应堆 | One | Zero |
| 皱胃向左移 | One | Zero |
| 近邻算法 | One | Zero |
| 手推车 | Zero point nine nine eight | Zero point zero zero six |
| 铌 | Zero point nine nine eight | Zero point zero zero six |
| 支撑向量机 | One | Zero |
| 请求评论 | Zero point nine nine eight | Zero point zero zero six |

```
# evaluate each model in turn
results = []
names = []
scoring = 'accuracy'

import warnings
warnings.filterwarnings("ignore")

for name, model in models:
    kfold = model_selection.KFold(n_splits=10, random_state=seed)
    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)
    results.append(cv_results)
    names.append(name)
    msg = "%s: %f (%f)" % (name, cv_results.mean(), cv_results.std())
    print(msg)

Listing 3-26. Model Evaluation

```

在表 [3-3](#Tab3) 中，我们可以从“精确度”一栏中查看分类器算法的精确度，我们可以看到，对于朴素贝叶斯和随机森林分类器，与精确度分数小于 1 的其他算法相比，有三种算法表现不佳。至此，我结束了关于如何在医疗保健中实现机器学习的章节。我曾尝试收集一个与医疗保健电子病历相关的数据集，在我看来，这在医疗保健领域非常常见。我敢肯定，当你试图实现代码及其结果时，读者会发现本章中的完整应用程序非常有用。您还可以使用 AUC 值或 RoC 指标对算法进行比较，这项任务我留给读者来计算和验证。您可以从以下网址了解有关 Scikit learn libraries auc metrics 的更多信息:sklearn.metrics.auc(x，y，reorder=False [ [8](#Par110) ])。您也可以从官方 Scikit learn library 网址[ [9](#Par111) ]查看计算 AUC 和 RoC 评分指标的快速方法。

## 尾注

1.  ShijunWangRonald M . Summe，医学图像分析，第 16 卷，第 5 期，2012 年 7 月，第 933-951 页 [`https://www.sciencedirect.com/science/article/pii/S1361841512000333`](https://www.sciencedirect.com/science/article/pii/S1361841512000333)

2.  杜普伊特挛缩症，由梅奥诊所工作人员， [`https://www.mayoclinic.org/diseases-conditions/dupuytrens-contracture/symptoms-causes/syc-20371943`](https://www.mayoclinic.org/diseases-conditions/dupuytrens-contracture/symptoms-causes/syc-20371943)

3.  平均值和标准偏差。[T2`http://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/2-mean-and-standard-deviation`](http://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/2-mean-and-standard-deviation)

4.  四分位距 IQR [`http://www.mathwords.com/i/interquartile_range.htm`](http://www.mathwords.com/i/interquartile_range.htm)

5.  为什么基于树的模型对异常值具有鲁棒性？[T2`https://www.quora.com/Why-are-tree-based-models-robust-to-outliers`](https://www.quora.com/Why-are-tree-based-models-robust-to-outliers)

6.  [https://www . dummies . com/education/math/statistics/how-to-interpret-a-correlation-coefficient-r/](https://www.dummies.com/education/math/statistics/how-to-interpret-a-correlation-coefficient-r/)

7.  [T2`https://www.medicalnewstoday.com/releases/11856.php`](https://www.medicalnewstoday.com/releases/11856.php)

8.  Scikit 了解 Auc 指标: [`http://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html)

9.  Scikit 学库 RoC 和 AUC 评分: [`http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)