# 4.医疗保健人工智能案例研究

声明:本书中的案例研究来自现实生活中的组织。已采取措施确保组织的名称及其员工的姓名被更改，并且与我的客户没有任何相似之处。熟悉医疗保健行业的读者肯定会发现这些情况非常实用和有见地。

在我们开始看案例研究之前，让我们先看看案例研究方法及其优势。有人可能会说，案例研究方法主要用于 MBA 项目，尤其是这种方法的发源地哈佛商学院[ [`https://www.hbs.edu/mba/blog/post/3-benefits-of-the-case-method`](https://www.hbs.edu/mba/blog/post/3-benefits-of-the-case-method) ]。在这里，我们将讨论使用 Python 的机器学习应用程序，以及如何将这种方法用于涉及编程代码的解决方案。在我回答这个具体问题之前，让我们先来看看案例研究方法今天带来的三个优势，以及我们在商业环境中通过使用案例研究获得的其他好处。

我们从案例研究方法中得到的第一个好处是，为案例研究提供解决方案的人不仅要阅读案例和案例研究提出的问题，还要对手头的业务问题做一些背景工作，供问题解决者用来解决问题。在案例研究解决方案完成后，这些信息会留在当事人那里，并以非正式的方式继续学习。没有必要为回答案例研究而填充任何网状课程，因为它们是独特的业务情况，并且不一定有支持其解决方案的理论。

使用案例研究方法的第二个好处是，在给出案例研究业务问题的解决方案时，人们应该对案例问题提出自己的独立观点。这是将机器学习和 Python 代码应用于业务情况的实践，然后当你仔细观察它并试图通过编写解决特定业务问题的代码来为它们提供解决方案做准备。值得注意的是，在案例研究方法中，没有绝对的对错，因为一个特定的业务问题可以通过多种方式解决。这里的实践是尽可能多地提出商业问题的解决方案，并在给定的情况下探索最有价值的方案。因此，使用案例研究方法解决问题的第三个优势是，它在商业环境中很重要，并且是应用机器学习工程师最受欢迎的技能。

我从现实生活的例子中仔细选择了这些案例研究，我很确定读者会发现它们很有用。我建议你在回答每个案例研究中的问题之前至少阅读两遍案例研究。在我看来，你应该做的是，先把案例研究文中给出的业务情况读一遍，理解一遍，然后看每一个问题再回到案例研究文中，把情况再理解一遍。一旦你看了关于每个问题的案例研究，你应该开始在你的头脑中制定解决方案，如果你在医疗保健行业面临这种情况，你会怎么做。回想一下我在第 [3](03.html) 章给大家展示的机器学习应用的过程。在制定解决方案时，注意不要错过任何步骤。

一旦您有了一个您认为在给定的业务情况下最合适的解决方案的草图，那么您应该继续查看所提议的解决方案以及给定案例研究的代码。请记住，在案例研究法中，不同的人可以提出不同的解决方案，解决方案没有对错之分。然而，它遵循的标准是，解决方案应该满足业务问题的所有需求，并且应该是业务可以接受的。在本书给出的案例研究解决方案中，我给出了企业可以接受的解决方案，因此读者可以将其作为基准来判断他们为案例研究提出的解决方案。目标是首先创建您自己的解决方案，而不看我在本书中给出的解决方案，以使您开始独立思考，并开始在医疗保健业务场景中应用机器学习。

## 案例研究 1:实验室协调员问题

周一早上，Deshmukh 博士坐在办公室里，他面前的笔记本电脑屏幕上显示着一份财务部门的报告，内容是关于他的医疗保健组织 DIRECTPyth 诊断中心全球连锁的财务状况，该组织由全球 250 多个诊断中心组成。

DIRECTPyth 的核心业务是糖尿病诊断中心。DIRECTPyth 诊断中心的突然增长发生在过去的 5 年里。DIRECTPyth 最初是一家本土诊断公司，在印度只有四个中心。在过去 10 年的运营中，它将其诊断中心扩展到了印度以及东南亚、中东和加拿大的所有主要城市。大多数海外中心是在过去 5 年中出现的，因为诊断公司看到人们对糖尿病诊断的需求迅速增长。

世界卫生组织关于糖尿病的报告( [`http://www.who.int/diabetes/global-report/en/`](http://www.who.int/diabetes/global-report/en/) )显示，糖尿病现在已经成为世界范围内的流行病。2012 年，糖尿病导致 150 万人因心脏病发作、中风、失明、肾衰竭和下肢截肢而死亡。世界各国政府已经通过在媒体上运行关于糖尿病流行的信息程序来传播意识。德里·福特还强调，自 1980 年以来，二型糖尿病患者的数量一直在增加，到那时已经翻了两番。为了控制这种流行病，世界各国政府在过去 5 年中加强了预防和治疗糖尿病的计划。DIRECTPyth 糖尿病诊断医疗保健链正处于这场流行病的中间，为任何人提供测试，以诊断他们是否患有糖尿病。

德什穆克博士正在看的报告指出，在过去的两年里，经济损失高达 2 亿美元。公司的财务状况如表 [4-1](#Tab1) 所示。

表 4-1

两年期财务概要报告

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

财务概要

(百万美元)

 | 

2015-2016 财年

 | 

2016-2017 财年

 |
| --- | --- | --- |
| 诊断收入 | Nine hundred and thirty | One thousand two hundred and twenty-one |
| 运营成本 | One thousand and thirty-one | One thousand three hundred and fifty-four |
| 诊断中心的平均运营天数 | One hundred and eighteen | One hundred and six |
| 非经营损失 | One hundred and one | One hundred and thirty-three |

我来简单解释一下表 [4-1](#Tab1) 。给出了两个财政年度的财务数据:2015-2016 年和 2016-2017 年。第 2 列和第 3 列中给出的状态是财务部门提供的诊断收入，您可以看到 DIRECTPyth 组织的收入每年都在增长。第一年和第二年的运营成本都高于诊断收入。最后一行给出了非手术造成的损失，这是从诊断收入中直接减去手术成本。这两年的总损失为 2 . 34 亿美元。第三行提供了全世界所有 DIRECTPyth 诊断中心的平均运行天数。DIRECTPyth 的平均运行天数为 118 天，远远低于 DIRECTPyth 内部衡量其性能的基准数 200。我们还可以看到，在 2016 年和 2017 年，诊断中心的平均运营天数下降到了 106 天。非操作性损失也从第一年的 1.01 亿美元上升到第二年的 1.33 亿美元。

为了让 DIRECTPyth 在市场上保持竞争力，它需要降低运营成本和非运营损失，现在就需要采取切实措施。

该报告清楚地表明了由于人力资源的限制而造成的损失。德什穆克博士要求与 DIRECTPyth 的人力资源经理进行一次晨会。目的是讨论经济损失并找出这个问题的最主要原因。人力资源经理是 Abbey 女士，她将向 Deshmukh 博士介绍直接造成财务损失的原因以及今后如何防止这些损失。然后，德什穆克博士起床，为上午 10 点的会议做好了充分准备。艾比女士和她的工作人员一起到达会场。问候结束后，她开始介绍两年的财务概要。她向德什穆克博士指出，手术费用在几年间上涨了 131%。这一损失也是同样的百分比，因为它是从业务成本中得出的。她解释说，诊断中心的平均运营天数是根据诊断中心在全年任何给定工作日保持开放的天数计算的。DIRECTPyth 的目标平均运营天数是 200 天。她展示了表 [4-2](#Tab2) 中给出的平均运行诊断中心数据的细分。

表 4-2

平均运营天数细分(AOD)数据

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

平均运营天数

 | 

达到 AOD 基准的中心数量

 | 

未达到 AOD 基准的中心数量

 |
| --- | --- | --- |
| 印度 | Thirty-two | Two hundred and thirty-four |
| 海外的 | Thirteen | Ninety-eight |
| 加固的 | Forty-five | Three hundred and thirty-two |
| %年龄 | Eleven point nine | Eighty-eight |

平均运行天数的细分数据显示，在全球范围内，DIRECTPyth 的诊断中心达到 200 天基准的百分比仅为 11.9%，未达到 AOD 基准的中心百分比为 88%。这显示了 DIRECTPyth 问题的严重性和范围。它还表明，由于这些中心没有达到 AOD 基准，收入损失严重。为了进一步深入研究这个问题，Abbey 女士展示了与 DIRECTPyth 组织的实验室诊断设施的人力资源相关的数据。该数据在表 [4-3](#Tab3) 中给出。

表 4-3

DIRECTPyth 实验室的人力资源数据

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"></colgroup> 
| 

DIRECTPyth 实验室的人力资源

 | 

实验室协调员

 | 

实验室技术员

 | 

实验室正在等待

 |
| --- | --- | --- | --- |
| 平均当前天数 | Eighty-eight | Ninety-seven | One hundred and ninety-four |
| 平均缺勤天数 | Twenty-six | Fifteen | eight |
| 损耗率(%) | 12% | 9% | 6% |

我们可以从表 [4-3](#Tab3) 中看到，最高的缺勤发生在实验室协调员和实验室技术员角色。实验室服务员平均缺勤率最高，缺勤率最低。最好的数据来自 DIRECTPyth 实验室的工资系统，记录了实验室每个人力资源的每日出勤情况。目前的总天数被视为 220 个生产工作日的基准值。实验室协调员的角色是与走进诊断实验室的客户进行互动，带他们了解实验室中可用的各种诊断选项，然后帮助他们找到最适合其糖尿病状况的测试。实验室协调员检查患者是否已经在诊断中心注册，然后调出计算机记录并请求新的测试。DIRECTPyth 的技术人员实际上是为排队等候的病人进行实验室测试的人。实验室服务员是从实验室技术人员那里获取特定患者的数据，将数据输入计算机，然后生成报告提交给患者的人。这三个关键职位对于 DIRECTPyth 诊断中心的业务运营非常重要。Abbey 女士在会上表示，实验室协调员和实验室技术员的高缺勤率导致了 DIRECTPyth 的收入损失。本组织迫切需要找到如何提高生产率和减少这一角色的缺勤率。我们还可以看到，实验室协调员的流失率最高(12%)，其次是实验室技术员(9%)。最低的流失率(6%)表明 DIRECTPyth 需要找到一种方法来降低实验室协调员的缺勤率和流失率。最重要的是实验室协调员的角色，那里的缺勤率和自然减员率非常高。人力资源部应该想办法降低缺勤率和离职率。在过去的三年里，他们尝试了五种方法，但在寻找解决方案方面收效甚微。因此，很明显，如果 DIRECTPyth 想要提高其盈利能力并减少损失，它需要紧急解决实验室协调员角色的缺勤和流失问题。

需要立即实施的解决方案应该是使用技术来模拟实验室协调员的角色。DIRECTPyth 获得了外国投资者的资助，能够投资于技术，以提高效率，从而增加收入。你需要使用基于 Python 的机器学习来解决和回答本案例研究中给出的问题。

1.  你认为 DIRECTPyth 诊断中心亏损的原因是什么？

2.  我们正在处理什么样的人类问题，你认为如何解决这些问题？

3.  你认为技术能帮助解决你在问题 2 中发现的问题吗？

4.  基于 Python 的机器学习解决方案能够解决 DIRECTPyth 的这些问题吗？

5.  你提议的基于 Python 的机器学习解决方案是什么？请为您的解决方案使用 Python 3.x 源代码。

6.  你对你的解决方案给出了什么样的商业理由，你认为它会被 DIRECTPyth 的商业领袖所接受？

我建议你先试着独立回答这些问题，然后看看这本书给出的解决方案。请注意，我给出的解决方案是这个业务场景中可以给出的众多解决方案之一。最终决定您的解决方案是否好，是否能够解决他们的业务问题的是业务所有者。

### 亲提示

在应用机器学习中，我们机器学习顾问与一个组织的业务领导密切合作，以确定什么对他们有效。永远记得和他们一起讨论，提出哪怕是一个不完整的小计划，并在将其转化为成熟的解决方案之前对其进行审查。这样可以节省你很多浪费的会议和精力。

现在让我试着用我自己的方式回答这些问题，给出我提出的解决方案，该方案已被组织接受。

1.  你认为 DIRECTPyth 诊断中心亏损的原因是什么？

DIRECTPyth 诊断中心损失的原因是高运营损失，大约 88%的诊断中心没有达到平均运营基准。造成这种情况的真正原因是组织中实验室协调员的高缺勤率和损耗率。实验室协调员的缺勤率非常高，为 26%，自然减员率为 12%，而实验室技术员的缺勤率为 15%，自然减员率为 9%。人力资源部想出了五种不同的方法来阻止自然减员和旷工，但收效甚微。

1.  我们正在处理什么样的人类问题，你认为如何解决这些问题？

我认为我们面对的是士气低落的员工，这就是我们看到高缺勤率和离职率的原因。

1.  你认为技术能帮助解决你在问题 2 中发现的问题吗？

在我看来，在人类无法以业务所需的最佳水平执行的领域使用技术是引入自动化、机器学习和人工智能的合适场景。技术的好处在于它可以重复做任何给定的任务，而不会感到无聊或疲劳。它还可以使用数据智能，并经过训练非常容易地执行专家任务。在 DIRECTPyth 诊断中心的情况下，我们可以使用技术来取代实验室协调员的任务，将自动化实验室机器放在它的前提下，从而让客户选择他们想要执行的实验室测试。自动化实验室机器可以运行基于 Python 的机器学习程序，帮助客户选择适合其场景的最佳诊断测试。

1.  基于 Python 的机器学习解决方案能够解决 DIRECTPyth 的这些问题吗？

是的，基于 Python 的机器学习系统可用于自动化实验室中的整个过程，从客户进来并选择诊断包以生成实验室测试，到生成报告并为客户提供有意义的解释的下一阶段。基于 Python 的机器学习系统可以连接到任何现代自动化实验室测试机器，以从中获得输出。

1.  你提议的基于 Python 的机器学习解决方案是什么？请为您的解决方案使用 Python 3.x 源代码。

在本书中，我将给出一个简短的解决方案；但是，它将模拟我在客户的生产环境中提供给客户的真实解决方案。读者可以在现实世界中类似的情况下使用自己的想法来构建这个解决方案。给读者一个警告:这是我用来创建聊天机器人的一个非常简单的方法；然而，它并不限制用户通过使用本书中给出的代码来扩展其功能。现实生活中的聊天机器人比我在这里给出的代码更复杂，因为它涉及到使用 nltk . corpora nltk 知识库的情感分析。它还将使用词汇化自然语言处理技术，为 Python 程序的用户提供最佳响应。这个解决方案是并且应该被认为是一个模板代码，而不是最终的解决方案，因为不可能在一本书里写一个完整的生产聊天机器人的源代码，因为它会运行成数百万行代码。我将带您浏览代码，让您了解为什么要编写代码的每个部分，包括它的意图和功能，以及如何在生产中应用它的一些技巧。

*   业务需求:该解决方案的业务需求是模拟实验室协调员的工作，并通过聊天界面与用户进行交互。我将向您展示一些适用于此案例研究场景的用例。

### 亲提示

甚至在你开始编码之前，将你的工作划分成简短的用例，并得到系统实际用户的认可，因为你将为他们开发。如果您跳过这一步，很可能您将开发一个用户可能拒绝的产品，因为您可能误解了一些需求。

*   用例:作为一个用于糖尿病诊断的自动聊天机器人的用户，我应该能够知道我过去的测试数据记录，以便我检查我的历史。

*   用例:作为一个用于糖尿病诊断的自动聊天机器人的用户，我应该能够知道该中心进行的测试类型及其目的，以便我的医生和我可以决定进行测试。

*   用例:作为一个用于糖尿病诊断的自动聊天机器人的用户，我应该能够得到我的测试结果，这样我就可以得到一份报告。

*   用例:作为一个用于糖尿病诊断的自动聊天机器人的用户，我应该能够得到关于我的测试结果的建议，以便我能够知道未来的行动过程。

对于 DIRECTPyth 诊断中心，有比这里给出的更多的可用用例。然而，为了简化流程，我们将只考虑我们的解决方案的这四个用例。

现在我们来看看图 [4-1](#Fig1) 中的流程图，它应用了其他聊天机器人在与客户交互时将遵循的流程。请记住，我对这个解决方案使用了极简的方法，因为它不是一个生产代码；这是给你一个想法，如何应用机器学习领域的模拟实验室协调员在医疗保健部分。

![../images/464968_1_En_4_Chapter/464968_1_En_4_Fig1_HTML.jpg](../images/464968_1_En_4_Chapter/464968_1_En_4_Fig1_HTML.jpg)

图 4-1

客户和实验室协调员聊天机器人之间的交互过程

在图 [4-1](#Fig1) 中，我们可以看到，当客户走进并与实验室协调员中的聊天机器人会面时，该流程就开始了，因此在该流程中没有人工交互或人工监督。这个售货亭有传感器，可以检测附近是否有人，并向顾客发出问候。在该过程的下一部分，如果是现有客户，聊天机器人会要求客户提供会员 ID。现在，如果在数据库中找到了客户提供的会员 id，实验室协调员 chatbot 必须根据提供的输入做出决定；然后，它向客户显示最后的测试记录结果。如果它不是现有客户，那么聊天机器人会显示糖尿病测试——许多列出了实验室可用的整套测试。一旦客户从列表中选择了测试，实验室协调员将进行测试，然后生成报告。在我们的例子中，在 Python 程序中。机器人要求客户坐在自动测试机旁边进行糖尿病诊断的部分已经被我标记了，我会在标记发生的代码中指明这一点。我这样做的原因是因为 Python 程序会为报告生成随机结果；然而，在生产环境中，该数据将来自承担测试的实验室技术人员机器。在现实世界中，通过内部医疗记录与医生共享报告的过程中会有其他步骤；然而，为了保持简单，我在这个解决方案中跳过了所有这些过程。

现在我们已经定义了聊天机器人的流程图，我们可以进入 Python 代码来实现简单的聊天机器人了。

### 小费

在您的机器上运行这个例子之前，加载 wordnet lemmatizer 和 punkt 包。

```py
Install using the following commands:
import nltk

nltk.download('wordnet')
[nltk_data] Downloading package wordnet to
[nltk_data]     C:\Users\PMAUTHOR\AppData\Roaming\nltk_data...
[nltk_data]   Unzipping corpora\wordnet.zip.
Out[4]: True
import nltk
nltk.download('punkt')

```

清单 [4-1](#PC2) 展示了我们聊天机器人的初始化代码，其中第一行声明我们的代码遵循 UTF 8 编码。在这之后我们有下一组语句，它们导入 GUI 库 tkinter 及其组件，如潦草的文本图像和图像 TK，以及时间包(用于配置睡眠功能)。我还引入了 random 函数，因为它可以帮助我们的聊天机器人从我们的答案中随机选择，这一点我们稍后会讲到。

```py
# -*- coding: utf-8 -*-
"""
Created on Sat Mar 24 10:20:18 2018

@author: PUNEETMATHUR
"""
#Loading tkinter libraries which will be used in the UI of chatbots
import tkinter
from tkinter import *
from tkinter.scrolledtext import *
from tkinter import ttk
import time
from PIL import ImageTk, Image
import tkinter

#Loading random for random choices in our chat program
import random

Listing 4-1Loading chatbot User Interface

```

清单 [4-1](#PC2) 显示了我们聊天机器人的初始代码。在清单 [4-2](#PC3) 中，我们看到了使用 tkinter 包实现闪屏的 Python 代码。为了做到这一点，我们首先创建一个名为 tkinter window TK 对象的 Splash 的新对象，然后我给它一个欢迎用户进入 Splash 屏幕的标题。然后，我使用飞溅的对象给高度和重量使用几何函数。我正在创建一个 1000×100 像素高和重的飞溅窗口，所以我在几何函数的参数中使用了 1000×100。接下来，我用参数 background 等于绿色的配置函数给 Splash 窗口设置了一个背景色。为了在程序加载时显示要求用户等待的文本，我使用了中央库中 label 对象的 label 小部件，名为 w，在初始化 w 时，我将它链接到 Splash 对象，这是将要创建标签的窗口。因此，第一个参数是标签与闪屏窗口的连接位置。接下来的第二个参数是你输入你想要标签显示的文本，我已经输入了一个字符串。我输入的第三个参数是字体，为了显示文本，我使用了 26 号 Helvetica 字体。下一个参数是 FG，它代表窗口的前景色，前景色是标签的文本和它将被显示的颜色。在我的例子中，我使用了白色。在下一个参数中，我使用了 BG，它代表背景颜色，我给了它一个绿色的值。在下一条语句中，我修改了标签，以便它可以显示在启动窗口上。完成后，我使用 Splash 的 update 方法，以便标签在 Windows 屏幕上更新。一旦屏幕出现，我们希望它在用户面前出现一段时间，您可以通过让程序休眠 X 秒来指定时间。我在下一个代码语句中使用了 time to sleep，参数为 6，表示程序将休眠 6 秒。您可以尝试这样做，看看什么适合您的闪屏，您可以相应地修改秒数。在闪屏显示 6 秒钟后，我希望它消失，因此我会识别该屏幕，然后在接下来的两个语句中销毁它。

```py
#Splash Screen
splash = tkinter.Tk()

splash.title("Welcome to Applications of Machine Learning in Healthcare, Retail & Finance")
splash.geometry("1000x100")
splash.configure(background='green')
w = Label(splash, text="DIRECTPyth Diabetes Diagnostics Chabot by Puneet Mathur\nLoading...",font=("Helvetica", 26),fg="white",bg="green")
w.pack()

splash.update()
time.sleep(6)
splash.deiconify()
splash.destroy()

Listing 4-2Splash Screen

```

现在是时候加载我们的聊天机器人应用程序的主聊天窗口了，因此在清单 [4-3](#PC4) 中，您可以看到加载聊天窗口所需的代码。在清单 [4-3](#PC4) 的第一条语句中，我在 tkinter 包中创建了一个 TK 类的窗口对象。然后，我使用滚动条类中的实例化 nS 对象将滚动条添加到窗口中，并使用 window 实例化滚动条类，使其与 window 对象相关联。如果你有滚动条而没有文本，那么它将变得无用，所以在下一个语句中，我用窗口对象实例化了一个文本框。这个文本框被称为聊天消息，我们将在以后的程序中广泛使用它，因为用户的所有输入和输出都将通过这个文本框。在下一个语句中，我使用 focus set 对象来设置文本框上的焦点。在下一个语句中，我打包了滚动条，并使用第一个参数将滚动条固定在窗口的右侧，并使用 y 轴作为滚动条。在下一条语句中，我将文本框 chat MSG 移动到窗口的顶部，并在 y 轴上填充它。在下一个语句中，我使用滚动条的 config 方法来配置从聊天消息评论中获取 nd。我还将 chatmsg 文本框与滚动条相链接，以设置–s.config 方法和 yscrollcommand 函数，然后与 s . config 的值相链接。现在，下一步是通过创建 stringware 类的对象来为输入用户和输入字段创建一个条目，然后通过实例化 entry 类并将其附加到第一个参数中的窗口以及第二个参数中的文本创建的 stringware 对象来将其与输入字段相链接。如果您不这样做，那么您的文本框将无法获取文本和回复文本。在下一条语句中，我将输入字段附加到底部，并沿 x 轴填充它。这是用户将要输入所有数据并与我们的聊天机器人进行交互的地方。在下一条语句中，我创建了一个可变的下划线文本，欢迎用户访问诊断中心。请记住，这将作为一个自动化程序在 kiosk 中运行，因此在客户到达时，kiosk 上会连接传感器，DIRECTPyth 将装配该程序。然而，在这个代码实现中，所有这些都被删除了，因为不可能在这样一本简短的书中展示完整的产品代码。在下一个语句中，我们使用 chat MSG，这是我们的文本框，并插入文本的值，这是我们的变量。在下一条语句中，我们将焦点转移到文本框。

```py
#Initializing tkinter library for UI window show up
window = tkinter.Tk()
s = tkinter.Scrollbar(window)
chatmsg = tkinter.Text(window)
chatmsg.focus_set()
s.pack(side=tkinter.RIGHT, fill=tkinter.Y)
chatmsg.pack(side=tkinter.TOP, fill=tkinter.Y)
s.config(command=chatmsg.yview)
chatmsg.config(yscrollcommand=s.set)
input_user = StringVar()
input_field = Entry(window, text=input_user)
input_field.pack(side=tkinter.BOTTOM, fill=tkinter.X)
bot_text="Welcome to DIRECTPythPyth Diagnostic Center\n"
chatmsg.insert(INSERT, 'Bot:%s\n' % bot_text)
bot_text = "Press enter to continue "
chatmsg.insert(INSERT, 'Bot:%s\n' % bot_text)
chatmsg.focus()

Listing 4-3Creating the Chatbots Window and Welcoming the User

```

在现实世界中，使用 NLP 的机器学习的生产级应用程序中，您需要首先花时间与业务人员在一起，并开发一个语料库，它只不过是业务词典或组织日常生活中使用的术语。由于这个实现很短，我只给你一个关于如何在清单 [4-4](#PC5) 中构建语料库的想法。您将看到，我已经使用 Python 变量类型的列表创建了我们的诊断语料库。第一张单子很棒；这只不过是我们的聊天机器人在新用户到来时给他们的各种问候的列表。下一个列表是添加确认，是，耶，耶，哟。你可以添加更多的确认，这个列表可能会很大，这样你才能理解用户想说什么。该列表的重要部分是该列表正在为我们的聊天机器人学习，我们提供了一些现成的答案以及客户可以在该语料库中提出的问题。在下一个列表中，我使用成员 ID，我已经使用了五个成员 ID，因为这只是一个原型应用程序。然而，在现实世界中，您可能有数百甚至数千个成员 id，这些数据可能来自一些平面文件或数据库，比如 mongo DB。在下一个列表中，我使用 customer 来捕捉这样的反应，并帮助我们的机器人识别它们，这是他们说 hello，hi 或 hey 的输入。在下一个列表答案中，我只给出了两个陈述:第一个是肯定的陈述，第二个是否定的陈述。我们将在后面查看我们的程序，看看这在实践中是如何使用的。在接下来的列表中，我使用了一些简单的问题及其回答；然而，它们可能没有被使用过。但是如果聊天机器人知道问题和回答，它会给你一个如何反应的想法。在下一个列表中，我已经给出了测试，它只是当用户输入他们的成员 ID 时弹出的菜单。我们有五个测试可以进行；然而，请记住，在诊断中心的真实业务中，他们有数百项测试，此外，他们还根据不同的客户要求打包这些测试，例如糖尿病患者概况测试和心脏状况测试，这只是一个例子。在下一组测试响应中，我使用了用户可以在之前的测试列表中输入的选项。例如，在测试响应中，一个对应于测试列表的第一项，HB A1c 测试，等等。

```py
#Diagnostics Corpus for the chatbots
greet=['Hello welcome to DIRECTPythPyth','Hi welcome to DIRECTPythPyth','Hey welcome to DIRECTPythPyth','Good day to you welcome to DIRECTPythPyth']
confirm=['yes','yay','yeah','yo']
memberid=['12345','12346','12347','12348','12349']
customer = ['hello','hi','hey']
answer = ['I understand you feel happy but please stay to the point and select one of the options',"I sympathize with you, However please do not deviate from the topic"]
greetings = ['hola Welcome to DIRECTPythPyth again', 'hello Welcome to DIRECTPythPyth again', 'hi Welcome to DIRECTPythPyth again', 'Hi Welcome to DIRECTPythPyth again', 'hey! Welcome to DIRECTPythPyth again', 'hey Welcome to DIRECTPythPyth again']
question = ['how are you?', 'how are you doing?']
responses = ['Okay', "I'm fine"]
another = "do you want another test?"
tests=['Type 1 for hbA1c test', "Type 2 for Blood Viscosity test","Type 3 for Heart rate test","Type 4 for Blood Oxygen test","Type 5 for Blood Pressure"]
testresponse= ['1','2','3','4','5','6']

Listing 4-4The Diagnostics Corpus

```

现在我们从聊天机器人的实际程序开始，定义它的程序结构。在清单 [4-5](#PC6) 中，我们可以看到这段代码是我们聊天机器人的核心。在代码的第一部分，我初始化了一些全局变量。第一个是第一开关，我给它赋值为 1。这用于确定聊天机器人是否是第一次运行。接下来，我初始化一个新的 ID。对于第一次到达诊断中心的人来说，这只是一个新的会员 ID。接下来，我用值 0 初始化了成员 ID (Mem ID)变量。在代码的下一部分，我使用了一个名为 chat 的函数，它有一个 event 参数，每当一个带电的事件发生时，它就会被触发。在这个函数中，我导入了时间和随机包，并声明了全局成员 id 变量或条件变量以及第一个开关变量。在下一个语句中，有一个 if 条件，我检查第一个 switch 是否等于 1，如果它等于 1，那么它通过从网格列表中选择一个值来对随机选择进行网格划分，我们在前面已经看到过。

它将 bot 文本变量中的值插入到 chat MSG 文本框中，因此当 chatbot 第一次运行时，用户能够看到一个问候语。然后它给出一个声明，如果你是 DIRECTPyth 的现有成员，那么你可以输入你的成员 ID；否则，根据用户输入，如果您不是成员，请输入值“否”。第一个开关变量现在的值为 2，如果用户输入一个值，它将再次触发并进入下一个 if 语句，其中第一个开关不等于 1。因此，这意味着这个特定的 if 条件将只在用户第一次问候之后运行，并且用户输入的这个值是通过输入字段接收的。我们在这里使用 lower 函数，这样我们就不必处理大写和小写，我们把值输入到下划线 get 变量中。检查该值以查看用户输入的成员 ID 是否在成员 ID 列表中找到，如果您还记得，我们有五个 ID，如果找到了，则满足 if 条件，内存函数存储用户在输入下划线 get 变量中输入的任何内容。然后填充机器人文本，感谢用户成为忠诚的成员，并向用户显示一个菜单，告诉用户最后一个退出程序的选项是什么类型的测试。

如果用户输入 no，这意味着它是一个新用户，并且他们没有成员 ID，则生成一个新的成员 ID。请记住，因为我正在创建一个原型程序，所以我不会详细讨论存储这个新 ID 和自动创建这个 ID 的细节。然而，在现实世界中，您将把这个值存储在一个平面文件或一个 mongo DB 数据库中，然后增加这个值以获得新的用户 ID。如果用户在下一个 if 语句中输入 1 到 6 之间的有效值，我会检查用户输入的 get 语句是否在测试响应列表中。如果您还记得的话，测试响应列表有从 1 到 6 的数字，所以这个 if 语句只有在测试响应被满足时才会被触发。一旦收到有效的响应，机器人模拟器会给用户一条消息，让他们将手指放在信息亭的手指面板上进行测试。它等待 10 秒，我在这里放了一个延迟计数器。

然而，在现实世界中，会有一个传感器来检测用户何时将手指放在手指面板上，并自动开始读取数据。在我们的例子中，我使用了一个 for 循环来模拟 10 秒，并使用聊天消息的时间数据表将延迟计数器休眠 1 秒。我将这些值插入聊天机器人，向用户显示我正在读取它们的值。在 for 循环的 10 个步骤完成后，机器人会说，“请等待，正在生成您的报告”，然后它会休眠 2 秒钟。然后，基于用户给出的测试输入，它为每个测试生成随机数。例如，让我向您介绍一下 if 语句，其中用户输入的值为 1，这意味着根据菜单，用户想要进行 HB A1c 测试。在这种情况下，机器人会生成一个介于 4 和 10 之间的随机数，这是 A1c 测试的有效值，并且会类似地向用户显示结果。在它完成之后，我向你展示我们如何给我们的聊天机器人添加智能，它正在模拟一个实验室协调员，而实验室协调员永远不会对报告的结果发表意见。然而，我们增加了第一次测试 HP A1c 的值，我已经向您展示了它如何根据结果智能地告诉用户他们是否患有糖尿病、糖尿病前期或没有糖尿病。在我们的例子中，它在 if 条件下寻找一个值，变量 HB A1c 在 4 到 5.6 之间。如果这个条件被满足，那么它说你没有糖尿病。它再次检查 HB A1c 变量，如果值在 5.7 和 6.4 之间，它说你是糖尿病前期。如果 HB A1c 变量值大于或等于 6.5，则患者被诊断为糖尿病。这种智能还可以添加到其他测试中，如血液粘度测试(范围从 30 到 44 MB)、心率(范围从 60 到 100 次/分钟)、血氧(范围从 95 到 100)以及血压收缩压和舒张压。您可以自己在这些条件下添加这种智能，我将让您来修改代码并更智能地使用它。

```py
#Global variable to check first time greeting
firstswitch=1
newid="12310"
memid=0

def chat(event):
    import time
    import random
    global memid
    condition=""
    #Greet for first time
    global firstswitch

    if (firstswitch==1):
        bot_text = random.choice(greet)
        chatmsg.insert(INSERT, 'Bot:%s\n' % bot_text)
        bot_text = "If you are an existing Member of DIRECTPythPyth please enter your membershipid: or enter no if you are not a member"
        chatmsg.insert(INSERT, 'Bot:%s\n' % bot_text)
        firstswitch=2
    if (firstswitch!=1):
        input_get = input_field.get().lower()
        if any(srchstr in input_get for srchstr  in memberid):
            memid=input_get
            bot_text = "Thank you for being a loyal member of DIRECTPythPyth\n Please choose a test from following menu to continue\nType 1 for hbA1c test\nType 2 for Blood Viscosity test\nType 3 for Heart rate test\nType 4 for Blood Oxygen test\nType 5 for Blood pressure test\nType 6 to exit\n\n"
        elif (input_get=="no"):
            memid=newid
            bot_text = "Your new Memberid is: " + newid + " Please remember this for future reference.\n Please choose a test from following menu to continue\nType 1 for hbA1c test\nType 2 for Blood Viscosity test\nType 3 for Heart rate test\nType 4 for Blood Oxygen test\nType 5 for Blood pressure test\nType 6 to exit\n\n"

        elif any(srchstr in input_get for srchstr  in testresponse):

                bot_text = "Please place any of your finger on the Finger panel above to conduct the test"
                chatmsg.insert(INSERT, 'Bot:%s\n' % bot_text)
                delaycounter=0
                for delaycounter in range(0,10):
                    bot_text = str(delaycounter)
                    time.sleep(1)
                    chatmsg.insert(INSERT, 'Bot:%s\n' % bot_text)
                bot_text = "Please wait generating your report\n"
                chatmsg.insert(INSERT, 'Bot:%s\n' % bot_text)
                time.sleep(2)
                if (input_get=="1"):
                    hba1c=random.randint(4,10)
                    bot_text = "MemberID: " + str(memid) + " Your hbA1c test result is: " + str(hba1c)
                    if(hba1c>=4 and hba1c<=5.6):
                        condition="You don't have diabetes"
                    elif(hba1c>=5.7 and hba1c<=6.4):
                        condition="You are Prediabetic"
                    elif(hba1c>=6.5):
                        condition="You are Diabetic"
                    bot_text=bot_text +  " Your condition is: " + condition    

                    chatmsg.insert(INSERT, 'Bot:%s\n' % bot_text)
                elif (input_get=="2"):
                    viscosity=random.randint(20,60)
                    bot_text = "MemberID: " + str(memid) + " Your Blood Viscosity level test result is: " + str(viscosity)
                elif (input_get=="3"):
                    heartrate=random.randint(40,150)
                    bot_text = "MemberID: " + str(memid) + " Your Heart rate test result is: " + str(heartrate)
                elif (input_get=="4"):
                    oxygen=random.randint(90,100)
                    bot_text = "MemberID: " + str(memid) + " Your Blood Oxygen level test result is: " + str(oxygen)
                elif (input_get=="5"):
                    systolic=random.randint(80,200)
                    diastolic=random.randint(80,110)
                    bot_text = "MemberID: " + str(memid) + " Your Blood Pressure test result is: Systolic: " + str(systolic) + " Diastolic: " + str(diastolic)
                elif (input_get=="6"):
                    import sys
                    window.deiconify()
                    window.destroy()
                    sys.exit(0)
        else:
         from nltk.stem import WordNetLemmatizer
         import nltk
         if((not input_get) or (int(input_get)<=0)):
                        print("did you just press Enter?") #print some info
         else:
             lemmatizer = WordNetLemmatizer()
             input_get = input_field.get().lower()
             lemvalue=lemmatizer.lemmatize(input_get)
             whatsentiment=getSentiment(lemvalue)
             if (whatsentiment=="pos"):
                 bot_text = answer[0]
                 #print("Positive Sentiment")
             elif (whatsentiment=="neg"):
                 bot_text = answer[1]
             #print("Negative Sentiment")
             chatmsg.insert(INSERT, '%s\n' % lemvalue)
             #bot_text = "I did not understand what you said !"

    chatmsg.insert(INSERT, 'Bot:%s\n' % bot_text)
    #label = Label(window, text=input_get)
    input_user.set(“)
    #label.pack()
    return "break"

Listing 4-5Chatbot Code

```

在这个聊天机器人中，我用 NLP 展示了如何在这样的应用程序中进行情感分析。但是，请记住，我使用的 NLP 是有限制的，因为我无法编写数百万行代码来模拟现实世界的聊天应用程序。我简单地使用了一个小的训练集作为列表，但是在真实的场景中，您将使用一个文件，该文件可能会有来自客户的反馈，并且会包含积极和消极情绪的分类。让我们浏览一下代码，以便简单地理解我是如何在获取情感函数中进行情感分析的。你可以参考图 [4-6](#Fig6) 中的代码，我在那里导入了 nltk 库，然后从 nltk 中导入了 tokenize 和 word tokenize 以便进一步分析。在这个例子中，我只使用了三个步骤来执行情感分析；但是，请记住，要进行全面的情感分析，还需要遵循更多的步骤。

在第一步中，我使用训练数据来建立糖尿病语料库，这可能只是客户对响应的积极和消极反馈分类。积极情绪被归类为 POS，消极情绪被归类为 energy。完成这些后，我创建了一个字典，并通过将每个单词转换成小写来标记它。在这之后，我为我们必须组织的每个单词创建一个字典，并通过我们一直在跟踪的训练数据集运行它。完成此操作后，我们已经创建了在训练数据中定位单词的步骤 3，现在我转到步骤 4 来训练分类器，在我们的示例中，是对样本数据进行朴素贝叶斯训练，因此我调用了朴素贝叶斯分类器，并对已定位的世界进行了训练。然后我得到新的数据，这被称为测试数据；例如，这里是“哦，我的上帝”，但是你可以用这个函数的文本变量替换它，以便创建你的测试数据。一旦创建了测试数据，我们需要为字典中标记的每个单词创建特征，这是我们在前面的步骤 3 中创建的。一旦完成，我们现在就可以告诉我们的数据特征是如何被分类的了。有没有被归类为能源或者 POS？该函数返回分类器点分类测试数据特征的值。如果你回到图 [4-1](#Fig1) 中，我在条件中定义了聊天功能。

在 else 语句的最后一个条件中，我使用了一个 wordnet lemmatizer，并检查了数据用户给出的输入是否不是一个条目。

然后，它使用单词 net lemmatizer，并获取用户以小写形式输入的值。它对值进行了引理。词汇化是将一个较大的单词转换成它的词根的过程。举个例子，cars 有一个词根词 car。在下一个语句中，我使用 get 情感函数并给出值，这是用户给定的 lemmatize 输入，作为回报，我从函数中获得 neg 能量或 POS 负面或正面情感。在下一个条件中，我检查值是否是 POS 则机器人回答 0 的肯定响应回答，或者，如果是否定情绪，则机器人回答否定响应。因此，您已经以非常简单的方式了解了如何实现聊天机器人应用程序并将其用于商业用途。

```py
#Sentiment Analyzer using NLP
def getSentiment(text):
    import nltk
    from nltk.tokenize import word_tokenize

    #nltk.download('punkt')
    # Step 1 – Training data building the Diabetes corpus
    train = [("Thanks for an excellent report", "pos"),
    ("Your service is very quick and fast", "pos"),
    ("I am pleased with your service", "pos"),
    ("I did not know i was diabetic until you gave me this report", "neg"),
    ("Service - Little slow, probably because too many people.", "neg"),
    ("The place is not easy to locate", "neg"),
    ("The place is very easy to locate", "pos"),
    ("Not satisfied will take a second opinion", "neg"),
    ("No human contact everything is so robotic here", "neg"),
    ("can i talk to a human not convinced with your report", "neg"),
    ("good results", "pos"),
    ("good service", "pos"),
    ("great service", "pos"),
    ("excellent service", "pos"),
    ("amazing technology", "pos"),
    ("fast service and satisfying report", "pos"),
    ("your report sucks", "neg"),
    ("this report will cost me a fortune", "neg"),
    ("I have diabetes", "neg"),
    ("this report will cost me a fortune", "neg"),
    ("this report means i have a dreadful disease", "neg"),

    ("will i need to take new medication", "neg"),
    ("i need to take my insulin injections regularly", "neg"),
    ("my lipids are getting worst need to talk to the doctor", "neg"),
    ("oh my god very bad results", "neg"),
    ("bad service", "neg"),
    ("very bad service", "neg"),
    ("poor service", "neg"),
    ("very bad service", "neg"),
    ("slow service", "neg"),
    ("very slow service", "neg"),
    ("diabetes got worst is this report accurate", "neg"),
    ("i dont believe this report", "neg"),
    ("i dont like this report", "neg"),
    ("i am in a diabetic hell", "neg"),
    ]
    # Step 2 Tokenize the words to dictionary
    dictionary = set(word.lower() for passage in train for word in word_tokenize(passage[0]))
    # Step 3 Locate the word in training data
    t = [({word: (word in word_tokenize(x[0])) for word in dictionary}, x[1]) for x in train]
    # Step 4 – the classifier is trained with sample data
    classifier = nltk.NaiveBayesClassifier.train(t)
    test_data = "oh my god what is this"
    test_data_features = {word.lower(): (word in word_tokenize(test_data.lower())) for word in dictionary}
    print (classifier.classify(test_data_features))
    return classifier.classify(test_data_features)

#Start the program chat and put in loop
input_field.bind("<Return>", chat)
tkinter.mainloop()

Listing 4-6Sentiment Analysis

```

## 案例研究 2:医院食物浪费问题

在这个案例研究中，我们要看一个非常普遍的医院现象:食物浪费。我们要应用机器学习的方法来解决这个商业问题。

Acadecia 医院是美国领先的国际连锁医院之一。它成立于 1986 年，位于加利福尼亚州的一个小镇欧康。刚开始的时候很小；然而，创始人 Jack Juice 博士的愿景是让小镇居民能够负担得起并轻松获得医疗保健。这家连锁医院最引人注目的事实是，它能够保持医院的低运营成本，以便为小镇居民提供负担得起的医疗保健。2017 年，它在全球拥有 120 多家医院，其中 70%位于人口不到 100 万的小城镇。

Twin Burger 博士正在啜饮他的早餐咖啡，并仔细阅读他从财务部收到的关于其医院网络运营成本的报告。他是 Acadecia 医院的负责人，带领连锁医院实现 Juice 博士的愿景，让全世界人民都能负担得起医疗保健。在图 [4-2](#Fig2) 中，你会看到 Burger 博士那天早上收到的报告。

![../images/464968_1_En_4_Chapter/464968_1_En_4_Fig2_HTML.jpg](../images/464968_1_En_4_Chapter/464968_1_En_4_Fig2_HTML.jpg)

图 4-2

Acadecia 医院的食品成本报告

在图 [4-2](#Fig2) 中，我们可以在 Burger 医生面前看到过去 3 年(2014-2016)每份医院报告的成本参数。报告显示，Acadecia 的医院数量稳步增长；员工人数也增加了，医院的平均床位也增加了。然而，对于我们的案例研究，相关数据在最后三行，第一行是医院每天的总食品订单，以千克为单位。随着医院的增多，这个数字也上去了。倒数第二行显示了食品通胀的上升，这是以美元计算的每公斤食品的平均成本，从 2.35 美元到 2.56 美元不等。以千克为单位的粮食浪费也从 2014 年的 74.9 千克下降到 109.8 千克。在 Acadecia 的所有医院中，食物浪费从 2014 年的 42%上升到 2015 年的 47 %,平均占食物订购总量的 55%。因此，很明显，正如报告中概述的那样，伯格医生正在考虑他的医院由于食物浪费增加而导致的成本上升。

在看完报告后，Burger 博士意识到问题正在失控，需要一些有针对性的解决方案。他记得在周末遇到了他的老朋友，他现在是一名机器学习顾问，他说他可以帮助伯格博士解决任何需要使用技术的问题。他向机器学习顾问发送了一封电子邮件，预约讨论问题并利用技术找到解决方案。

他见了机器学习顾问，和他签了协议后给他看了数据。他问机器学习是否可以帮助解决这个问题，并提出一个适当的解决方案来降低他的组织因食物浪费而产生的成本。

该顾问要求提供更多的数据，以便他找出原因，然后找到解决问题的可能办法。Acadecia 计算机部门的人给了他数据访问权，让他查看中央数据库中全球服务器上的数据存储。

有趣的是，我不打算讨论数据集成和数据争论的部分，因为我们在前面的案例研究中已经讨论过了。但是，请记住，在真实的生产环境中，您很难获得本案例研究中的现成数据。您需要从平面文件、Excel 表、Word 文档、PowerPoint 演示文稿、专有数据库(如 Oracle、sQL server 和 dB2)等来源中集成数据并将其收集到一个单一来源中，如 Hadoop 或 mongo DB 或 Cassandra。

现在我们来看看 Acadecia 的综合数据集，我们将在此基础上建立我们的机器学习模型。

![../images/464968_1_En_4_Chapter/464968_1_En_4_Fig3_HTML.jpg](../images/464968_1_En_4_Chapter/464968_1_En_4_Fig3_HTML.jpg)

图 4-3

样本数据集

在图 [4-3](#Fig3) 中，我们查看了 Acadecia 医院的样本数据集。这是三家医院的数据，为了保密，我特意去掉了名字。为了保持客户的匿名性，还对其原始来源进行了充分的修改。从 Acadecia 的 125 家医院收集的数据包括医院订购的食物总量、医院浪费的食物总量、提供的住院病人膳食数量、住院病人的客人数量以及医院的类型。所有这些信息是 2014 年至 2016 年所有 3 年的平均值。

在接下来的步骤中，我们将在 Python 中加载这个数据集，并开始应用机器学习的过程，我在本书的前几章中概述了这一过程。

```py
import pandas as pd
import os
os.getcwd()

fname="Food_Raw_Data.csv"
hospitals= pd.read_csv(fname, low_memory=False, index_col=False)
df= pd.DataFrame(hospitals)
print(df.head(1))

Listing 4-7Loading the Data Set

```

最初在清单 [4-7](#PC8) 中，我加载所需的 Python 库 Pandas os，然后打开文件 food raw data。csv 文件从本地 DIRECTPyth 导入到医院的 Pandas 数据帧中，然后通过 head 函数从数据帧中读取第一条记录。加载完数据集后，我们现在将查看数据集的形状、列和数据类型，以便进一步研究它。我还查看了清单 [4-8](#PC9) 中数据框的列及其数据类型，该数据框的形状由 125 行 8 列组成。通过给定 from，我们可以看到所有 8 列，从订购的食物总数、浪费的食物总数、住院病人数、提供的膳食数、住院病人的客人数、反馈、医院类型和病床总数开始。在这之后，我们查看每一列的数据类型；数字列是特定医院订购的食物总量、特定医院浪费的食物总量、医院接收的住院病人数量、医院一天供应的膳食数量、医院住院病人的客人数量以及医院的病床总数。非数字列是医院名称和反馈，这是患者和客人对医院食品质量的评级，但我们不打算在我们的模型中使用它。

```py
print(df.shape)
(125, 8)

print(df.columns)
Index(['Total Food ordered', 'Total Food Wasted', 'No of Inpatients',
       'No of Meals served', 'No of Guests with Inpatient', 'Feedback',
       'Type of Hospital', 'Total No of beds'],
      dtype='object')

df.dtypes
Out[72]:
Total Food ordered              int64
Total Food Wasted               int64
No of Inpatients                int64
No of Meals served              int64
No of Guests with Inpatient     int64
Feedback                       object
Type of Hospital               object
Total No of beds                int64
dtype: object

Listing 4-8Looking at the Shape and Size of the Data Set and Its Structure

```

在清单 [4-9](#PC10) 中，我们可以通过 df.org 空值看到没有空值，我们用 bf.in 验证了这一点，对于每种数据类型，所有的值都是非空的。通过这种方式，我们可以确保数据集中的每一列和每一行都被填充，因此没有丢失的值。

```py
#Check if there are any columns with empty/null dataset
df.isnull().any()
#Checking how many columns have null values
df.info()
df.isnull().any()
#Checking how many columns have null values
df.info()
<class 'pandas.core.frame.DataFrame'>
Index: 125 entries, Hospital 1 to Hospital 99
Data columns (total 8 columns):
Total Food ordered             125 non-null int64
Total Food Wasted              125 non-null int64
No of Inpatients               125 non-null int64
No of Meals served             125 non-null int64
No of Guests with Inpatient    125 non-null int64
Feedback                       125 non-null object
Type of Hospital               125 non-null object
Total No of beds               125 non-null int64
dtypes: int64(6), object(2)
memory usage: 13.8+ KB

Listing 4-9Checking for Missing Values

```

既然我们已经检查了丢失的值，让我们继续探索性的数据分析，查看我们的数据集的数字列的平均值、中值和众数，并通过未定义的 df.com 众数查看清单 [4-10](#PC11) 。为了从均值函数简单地理解我们的结果，总的食物订购平均值为 319.18，医院浪费的食物平均值为 54.68 千克。人数为 33 人，医院平均提供 140 顿饭。住院客人的平均人数为 8 人。医院平均共有 64 张床位。如果我们查看相同列的中值，我们会发现中值为 255 的总订购量和 23 的总浪费量之间存在巨大差异。住院病人人数为 26 人，提供的膳食数量为 113 份。住院客人数为 7 人，总床位数接近平均值 66 张。如果中值和平均值足够接近，则意味着我们的数据集是正态的或接近正态的，其特征是，如果数据集具有正态分布，则平均值、中值和众数的每一列的值将接近相等。但是，我们可以清楚地看到，我们的数据集并不是正态分布的。均值和中值之间的差异告诉我们的另一件事是，我们正在处理异常值，在总食物浪费、用餐次数和总食物订购列中有更多的异常值。其余的列彼此接近，因此其中可能没有很多异常值。

```py
#How is the data distributed and detecting Outliers
df.std()
df.max()
df.min()
df.quantile(0.25)*1.5
df.quantile(0.75)*1.5
df.std()
Out[79]:
Total Food ordered             220.918186
Total Food Wasted               81.394658
No of Inpatients                22.565266
No of Meals served              97.742244
No of Guests with Inpatient      8.358886
Total No of beds                20.279047
dtype: float64

df.max()
Out[80]:
Total Food ordered               921
Total Food Wasted                454
No of Inpatients                  91
No of Meals served               407
No of Guests with Inpatient       38
Feedback                           C
Type of Hospital               Urban
Total No of beds                 100
dtype: object

df.min()
Out[81]:
Total Food ordered                 2
Total Food Wasted                  0
No of Inpatients                   0
No of Meals served                 1
No of Guests with Inpatient        0
Feedback                           A
Type of Hospital               Rural
Total No of beds                  30
dtype: object

df.quantile(0.25)*1.5
Out[82]:
Total Food ordered             238.5
Total Food Wasted                7.5
No of Inpatients                25.5
No of Meals served             105.0
No of Guests with Inpatient      3.0
Total No of beds                66.0
Name: 0.25, dtype: float64

df.quantile(0.75)*1.5
Out[83]:
Total Food ordered             679.5
Total Food Wasted               87.0
No of Inpatients                70.5
No of Meals served             300.0
No of Guests with Inpatient     18.0
Total No of beds               123.0
Name: 0.75, dtype: float64

Listing 4-11Exploratory Data Analysis

```

```py
df.mean()
Out[75]:
Total Food ordered             319.184
Total Food Wasted               54.680
No of Inpatients                32.952
No of Meals served             141.224
No of Guests with Inpatient      8.800
Total No of beds                64.776
dtype: float64

df.median()
Out[76]:
Total Food ordered             255.0
Total Food Wasted               23.0
No of Inpatients                26.0
No of Meals served             113.0
No of Guests with Inpatient      7.0
Total No of beds                66.0
dtype: float64

df.mode()
Out[77]:
   Total Food ordered  Total Food Wasted  No of Inpatients  \
0               110.0                0.0                23
1                 NaN                NaN                25

   No of Meals served  No of Guests with Inpatient Feedback Type of Hospital  \
0                97.0                          2.0        B            Urban
1                 NaN                          NaN      NaN              NaN

   Total No of beds
0              44.0
1               NaN

Listing 4-10
Detecting Outliers

```

在清单 [4-11](#PC12) 中，我们转到检测异常值，以检测我们首先查看标准偏差，它告诉我们数据在每一列中的离差，然后我们查看最大值和最小值，以找出数据集中每一列的范围。然后，我们使用分位数函数，使用第 25 个百分点和第 75 个百分点，并乘以 1，以获得下限异常值和上限异常值。例如，从分位数 0.2 中，我们可以看到，订购的食物总量的异常值下限为 238.5，而第 75 个百分位 X 1.5 的“订购的食物总量”列的值为 679。实际上，对于“订购的食物总量”列，任何低于 38.5 的值和任何高于 679 的值都将被视为异常值。你同样可以查看其他栏，如浪费的食物总量、住院病人数量、提供的餐饮数量等。

```py
#How many Outliers in the BPSystolic column
df.columns
df.dtypes
df.set_index(['Hospital Name'])
df['Total Food ordered'].loc[df['Total Food ordered'] <=238.5].count()
Out[84]: 55

df['Total Food ordered'].loc[df['Total Food ordered'] >=679.5].count()
Out[85]: 11

Listing 4-12How Many Outliers in Any Particular Columns

```

现在我们来看图 [4-3](#Fig3) ，在图中，我给出了一个示例，说明如何计算特定列中有多少值(如总点餐数)不符合异常值的下限和上限。我们可以看到，对于订购的总食物，异常值下限为 38.5，有 55 个值小于这个数字。类似地，对于异常值上限 679,“订购的食物总数”列有 11 个值超出了该阈值限制。

为什么我们需要知道这些？首先，任何机器学习顾问都会考虑这个值，因为他们需要决定是丢弃、保留还是修改离群值。在这种情况下，我决定保留离群值，因为如果我删除它们，我将丢失数据集的很大一部分(125 行中的 66 行将丢失)，并且这些行可以带来的学习也将随之丢失。然而，这并不是您在每次建模练习中都必须遵循的规则。您应该独立思考什么是相关的，什么对您的数据集和您正在构建的模型是有益的。

![../images/464968_1_En_4_Chapter/464968_1_En_4_Fig4_HTML.jpg](../images/464968_1_En_4_Chapter/464968_1_En_4_Fig4_HTML.jpg)

图 4-4

可视化数据集的结构

```py
#Visualizing the dataset
df.boxplot(figsize=(10, 6))
df.plot.box(vert=False)
df.kurtosis()
df.skew()
import scipy.stats as sp
sp.skew(df['Total Food ordered'])

```

在图 [4-4](#Fig4) 中，我们试图通过绘制盒状图的水平和垂直方向来可视化我们的数据集，从图中可以非常清楚地看出，订购的食物总量更加分散，并且在尾部末端有异常值。相比之下，浪费的食物总量要少得多；然而，它在尾部有更多的异常值。

类似地，读者会从第 3 章中回忆起峰度显示了我们数据集分布的厚度。这意味着厚度，如果峰向左，那么它被称为薄峰。如果分布是厚尾，那么这样的分布与正态分布比较，峰度值等于 3。过度峰度意味着峰度值将大于 3，而较少峰度意味着峰度值将小于 3。如果峰度值小于 0，则称之为平峰分布。记住这一点，现在让我们研究清单 [4-13](#PC15) 中给出的四个变量。总食物顺序的峰度值是负的(0.1)，所以它是平峰度。浪费的食物总量在 3 以上，价值 7。这意味着在数据中有更多的峰值和过度峰度，并且分布是中等峰度的。住院病人数和提供的膳食数列是 platykurtic，因为它们小于 0；同样，床位总数也小于 0。有住院病人的客人的列数是 2，这意味着它不是更小的峰度，因为该值小于 3。

```py
df.kurtosis()
Out[91]:
Total Food ordered            -0.150535
Total Food Wasted              7.432315
No of Inpatients              -0.299269
No of Meals served            -0.155185
No of Guests with Inpatient    2.008910
Total No of beds              -1.224649
dtype: float64

df.skew()
Out[92]:
Total Food ordered             0.756837
Total Food Wasted              2.570979
No of Inpatients               0.712854
No of Meals served             0.754662
No of Guests with Inpatient    1.476908
Total No of beds              -0.028728
dtype: float64

Listing 4-13Looking at Skew and Kurtosis

```

在清单 [4-13](#PC15) 中，我们查看了每一列的偏斜度和峰度，您会从第 [3 章](03.html)中回忆起，如果偏斜度小于 0，那么我们说分布是负偏斜的；如果偏斜度等于 0，则称该分布是对称的；如果偏斜值大于 0，那么我们说分布是正偏斜的。偏斜告诉我们尾巴向哪个方向偏斜。负偏差的结果有一个长的左尾巴，正偏差的结果有一个长的右尾巴。从清单 [4-13](#PC15) 中，我们可以看到，总点餐数为正值 0.7，总浪费食物数也正偏于 2。住院病人数正偏于 0.71，提供的餐饮数也正偏于 0.7，有住院病人的客人数高度偏于 1.4，总床位数略微负偏，但在 0.02 更接近于 0。

```py
df.hist(figsize=(10, 6))
Out[95]:
array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000019D18C1F940>,
<matplotlib.axes._subplots.AxesSubplot object at 0x0000019D18F2CB70>],
       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000019D18F64B70>,
<matplotlib.axes._subplots.AxesSubplot object at 0x0000019D18F9FC50>],
       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000019D18FDAC50>,
<matplotlib.axes._subplots.AxesSubplot object at 0x0000019D18FDAC88>]], dtype=object)

```

在图 [4-5](#Fig5) 中，我们可以清楚地看到数据集中的列是如何分布的。这表明列中的数据都不符合正态曲线。

![../images/464968_1_En_4_Chapter/464968_1_En_4_Fig5_HTML.jpg](../images/464968_1_En_4_Chapter/464968_1_En_4_Fig5_HTML.jpg)

图 4-5

可视化数据分布

现在我们进入下一步，识别数据之间的任何关系，因为我们在建模练习中讨论的是数字数据。在图 [4-6](#Fig6) 中，我们可以看到各列相关值的结果，我们案例研究的主要重点是基于总食物浪费值创建一个模型，这需要根据其他数据进行预测。其他数据是可用的，所以看相关值，我选择的最重要的是，浪费的食物总量与病人数量的相关值为 0.7；浪费的食物总量与用餐次数呈正相关，相关系数为 0.7；浪费的食物总量与有住院病人的客人数量呈非常高的正相关，为 0.9；与总食物订单相关的总食物浪费是 0.7。我提议基于这四个输入建立一个总食物浪费的预测模型。我们可以看到，住院病人的客人数量与总食物浪费的比例可能为 0.9，因此 Acadecia 医院可能需要研究住院病人数量增加导致医院设施食物浪费的原因。这一最重要的决定因素可以为他们节省大量的食物浪费。

![../images/464968_1_En_4_Chapter/464968_1_En_4_Fig6_HTML.jpg](../images/464968_1_En_4_Chapter/464968_1_En_4_Fig6_HTML.jpg)

图 4-6

用散点图可视化相关性

```py
df.corr()
Out[96]:
                             Total Food ordered  Total Food Wasted  \
Total Food ordered                     1.000000           0.770522
Total Food Wasted                      0.770522           1.000000
No of Inpatients                       0.998059           0.765459
No of Meals served                     0.999994           0.770236
No of Guests with Inpatient            0.696581           0.934847
Total No of beds                       0.410256           0.357904

                             No of Inpatients  No of Meals served  \
Total Food ordered                   0.998059            0.999994
Total Food Wasted                    0.765459            0.770236
No of Inpatients                     1.000000            0.998056
No of Meals served                   0.998056            1.000000
No of Guests with Inpatient          0.697330            0.696443
Total No of beds                     0.411096            0.409509

                             No of Guests with Inpatient  Total No of beds
Total Food ordered                              0.696581          0.410256
Total Food Wasted                               0.934847          0.357904
No of Inpatients                                0.697330          0.411096
No of Meals served                              0.696443          0.409509
No of Guests with Inpatient                     1.000000          0.296937
Total No of beds                                0.296937          1.000000
Figure 4.22 Correlation for all the numeric column variables
df.plot.scatter(x='Total Food Wasted', y='No of Guests with Inpatient',s=df['Total Food Wasted']*2)
Out[98]: <matplotlib.axes._subplots.AxesSubplot at 0x19d190eec50>

```

现在，图 [4-6](#Fig6) 向您展示了一种观察这种相关性的方法，并创建了一个散点图，清楚地显示了总食物浪费量和住院客人数量之间的联系。我们可以在图表中清楚地看到一种模式。虽然我们有两个分类列，反馈和医院类型，但因为我们的案例研究不需要对它们进行任何计算或理解，所以在我们的模型构建练习中，我们将忽略它们。接下来，我进入数据准备步骤，将数据分为特性集和目标集。第一个数据框是浪费，这是我们的目标数据集，我们需要根据其他列来预测浪费的食物总量。为了创建要素数据框，我从数据框中删除了浪费的食物总量，这是我们的目标列、反馈列、医院类型列和床位总数列。这在清单 [4-14](#PC18) 中进行了描述。

```py
wastage = pd.DataFrame(df['Total Food Wasted'])

dropp=df[['Total Food Wasted','Feedback','Type of Hospital','Total No of beds']]
features= df.drop(dropp, axis=1)
wastage.columns
features.columns
Out[102]:
Index(['Total Food ordered', 'No of Inpatients', 'No of Meals served',
       'No of Guests with Inpatient'],
      dtype='object')

Listing 4-14Preparing Features and Target Data Sets

```

接下来，我们继续洗牌，并按照 80%比 20%的比例将数据分成训练集和测试集。这可以在清单 [4-15](#PC19) 中看到。

```py
from sklearn.cross_validation import train_test_split
from sklearn.utils import shuffle

# Shuffle and split the data into training and testing subsets
features=shuffle(features,  random_state=0)
wastage=shuffle(wastage,  random_state=0)
# Split the 'features' and 'income' data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features, wastage, test_size = 0.2, random_state = 0)

# Show the results of the split
print("Training set has {} samples.".format(X_train.shape[0]))
print("Testing set has {} samples.".format(X_test.shape[0]))
Training set has 100 samples.
Testing set has 25 samples.

Listing 4-15Shuffling and Splitting the Data

```

接下来，我继续构建和评估模型。我将使用两个回归变量:一个是线性回归模型，另一个是线性 SVC(支持向量机)。您可以在清单 [4-16](#PC20) 中看到库导入及其初始化。

```py
import matplotlib.pyplot as plt
import numpy as np
from sklearn import linear_model
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.svm import LinearSVC

#Creating Linear Regression object
regr = linear_model.LinearRegression()
linear_svm = LinearSVC().fit(X_train,y_train)
Figure 4.26  Model Evaluation and Initializing

regr.fit(X_train,y_train)
y_pred= regr.predict(X_test)
yy_pred= linear_svm.predict(X_test)
#Printing Codfficients
print('Coefficients: \n',regr.coef_)
print(LinearSVC().fit(X_train,y_train).coef_)
Coefficients:
 [[ 3.84820846 -4.81910798 -7.39895629  7.71902335]]
[[ -3.53041635e-02   5.09097801e-02   3.14979916e-02  -3.88312025e-01]
 [ -2.32668818e-02  -1.42174073e-01   7.43984582e-02  -1.16573785e-02]
 [  4.72789182e-02   1.47150837e-01  -1.36891194e-01  -5.32241337e-02]
 [  2.93890989e-02  -1.19191185e-01  -2.58725709e-02  -3.82878378e-02]
 [  4.11308074e-02   2.64727641e-02  -9.78443211e-02  -5.51862063e-02]
 [  7.00718282e-02  -8.10166533e-02  -1.22951514e-01   1.71447192e-01]
 [  3.42043753e-02  -2.05910747e-02  -6.20141160e-02  -9.89629458e-02]
 [  2.77961883e-02  -4.46751024e-02  -4.37038593e-02   2.66465015e-01]
 [  1.13547353e-02  -2.71632958e-02  -2.08526490e-03   1.70754244e-01]
 [  3.32914578e-02  -1.67505293e-02  -5.77349454e-02   2.09845962e-03]
 [  4.77186007e-02  -8.23837686e-02  -9.30268666e-02   3.78425737e-02]
 [  3.41540305e-02  -7.34444501e-02  -6.46481812e-02   3.54015691e-02]
 [  3.84521437e-02  -6.41689817e-02  -7.31629621e-02   2.70787385e-01]
 [  4.87625884e-02  -6.84474198e-02  -8.67811679e-02  -5.64164062e-02]
 [  1.49537087e-02  -3.77585007e-02  -1.36249294e-02   7.99620681e-02]
 [  4.89155675e-02  -9.21493872e-02  -8.01503822e-02   1.77140915e-01]
 [  4.24949470e-02  -4.87499272e-02  -7.78022864e-02   1.34518802e-01]
 [  3.50542029e-02  -3.54090045e-02  -6.63975873e-02   1.09584692e-03]
 [  9.38169848e-03  -3.67554573e-02  -1.71349625e-02   2.41221242e-01]
 [  1.00033106e-02  -4.53600521e-02  -6.24499229e-03   1.58324477e-01]
 [  1.41868325e-02  -3.95136457e-02  -1.76177176e-02   2.42552491e-02]
 [  2.67055967e-02  -3.86757704e-02  -5.58150253e-02   2.54908921e-01]
 [  4.79369084e-02  -6.20604669e-02  -8.98633410e-02  -7.57650121e-03]
 [  3.08510176e-02  -8.53705374e-02  -5.20465381e-02   2.20385612e-01]
 [  1.73454354e-02   1.98721103e-02  -4.24878889e-02   9.81570693e-02]
 [  1.24536489e-02  -4.20971569e-02  -1.23960336e-02   3.52634992e-02]
 [  2.57398024e-02  -9.16159713e-02  -4.47215477e-02   2.19305087e-01]
 [  4.23505923e-03   6.72353051e-04  -6.50834658e-03   1.49214594e-01]
 [  2.53837094e-02  -6.98875557e-02  -4.85734903e-02   2.22530149e-01]
 [  1.43908959e-02  -4.75516908e-02  -1.95433533e-02   1.51543940e-01]
 [  2.74067987e-02  -7.52560330e-02  -4.01603079e-02   1.10143783e-01]
 [  4.64045608e-02  -4.05773937e-02  -8.79857548e-02   1.03748880e-02]
 [  1.90491415e-02  -4.10809528e-02  -3.62574033e-02  -1.81196597e-02]
 [  2.22912356e-02  -2.72874169e-02  -4.39681811e-02   1.09394978e-01]
 [  4.20384279e-02  -3.25727010e-02  -8.51492094e-02  -6.37752010e-03]
 [  2.61534393e-02  -2.94261743e-02  -5.41846630e-02  -2.75644483e-02]
 [  2.45319444e-02  -5.09991059e-02  -5.06126410e-02   2.02505939e-01]
 [  2.61919602e-03  -1.25839053e-02  -6.30409084e-03   1.80773339e-01]
 [  2.74789306e-03  -2.73580886e-02  -6.50473121e-03   2.01205405e-01]
 [  2.44669007e-02  -7.03696516e-03  -4.64750958e-02   2.60881871e-02]
 [  1.51200603e-02  -6.89484027e-02  -8.71324723e-03  -8.82744952e-02]
 [  2.65609136e-02  -4.97286727e-02  -5.75957648e-02   3.38979678e-02]
 [  7.11056619e-03  -3.27401201e-02  -1.46946498e-02   1.84639962e-01]
 [ -3.19488770e-03  -1.29730299e-02  -6.65748840e-03   2.30931190e-01]
 [  2.39725322e-02  -4.20831865e-02  -5.23242642e-02   6.14469586e-02]
 [  6.08374964e-03  -3.24197530e-02  -1.01534653e-02   1.56827822e-01]
 [  6.69569094e-03   4.31666176e-03  -3.94068509e-02   1.51761293e-01]
 [  4.25886521e-04  -2.49710716e-02  -1.34306904e-02   2.29936692e-01]
 [ -1.00182507e-03  -2.39362307e-02  -8.88224128e-03   2.23843885e-01]
 [  1.51225156e-02  -4.74318832e-02  -3.73751734e-02   1.50716919e-01]
 [  2.45229013e-02  -5.96876827e-02  -5.15767695e-02   1.86736550e-02]
 [  1.13573008e-02  -2.92617710e-02  -3.19670746e-02   1.29940982e-01]
 [  1.33635906e-02  -3.62729876e-02  -2.39250008e-02   1.03188376e-01]
 [  1.22517696e-02  -4.33917684e-02  -1.70961907e-02   8.42211744e-02]
 [  7.24558495e-03  -3.29668719e-02  -1.44697007e-02   1.50876782e-01]
 [  9.93726094e-04  -3.39403174e-02  -9.35154827e-03   2.01139275e-01]
 [  4.76853411e-03  -1.52811320e-02  -2.65559075e-02   1.66170095e-01]
 [  3.07916719e-03   3.05077312e-05  -2.62159469e-02   1.62382755e-01]
 [  1.07347039e-02  -4.44424820e-02  -3.08244532e-02   1.32283650e-01]
 [  1.24123818e-02  -4.00221036e-02  -3.10893289e-02   1.28289289e-01]]
print('Coefficients: \n',regr.coef_)
Coefficients:
 [[ 3.84820846 -4.81910798 -7.39895629  7.71902335]]

plt.plot(X_test, y_pred, linewidth=3)
plt.show()

Listing 4-16Results of Regressors

```

![../images/464968_1_En_4_Chapter/464968_1_En_4_Figa_HTML.jpg](../images/464968_1_En_4_Chapter/464968_1_En_4_Figa_HTML.jpg)

![../images/464968_1_En_4_Chapter/464968_1_En_4_Fig7_HTML.jpg](../images/464968_1_En_4_Chapter/464968_1_En_4_Fig7_HTML.jpg)

图 4-7

线性回归与线性 SVM 可视化

```py
line = np.linspace(-15, 15)
for coef, intercept in zip(linear_svm.coef_, linear_svm.intercept_):
    plt.plot(line, -(line * coef[0] + intercept) / coef[1])  #HOW DO WE KNOW

plt.ylim(-10, 15)
plt.xlim(-10, 8)
plt.show()

```

在图 [4-7](#Fig7) 中，我们看到线性回归的结果以及来自线性 SVC 的系数，同时我们看到来自线性回归的系数有四个参数，正如预期的那样。然而，在这种特殊情况下，线性 SVC 是一种不好的方法，因为为了预测解，它给了我们更多的划分。为了让你理解这个概念，我将在清单 [4-17](#PC22) 中列出线性回归的结果，以及在线性 SVM 中使用的预测和图形表示。当我们比较线性回归和线性 SVM 的图形时，我们看到线性 SVM 中有更多的边界，而线性回归中只有四个边界。所以我们应该使用线性回归来建立我们的模型。

```py
predicted= regr.predict([[820,81,363,35]])
print(predicted)
[[ 312.23258101]]

Listing 4-17Predict Using Linear Regression Using Our Model on the Amount of Wasted Food Based on Four Parameters

```

我使用清单 [4-17](#PC22) 中的最后一步，通过给定我们的因变量和自变量的四个值来随机预测，以获得特定医院的总食物浪费。

这就是我对这一章案例研究的全部内容。我希望您能像我有幸向您展示案例一样，喜欢阅读这些案例。