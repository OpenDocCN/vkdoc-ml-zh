# 2.机器学习

机器学习(ML)作为人工智能和认知科学的一个子领域出现。机器学习的三种主要类型是*监督学习*、*非监督学习*和*强化学习*。还有其他几种，包括*半监督学习*、*批量学习*、*在线学习*。深度学习(DL)是一个特殊的子集，包括这些不同类型的 ML。它扩展它们来解决人工智能中的其他问题，如推理、规划和知识表示。

什么是机器学习？1959 年，阿瑟·塞缪尔(Arthur Samuel)将机器学习定义为“在没有明确编程的情况下赋予计算机学习能力的研究领域。”ML 是一门专注于教计算机如何学习的学科，在今天的背景下不需要任何特定任务的编程。机器学习探索创建从数据中学习并对数据进行预测的算法。

Note

这一章从应用的角度看经典机器学习的一些基本原理，例如学习的类型、方差和偏差。它沉迷于使用公开可用的数据类型的实践练习。代码可以从该书的网站上下载。ML 本身是一个庞大的领域，不可能在一章中包含它的所有方面。我们在整本书中重温经典概念，包括深入的误差校正和特征工程，以适应数据驱动的预测中的量子概念。

传统上，手工制作和优化算法以完成特定任务一直是构建遗留软件和处理数据操作和分析工作负载的方式。从高层次来看，传统编程关注的是对充分理解的输入数据的确定性结果。相比之下，最大似然法有能力解决一类或一系列输入-输出对应关系不清楚的数据集的问题。

ML 构成了从数据中学习。ML 的一个例子是垃圾邮件过滤器。垃圾邮件过滤器基本上是从用户标记的垃圾邮件示例、常规的*非垃圾邮件*示例、垃圾邮件造成的已知广泛欺诈案例(如钓鱼邮件、要求个人信息的众所周知的欺诈等)中“学习”。)，以及其他类型的用例。

由 ML 管理的垃圾邮件过滤器从示例中学习，并将其所学应用于可疑的垃圾邮件。然而，这种学习过程和“学习”结果的后续算法应用是概率性的(即，它并不总是完美的或确定的)。因此，有时你会在垃圾邮件文件夹中发现合法邮件，在收件箱中发现垃圾邮件。垃圾邮件过滤器“看到”的例子越多，它训练自己检测合法垃圾邮件的次数就越多，它在保护我们的邮箱方面的表现就越好。

在这种类型的任务中，ML 比传统编程成功的主要原因之一是不断增长的数据量。垃圾邮件过滤器通常根据规则进行操作。过去，我们必须手动定义规则来阻止邮箱中的垃圾邮件，我们必须定义“发件人”、“收件人”、“主题”等等，如图 [2-1](#Fig1) 所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig1_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig1_HTML.jpg)

图 2-1

手动输入规则以获得理想结果的传统方法

随着现代世界大数据时代流量和数据的爆炸式增长，人类手动定义规则并跟上不断增长的数据量的能力已经远远低于所需的效率水平。因此，机器已经接管了这项任务，来定义处理大块数据的综合规则，并应用这些规则来提供问题的解决方案。ML 系统用来学习的数据被称为*训练集*。在垃圾邮件过滤器的例子中，标记和过滤垃圾邮件或定义算法的*性能*的*训练数据*。在这种情况下，性能测量可以是正确或不正确的垃圾邮件的比率。性能测量被称为*准确度*，这个值，正如本章中的一些例子所展示的，通常会随着训练和时间的推移而提高。图 [2-2](#Fig2) 显示了将 ML 应用于垃圾邮件过滤器的工作流程。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig2_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig2_HTML.jpg)

图 2-2

用 ML 过滤垃圾邮件

本章介绍了机器学习算法的基础知识、数据驱动预测的原理、性能和复杂性。本章从经典的角度探索了数据驱动的模型和预测以及各种学习算法，随后是一些实际操作的例子。随后的章节建立在由量子物理学驱动的经典机器学习的概念上。

在我们深入一些基本和必要的机器学习概念之前，快速浏览一下该主题中涉及的一些术语可能是有益的。

***机器学习和大数据*** :直到最近，大多数 ML 工作负载都是在单机(计算机)上执行的。然而，GPU(图形处理单元)、谷歌的 TPU(张量处理单元)和分布式计算的发展现在使得大规模运行大数据的机器学习算法成为可能，这些算法分布在各个集群中。

## 算法和模型

这些天有太多关于 ML 和它的各个方面的文献。通常，很难区分算法和模型，因为这两个术语在文献中可以互换使用。在本文中，我们将两者区分如下。

*算法*是由数学或统计公式定义的方法论。

*模型*是定义输入数据和输出之间关系的数学对象，是用数据训练算法后得到的。一旦输入进入模型，输出就产生了；但是模型需要首先被训练以获得有意义的输出。

算法和模型的区别如图 [2-3](#Fig3) 所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig3_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig3_HTML.jpg)

图 2-3

算法和模型

不同的训练数据导致产生具有不同系数的不同模型。有效算法的一个例子是房价预测，其中价格基于房间数量、地块大小、居住空间等。然而，在算法被采用并且由它产生的结果可以被信任之前，需要有一些它工作的证明。

来自算法的“预期”值是指构建一个*估计器*。所有的 ML 算法都是估计量。评估者告诉我们*对未来*的预期，但*实际上并不预测未来*。理想情况下，我们更希望有一个能完美预测未来的估计器！但那将类似于具有远见或精神洞察力。从数学和科学的角度来看，我们创建模型并优化它们，以尽我们最大的能力提高精确度。

以下是数据的一些基本属性和相关模型，在衡量算法的成功时会考虑这些属性。

### 偏见

*偏差*表示估计器离目标有多远，或者换句话说，模型预测离正确值有多远。这直接取决于对训练数据的假设。*假设*的数量越多，模型泛化的可能性越低；泛化错误的一个例子是假设数据是*多项式*，而它是*线性*。因此，根据经验，低偏置通常是首选。高偏差模型通常使训练数据受到*欠拟合*(本章稍后讨论)。偏差告诉我们预测的*平均值*是否接近正确的位置，或者误差是否在一个方向或另一个方向*偏向*(或偏斜)。

数学上，偏差定义如下。

![$$ BIAS\left(\hat{X},X\right)\equiv \mathbbm{E}\left[\hat{X},X\right] $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equa.png)

(2.1)

其中， *X* 是概率分布，![$$ \hat{X} $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_IEq1.png)是同一概率分布的估计量。

从方程 [2.1](#Equa) 中可以看出，偏差显示了一个估计值平均可能会偏离目标值多少。

综上所述，以下是偏倚的主要性质。

*   *偏差误差*最常见的原因之一是模型简化假设，以实现更容易学习的目标函数。

*   作为一个算法家族，参数算法通常会有很高的偏差。
    *   学习很快，因此计算成本更低，因此很有吸引力

    *   它们很简单，但不太灵活

    *   它们在预测复杂数据时表现不佳，因为这些数据特征不太适合简化的假设。

减少对目标函数的假设数量是达到*低偏差*的一种方式。其中一些技术是*决策树*、 *k 近邻* (KNN)和*支持向量机* (SVM)。

### 变化

*方差*是预测对训练集敏感程度的指标。方差直接取决于数据的分布。方差告诉我们，与未来预测的实际值相比，估计值有多宽或多窄。由许多自由度组成的模型，如多项式模型，通常表现出高度的变化，这导致训练数据的*过拟合*(在本章后面详述)。数学上，

![$$ VAR\left(\hat{X}\right)\equiv \mathbbm{E}\left[{\left(\hat{X}-\mathbbm{E}\left(\hat{X}\right)\right)}^2\right] $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equb.png)

(2.2)

换句话说，方差是平均值的平方差的平均值*。方差衡量相关数据的分布程度。方差有两个更广泛的品种:*总体方差*和*样本方差*。*

总体方差通常用 sigma 平方(*σ*T2】2 设计。以下是计算数据集的*总体方差*的步骤。

总体方差在数学上由下式给出

![$$ {\sigma}^2=\frac{\sum {\left(x-\mu \right)}^2}{N} $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equc.png)

(2.3)

其中 *x* 表示个体数据点， *μ* 是平均值， *N* 是整个*总体*中数据点的*个数*。

以下是计算*σ*T2】2 的步骤。

1.  计算数据集的平均值。例如，我需要计算一小时内在我的街道上看到的汽车数量。为此，我们记录了对三辆车的观察，一辆车、两辆车、六辆车和三辆车。平均值是数据的平均值，在本例中为![$$ \frac{3+1+2+6+3}{5}=3.0 $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_IEq2.png)。

2.  每个数据点与平均值的差异由下式给出

(3 − 3 = 0); (1 − 3 =  − 2); (2 − 3 =  − 1); (6 − 3 = 3); (3 − 3 = 0)

1.  差值的平方给出如下:0，4，1，9，0。

2.  The average of the squared differences gives the final variance value.

    ![$$ {\sigma}^2=\frac{0+4+1+9+0}{5}=2.8 $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equd.png)

*样本方差*的计算略有不同。总体方差指的是整个数据集，而样本方差指的是数据集的子集。样本方差通常是在定义明确的数据集空间中获取的，例如连续五个小时计算每小时看到的汽车数量。在这种情况下，我们可能希望通过每小时分组的数据块来计算每小时的汽车数量。然后我们将平均值的*平方差除以*N*1。换句话说，样本方差*s*T8】2 由下式给出*

![$$ {s}^2=\frac{\sum {\left(y-\overline{m}\right)}^2}{n-1} $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Eque.png)

(2.4)

其中 *y* 表示单个数据点，![$$ \overline{m} $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_IEq3.png)是平均值， *n* 是在*样本*空间中数据点的*数量*。

方差是如果使用了*不同的训练数据*，目标函数的估计值*将改变*的量【15】。与方差相关，目标函数是根据训练数据计算的，因此受到训练数据的影响。在理想情况下，如果训练数据集发生变化，目标函数的变化应该是最小的。一个好的算法应该解决输入和输出变量之间隐藏的潜在映射。

当目标函数的估计变化相对于训练数据集中的变化为*小*时，表示*低方差*，例如，诸如线性回归和逻辑回归的参数算法。

*当目标函数的估计值的变化相对于训练数据集中的变化较高时，指示高方差*。通常，像决策树这样的非参数算法往往具有很高的方差。算法中较高的灵活性会导致较高的方差误差。

*标准差*计算为方差的平方根*σ*T4】2T6】σ。这里， *σ* 是标准差。

*不可约误差*由于数据中的噪声和未知变量而产生。因此，在任何与数据科学相关的项目中，数据清理都是至关重要的。

这本书有可供下载的实践练习代码。从这一章开始，我们遵循惯例，用以下图标标注的代码片段可以下载。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figa_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Figa_HTML.jpg)

下面是一个使用`matplotlib` Python 库和分布式随机数据可视化方差概念的快速练习。

如果您使用 Python 3.7 或 3.8 打开 Jupyter 笔记本中的`variance.ipynb`代码文件(如第 [1 章](1.html)所述)，您会看到一个住宅区房价假设数据分布的方差和标准差计算示例。代码如清单 [2-1](#PC1) 所示，对应的直方图如图 [2-4](#Fig4) 所示。

```
%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
houseprice = np.random.normal(150.0, 50.0, 20000)
plt.hist(houseprice, 75)
plt.show()

Listing 2-1variance.ipynb

```

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figb_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Figb_HTML.jpg)

对于正态分布，数据是随机生成的。分布以大约 150 为中心，20，000 个数据点的标准偏差为 50.0。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig4_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig4_HTML.jpg)

图 2-4

方差直方图. ipynb

直方图显示，标准偏差约为 50.0，约为 100 和 200，数据以约 150 为中心。

可以分别使用`.std`和`.var`函数调用计算数据的标准差和方差，如图 [2-5](#Fig5) 所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig5_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig5_HTML.jpg)

图 2-5

方差的标准差和方差

对于标准偏差，获得的值约为 50.38，非常接近清单 [2-1](#PC1) 中指定的值。方差是 2538.34，大约是我们预期的 50.38 <sup>2</sup> ，因为标准差是方差的平方根。

#### 偏差与方差的权衡

方差与模型的复杂性直接相关。如果模型的复杂性增加，方差通常也会增加。然而，增加复杂度也会减少偏差。正如预期的那样，降低复杂性会增加其偏差并减少其方差。因此，在选择模型时，通常需要在方差和偏差之间进行权衡，并且需要精确平衡这两者。

权衡取舍的选择通常归结为数据的过拟合与欠拟合。高度的方差会导致过度拟合，而高偏差模型会使训练数据欠拟合。图 [2-6a](#Fig6) 显示了一个低偏置的例子。之字形图有一个低偏差，但高方差。在图 [2-6b](#Fig6) 中，线性图相对于数据具有较低的方差，但是具有较高的偏差，与每个数据点的误差有关。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig6_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig6_HTML.jpg)

图 2-6

偏差和方差权衡

方差和偏差之间的权衡对于减少误差很重要，这是任何模型的目标。误差可以用方差和偏差来表示，如下所示。

![$$ \epsilon ={\beta}^2+{\sigma}^2 $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equf.png)

(2.5)

其中 *ϵ* 为误差， *β* 为偏差，*σ*T6】2 为方差。

默认情况下，对目标函数值的假设越少，灵活性越大，因此偏差越小。另一方面，与训练数据的变化相关的目标函数的变化越少，方差越小，算法越不灵活但越稳定。图 [2-7](#Fig7) 描绘了两者之间的关系。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig7_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig7_HTML.jpg)

图 2-7

偏差和方差权衡

参数或线性算法通常具有高偏差但低方差，而非参数或非线性算法通常具有低偏差但高方差。

机器学习中偏差和方差之间的权衡关系对于算法决策者来说是一个不可避免且无处不在的问题:增加偏差会减少方差，减少偏差会增加方差。这里的圣杯是在模型复杂性允许的情况下找到优化性能的最佳点。

## 数据过度拟合

假设在一场足球比赛中，一名前锋在她得到的第一个得分机会就射门得分。那么我们是否可以推测所有的前锋都能抓住每一个机会进球？我们不能做出这样的假设，因为更多的得分机会最终没有进球。基于数据量不足而高估预测结果在 ML 中被称为*过拟合*。如图 [2-8](#Fig8) 所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig8_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig8_HTML.jpg)

图 2-8

过度拟合

当模型与训练数据集的拟合过于精确时，乍一看似乎是“正确的”，但因为它与训练数据的拟合过于“接近”，所以它可能会排除在测试时在*之前没有“看到”的有效数据。一个例子是一个曲线函数，几乎触及图 [2-8](#Fig8) 中的每个数据点，误差很小或根本没有误差。在这种情况下，最佳拟合曲线与训练数据吻合得非常好，但在使用模型以前未见过的测试数据进行评估时，可能表现不佳。因此，模型预测的准确性由于过度拟合而受损，因为它倾向于*记忆*训练数据，而不是*从中学习*。过于灵活的模型往往显示出高方差和低偏差。*

定义明确的特征可以检测过度拟合。通常，过度拟合的模型对于训练数据给出了很好的结果，但是对于看不见的新测试数据却表现不佳。一个例子是 96%的训练准确率和 68%的测试准确率。一种解决方案是使用更适合数据的算法或模型，如 k 倍交叉验证(本章稍后解释)。

## 数据拟合不足

当相对*僵化的*模型运行时，会发生欠拟合，该模型过于简单，无法捕捉输入数据中的所有趋势。这通常在训练数据和测试数据上都得分较低。拟合不足、不太灵活的模型具有低方差和高偏差。图 [2-9](#Fig9) 显示了与图 [2-8](#Fig8) 中的*过拟合*模型相同的原始数据的欠拟合。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig9_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig9_HTML.jpg)

图 2-9

欠拟合

## 数据的理想拟合

理想情况下，您需要一个基于方差的误差和基于偏置的误差都较低的模型，如图 [2-10](#Fig10) 所示。因为，如等式 [2.5](#Equf) 所示，误差与偏差的平方成比例，与方差成线性比例。因此，偏差与方差的权衡非常重要。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig10_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig10_HTML.jpg)

图 2-10

理想匹配

在 ML 中，一个重要的期望方面是实现一个“完美点”或“甜蜜点”，作为过度拟合和欠拟合模型之间的平衡，如图 [2-11](#Fig11) 所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig11_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig11_HTML.jpg)

图 2-11

完美或甜蜜的地点

为了实现良好的拟合，遵循以下经验法则。

*   过度拟合和欠拟合都会降低模型性能。

*   过度拟合相对难以发现，因为它在训练数据上表现很好，但在看不见的新测试数据上表现很差。过度拟合模型倾向于“记忆”数据。确认的几种方法是尝试不同的算法，如 k-fold 交叉验证来验证或*阻止*验证数据集或尝试重采样。

*   欠拟合更容易发现，因为它在训练和测试数据上都表现不佳。

减轻模型中过度拟合的过程称为*正则化*。正如本章前面所讨论的，正则化可以通过几种方式实现。最近与量子机器学习相关的工作正在寻找正则化的方法之一是*优化*，这将在接下来的章节中讨论。

学习过程中应用的正则化量可以用*超参数*来控制。超参数是与学习算法相关但与模型无关的参数。超参数在训练数据之前是固定的，并且在整个训练过程中保持不变。*超参数调整*是构建 ML 系统的一个非常重要的方面。随着我们在书中的深入，我们会对其进行扩展。超参数调整在计算上是昂贵的，但有时是不可避免的。设置错误的超参数的影响可能是深远的。例如，如果正则化超参数设置得非常大，则绘图可能几乎是平坦的，梯度接近于零。相关的学习算法可能不会表现出过度拟合，但是它不会产生可接受的好的解决方案。

优化的一个例子是通过将参数子集删减为零来防止算法中的长迭代。如果模型的参数由 *τ* 给出，那么它与由 *a 成本函数 C* 定义的*成本*相关联。成本函数 *C* 由几个不同的方面组成，其中最重要的是*损失*。损失函数将在本章后面更详细地讨论。损失衡量一个模型的预测与目标的接近程度。

## 模型准确性和质量

机器学习使用类似于学校考试分数的评分策略。*精度*由下式定义

![$$ accuracy=\frac{number\ of\ correctly\ classified\ cases}{total\ number\ of\ cases} $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equg.png)

另一方面，误差被定义为准确性的反义词。

![$$ error=1- accuracy $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equh.png)

从定义可以直观的看出，误差是*错误分类的病例数*与*总病例数*的比值。这种估计精度和误差的方案类似于利用近似值的经验法则，而不是采用面向精度的算法。

在实践中，有明确定义的方法来估计精度和误差以及两者之间的关系。例如，一些方法包括*假阳性*和*假阴性*。正则化可以由成本函数定义如下。

![$$ C\left(\tau \right)= regularizer+ loss\left(\ \tau \right) $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equi.png)

2.6(a)

其中，*正则子*是惩罚表达式。正则化器向训练参数添加约束。这涉及一种将乘以非负数的较小系数向量相加的方法:

![$$ C\left(\tau \right)=\alpha \left(\lambda \right)+ loss\left(\ \tau \right) $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equj.png)

2.6(b)

其中 *λ* 是小系数向量。 *α* 为非负数。 *α* ( *λ* )是惩罚项(或*正则项*)，可以根据我们希望赋予它的权重而变化。如果 *α* = 0，则正则化为零，因此正则化不存在。随着 *α* 变大，具有较大范数的参数受到严重惩罚。范数的选择通常被认为是 L1 或 L2，这是量子计算和量子机器学习未来章节的重点。

## 贝叶斯学习

*贝叶斯学习* (BL) [17]是一种重要的机器学习方法，因为它具有根本不同的逻辑，并使用概率模型。BL 试图将学习转化为一个计算问题。这种学习视角利用的是整合而不是优化。

贝叶斯定理指出，给定 *B* 的概率， *A* 的概率等于 *A* 的概率乘以给定 *A* 的 *B* 的概率除以 *B* 的概率。从数学上讲，这意味着以下几点。

![$$ P\left(a|b\right)=\frac{P(a)P\left(b|a\right)}{P(b)} $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equk.png)

(2.7)

其中， *a* 和 *b* 是随机变量 *A* 和 *B* 的子集或值，并且

![$$ P\left(a|b\right)=\frac{P\left(a,b\right)}{P(b)} $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equl.png)

(2.8)

其中， *P* ( *a* ， *b* )是 *a* 和 *b* 都发生的概率。术语*P*(*a*|*b*)称为*后*，*P*(*b*|*a*)称为*可能性，*和 *P* ( *a* )称为*前*。如果给我们一个训练数据集， *D* ，随机变量 *a* 和 *b* ，目标是考察概率， *P* ( *a* ， *a* | *D* )。 *P* ( *a* ， *a* | *D* )是发现发生事件的概率 *a* ，给定 *a* 给定 *D* 。在数学上，该模型表示为

![$$ P\left(a,a|D\right)=\int P\left(a,b|\tau \right)P\left(\ \tau |D\right) d\tau $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equm.png)

(2.9)

其中， *τ* 为模型的参数。 *P* ( *a* ， *b* | *τ* )是模型的参数化分布，写成无条件概率。*P*(*τ*|*D*)是给定数据，某个期望的参数集是正确选择的参数集的概率。从概念上讲，训练数据集的根本原因是为给定数据找到一个最佳参数，在这种情况下，由 *τ* 表示。未知项*P*(*τ*|*D*)可以使用贝叶斯公式计算，公式如下

![$$ P\left(\ \tau |D\right)=\frac{P\left(\ \tau \right)P\left(\ D|\tau \right)\kern0.5em }{\int P\left(\ \tau \right)P\left(\ D|\tau \right) d\tau} $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equn.png)

(2.10)

这里， *P* ( *τ* )解决了之前对参数的假设，这导致了在模型看到数据之前的最佳模型*。贝叶斯学习中的先验 *P* ( *τ* )允许在没有看到数据的情况下对参数 *τ* 进行*有根据的猜测。如方程式 [2.6](#Equi) 所示，在某些情况下，它可以与*正则化子*相关联。基于集成的方法和基于优化的方法之间存在权衡。当缺乏已知的结构时，两者都具有挑战性，并很快成为难以解决的问题。**

## 应用 ML 工作流

我们经常得到大量的数据，坐下来思考，“我到底该如何处理这些数据，我该如何解决这个问题？”。解决 ML 问题有一些基本的经验法则。以下是大致的步骤。

1.  获取数据。

2.  探索数据。数据是关于什么的？

3.  建立一个模型。

4.  评估模型。这个模型有效吗？

5.  优化模型。

6.  部署模型并监控性能。如有必要，调整模型并重试。

*数据探索*是开始构建高效 ML 模型的关键步骤。这包括三个主要步骤。

1.  数据收集

2.  数据清理

3.  数据处理

尽管数据收集是标准流程，但数据清理可能是整个 ML 工作流程中最耗时的流程之一。清理脏数据、充满不可理解的特殊字符的数据、算法不能很好理解的空格以及各种其他类型的噪音一直是数据工程师和科学家的灾难。如今，有一些现成的数据清理解决方案；例如，谷歌云平台(GCP)托管的 Dataprep 工具。

如果预期目标不明确，数据处理的任务可能会很棘手。一个 ML 爱好者需要定义一个目标，她/他试图通过向模型提供数据集来实现这个目标。现在有 Python 和其他语言的专用库，极大地方便了数据处理。Python 特别有 NumPy、Pandas 和 scikit-learn，它们贯穿于本书。ML 的整体工作流程如图 [2-12](#Fig12) 所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig12_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig12_HTML.jpg)

图 2-12

机器学习工作流

数据探索的下一步是*建模*。这包括数据检查、从数据中提取特征集、选择最适合数据集的适当算法，以及最终构建所需的模型。

第三步*模型评估*，涉及误差估计和精度计算。

第四步是*模型优化，*向模型输入更多数据，并调整参数以获得更好的性能。一旦优化完成，输出将反馈到步骤 2 和 3，直到误差和精度水平被认为是可接受的。

第五步也是最后一步是*模型部署*，涉及生产级使用和可视化。

## 模型验证

一旦我们决定了一个模型，并构建和测试了它，我们需要验证它。用已经看到的数据来验证模型是错误的。例如，如果我们重用训练数据来测试模型，那么它的预测将会非常好，因为它是在已经看到的数据上测试的。因为模型对该数据集的预测是“正确的”，所以它对模型预测的效率产生了错误的信心。同样的模型，当用新数据测试时，可能会在预测中表现得更差。因此，一种常见的做法是将数据集分开用于训练和测试，下面将简要讨论其中的一些数据集。

## 坚持的方法

这种方法只是将部分数据作为训练集进行“筛选”，以评估模型并选择最佳模型；然后测试模型(即，用剩余的数据作为测试集来验证它)。这意味着“测试集”是随机选择的，并保留用于测试。

在 hold-out 方法中拆分数据是 ML 中的常见做法。根据经验，数据被随机分成 80%或 75%，或 70%的训练数据和 20%或 25%或 30%的测试数据，如图 [2-13](#Fig13) 所示。

这种分割没有固定的规则。在进行分割时，要牢记数据的性质和训练的计算成本。训练数据量越大，计算成本越高。作为一个讨论的问题，如果数据集中的划分是，例如，50%训练和 50%测试，那么这是*而不是*被认为是“好的”,因为训练数据量太低，增加了模型可能没有看到足够的数据来有效训练的风险。类似地，大约 95%的训练数据和 5%的测试数据的分割是不理想的，因为这样测试数据的百分比太低了。这是不可接受的，因为如果最终模型在太大的数据集上训练，那么用在小得多的数据集上训练的模型来测试它是不理想的。这可能类似于选择一辆 f1 赛车参加沙漠中的达喀尔拉力赛。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig13_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig13_HTML.jpg)

图 2-13

坚持验证

尽管保留法适用于通用数据，但当某些数据可能有偏差时，它不是很有效。例如，考虑一个 ML 考试，学生从 50 个问题库中得到 20 个问题，这些问题是简单和困难问题的混合。因为在坚持法中，数据是随机选择的，所以我们在这种情况下随机选择问题。假设这个学生在这次考试中得了 80 分。在这种情况下，我们可以认为他的分数反映了他对该学科的真实知识吗？我们不能。这可能是因为由于问题选择的随机性，大多数问题都比较容易。为了获得他的知识的真正精髓，我们需要对同一名学生和类似的随机选择的数据集进行更多的测试，然后取平均分数。

由于保留方法中的训练/测试分割是随机进行的，如果选择了代表整个数据特征的全面数据集，模型可以很好地学习并提供很好的预测。此外，如果测试集也是相对容易的测试集，则该模型可以提供高精度。但是数据选择的随机性使得训练和后续预测的准确性有些不可靠。例如，我们可以选择一个缺乏数据多样性的“弱”数据集进行训练，其中模型没有学到多少东西，并最终根据剩余的数据对其进行测试，这些数据包括模型未知的大多数多样性，从而导致模型性能较差。因此，在排除法中，模型精度可能会因数据的随机分割而发生显著变化。

### 交叉验证法

我们如何确保更好、更有效地验证数据驱动模型？一个解决方案是*交叉验证*。交叉验证的基础如下:在训练集上训练模型，然后每个验证集评估一次。然后对评估进行平均。这种方法提供了更高的精确度。然而，因为训练时间乘以验证集的数量，所以这在计算上比以前的保留方法更昂贵。其中一种也很常见的交叉验证方法是 *k 倍交叉验证*。

在选择模型的一般情况下，训练数据有可能不代表整个数据集，在这种情况下，数据集可能是偏斜的，并且可能发生过度拟合。k 重交叉验证有助于避免这种情况，因为在这种情况下，模型是使用训练数据集中的数据来训练的。然后，使用为测试保留的数据来评估模型性能。

在 k 重交叉验证中，数据被分成 10 到 20 块 *k* 等截面，称为 *k 重*。图 [2-14](#Fig14) 显示了 k 重交叉验证工作流程图。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig14_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig14_HTML.jpg)

图 2-14

k 倍交叉验证

通常情况下，其中一个褶皱，比如褶皱- *i* (图 [2-14](#Fig14) 中=5)，是预留给*测试*的。图 [2-14](#Fig14) 中的其他褶皱用于训练。一旦训练完成，模型将根据 fold- *i* 进行测试。以这种方式，在通过训练和测试循环所有折叠之后，比较预测的准确性。

图 [2-15](#Fig15) 描述了一个 k 倍交叉验证的例子，其中 k = 6。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig15_HTML.png](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig15_HTML.png)

图 2-15

六重交叉验证

这种六重交叉验证将其数据分成六个块，一个保留用于测试，其余五个数据折叠保留用于训练。精确度栏显示精确度在 80%到 92%之间变化。平均精度由下式给出

![$$ \frac{80+82+88+90+85+92}{6}=86.17 $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equo.png)

可以对同一数据集的不同范围的不同算法运行交叉验证。根据哪种算法提供了可接受的精度范围，可以选择该算法作为给定数据集的最佳算法。

总之，交叉验证是*而不是*通常用于寻找最佳表现模型。它更多地用于验证或了解特定模型对于给定数据集和新测试数据的性能。现实生活中的一般方法是通过测量模型来调整它，同时用不同的参数改变它。

交叉验证的优点是，它有助于用数据系统地测试新模型，并且可以识别具有高方差或过度拟合问题的模型。

交叉验证的一个缺点是对数据集运行多个模型可能计算量大且耗时。目前解决时间问题的一种方法是在多个 CPU/GPU 核心或集群上并行运行交叉验证任务。

作为一个体验 k-fold CV(交叉验证)的练习，让我们看一下`kFoldCV.ipynb`代码。这里使用的数据是一个公开的数据集，名为*虹膜*。这个特定的数据集由 150 朵鸢尾花的花瓣和萼片的长度和宽度的测量值组成。数据集中有三类鸢尾花，每类 50 个实例:海滨鸢尾、杂色鸢尾和刚毛鸢尾[13]，如图 [2-16](#Fig16) 所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig16_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig16_HTML.jpg)

图 2-16

鸢尾(Radomil，CC BY-SA 3.0)、杂色鸢尾(Dlanglois，CC BY-SA 3.0)和海滨鸢尾(Frank Mayfield，CC BY-SA 2.0)

清单 [2-2a](#PC2) 、 [2-2b](#PC3) 和 [2-2c](#PC4) 中的代码查看一个模型，该模型试图根据给定的属性(花瓣和萼片的宽度和长度)预测正确的鸢尾属物种。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figc_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Figc_HTML.jpg)

```
#Import Libraries
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn import svm  #import (SVM) for classification
from sklearn import datasets
iris = datasets.load_iris() #load the data
# Data split into train/test sets with 25% for testing
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=0)
# Train data for Linear Support Vector Classifier (SVC) model for prediction
clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
# Performance measurement with the test data
clf.score(X_test, y_test)

Listing 2-2a
k-Fold Cross-Validation

of Iris Dataset from kFoldCV.ipynb

```

scikit-learn [14]的 val_score 库允许我们通过交叉验证来评估分数。数据被输入到 train_test_split()函数，该函数便于将数据分割成训练和测试块。在这个模型中，我们从训练 75%的数据和测试 25%的数据开始，这由 test_size=0.25 指定。按照 k-fold CV 的惯例，测试数据是随机抽取的(random_state=0)并留作测试之用。

该方案给我们四个数据集:`X_train`包含 75%的虹膜测量数据，`X_test`包含 25%的保留用于测试的虹膜测量数据，`y_train`和`y_test`包含对应于测量的物种。

使用的模型是*支持向量分类* (SVC)，它是支持向量机(SVM)的一部分。这将在本章后面讨论。此处型号命名为`svc`。`score()`函数测量 SVC 模型的性能。针对保留的测试数据集对 SVC 模型进行评分。分数给定为

![$$ 0.9736842105263158 $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equp.png)

(2.11)

然而，由于数据集大小只有 150，这是一个相当小的数据集，其中 75%用于训练，25%用于测试。因此，我们很有可能过度适应。k 倍交叉验证是一个很好的方法来验证这一点，看看我们是否有更好的拟合。

在`kFoldCV.ipynb`代码的下一部分，如清单 [2-2b](#PC3) 所示，SVC 模型用于将整个数据集(即`iris.data`的测量值)和目标数据`iris.target`传递给函数`cross_val_score().`，我们使用交叉验证`cv=5,`，这意味着它将使用五个不同的数据集，并保留一个数据集用于测试。数据集是随机选择的。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figd_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Figd_HTML.jpg)

```
#cross_val_score a model, the data set, and the number of folds:
cvs = cross_val_score(svc, iris.data, iris.target, cv=5)
# Print accuracy of each fold:
print(cvs)
# Mean accuracy of all 5 folds:
print(cvs.mean())

Listing 2-2bContinued: 5-Fold Cross Validation

kFoldCV.ipynb

```

这段代码从每次迭代(总共 5 次)或“折叠”中返回一个错误值列表，如下所示。

![$$ \left[0.96666667\kern2em 1.\kern2.25em 1.\kern2.25em 0.96666667\kern1.75em 1.\kern2.25em \right] $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equq.png)

然后对这五个值进行平均，以给出虹膜数据集的 k 倍 CV 的误差度量。

![$$ 0.9866666666666667 $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equr.png)

(2.12)

如果我们比较 2.12 和 2.11 的结果，我们可以立即推测 5 倍 CV (2.12)的结果比以前更好；因此，这是一个明确的改进。

这里通常的方法是看看是否有比这个结果更好的方法。为了获得 2.6 的结果，使用了线性核(`kernel=` ' `linear`')。一种方法是用可能更适合的基于多项式的内核来测试模型和相应的数据行为。线性拟合是否优于多项式拟合取决于数据特征。因此，看看清单 [2-2c](#PC4) 中所示的`kFoldCV.ipynb`代码的下一部分，我们尝试了一个内核，它是多项式的 *poly* 。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fige_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fige_HTML.jpg)

```
svc = svm.SVC(kernel='poly', C=1).fit(X_train, y_train)
cvs = cross_val_score(svc, iris.data, iris.target, cv=5)
print(cvs)
print(cvs.mean())

Listing 2-2cContinued: K-Fold Cross-Validation with Polynomial Kernel

from kFoldCV.ipynb

```

运行多项式内核后，它会给出以下五倍误差值和相应的平均值。

![$$ \left[0.96666667\kern1.75em 1.\kern2.25em 0.96666667\kern1em 0.96666667\kern2.5em 1.\kern2em \right] $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equs.png)

![$$ 0.9800000000000001 $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equt.png)

(2.13)

2.13 和 2.11 之间的比较表明，多项式核给出的值低于线性核。这表明多项式可能过拟合。这里要吸取的教训是，如果我们没有使用 k 倍 CV 进行验证，而是使用标准的训练/测试分割，我们就不会意识到我们过度拟合了。这是一个简单但很好的例子，说明了 k 倍简历的重要性。

线性模型通常不太灵活，因为它只有两个自由度，而高次多项式由于有几个自由度而非常灵活。k 倍交叉验证运行的结果通常用模型技能得分的平均值来概括。一个好的做法是测量技能分数的方差，如标准差或标准误差。CV 因为简单而受欢迎。与其他方法(例如简单的训练/测试分割)相比，它通常会导致对模型技能的更少偏差或更少乐观的估计。

#### 回归

*回归*是研究如何最好地拟合一条曲线来汇总数据。例如，农业产量“通常”与降雨量直接相关。回归构成了监督学习的一些最强大和最广泛研究的算法。在这种方法中，我们试图通过可能最适合它们的曲线来理解数据点。回归算法有几种类型。随着我们进入量子机器学习的领域，将有更多关于回归和相关算法的内容要说。

### 线性回归

顾名思义，*线性回归*是对一组观测数据进行直线拟合。一个例子是足球队队员的身高和体重。图 [2-17](#Fig17) 显示了该数据集中的数据和曲线。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig17_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig17_HTML.jpg)

图 2-17

线性回归

在图 [2-17](#Fig17) 中，X 轴表示身高，Y 轴表示体重。一旦绘制了数据点，教练可能会看着图并认为虽然大多数球员的身高和体重匹配，但有些人不匹配，他们可能需要开始健身制度来增加或减少一些体重。如果教练画一条曲线来最好地拟合这些数据点，他可能会以一条直曲线或一个线性图结束。

在这个例子中，曲线的方程由一条直线给出，它是 *y* = *mx* + *c* ，其中 *m* 是直线的斜率 *c* 是常数。线性回归可以建模为确定性函数[5]。

![$$ f\left(x;\tau \right)={\tau}_0+{\tau}^{\epsilon }x $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equu.png)

(2.14)

其中，参数包含在向量*τ*∈ℝ<sup>T3】nt5】和 x∈ℝ<sup>T7】nT9】中，其中ℝ是实数的空间， *N* 是参数的维数。偏差*τ*t14】0 可以包含在*τ*<sup>*ϵ*</sup>*x*中作为一个额外的维度。</sup></sup>

线性回归中的学习考虑寻找参数 *τ* ，该参数可以将方程 [2.14](#Equu) 中的函数 *f* 拟合到训练数据以进行有效预测。

#### 最小平方技术

*最小二乘技术*包括使用平方损失(本章稍后解释)。直线拟合中产生的误差由各个数据点到直线的距离给出。我们将所有这些误差平方，并计算它们的总和。这样，如果有负误差，那么从误差产生的角度来看，它们不会抵消正误差，给我们一个假阳性。

这类似于方差计算。一旦知道了数据点的距离，就可以计算出误差并使其最小化。

#### 梯度下降

*梯度下降* (GD)是一种迭代技术，它逐渐调整一组特定训练数据集的模型参数，以最小化成本函数。这种技术可以找到各种问题的最佳解决方案。GD 的理论性深入文献可以在参考文献[15]中找到。GD 中的一个标准挑战是在不知道误差曲线的情况下找到一个最优值*！*

该过程包括从图 [2-18a](#Fig18) 中 X 轴上变量 X 的随机值开始。X1 的随机误差可通过关系式 error = f(x1)计算。误差的梯度也可以用斜率来计算。数学上，我们需要取误差函数的*导数*来计算梯度。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig18_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig18_HTML.jpg)

图 2-18a

梯度下降步骤 1

误差导数给了我们斜率或梯度倾斜方向的指示。此时，随机计算第二个数据点 x2(如果未知)，如图 [2-18b](#Fig19) 所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig19_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig19_HTML.jpg)

图 2-18b

梯度下降步骤 2

接下来，如图 [2-18c](#Fig20) 所示，点 x2 的误差计算为 error = f(x2)，测量误差梯度，然后我们“猜测”点 x3 的值并重复该过程。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig20_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig20_HTML.jpg)

图 2-18c

梯度下降步骤 3

最后，计算完所有数据点及其梯度后，梯度下降曲线如图 [2-18d](#Fig21) 所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig21_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig21_HTML.jpg)

图 2-18d

梯度下降步骤 4

GD 计算从一个随机点开始，猜测下一个。随着我们越来越接近收敛，这些步骤变得越来越小。步长在接近收敛时变得重要，以免错过或超过最小值。GD 中的一个常见问题是接近最小值。对此的解决方案是从随机点开始多次运行该算法，最终，该算法找到最小值。

梯度下降有几种变化。以下是最重要的两个。

*   **批量梯度下降**:在这种方案中，每种算法在整个训练数据集上为梯度的每次迭代计算成本。该算法的一次迭代被称为*批次*。

*   **随机梯度下降(SGD)** : SGD 为每个训练实例计算系数，而不是在一批实例结束时。相比之下，对于大型数据集，GD 可能会很慢，因为每次迭代都需要对数百万个数据集进行计算。SGD 将训练集随机化以减少系数多样性，并帮助避免陷入局部最小值。SGD 对于大型数据集非常有效，因为它只需要相对很少的次数(通常为 10 到 20 次)就可以收敛。

#### 非线性和多项式回归

*多项式回归*用于更一般的回归情况，其中数据分布可能不太适合线性(直线)拟合。多项式拟合允许更多的自由度。然而，更多的自由度并不总是好的；根据数据集的不同，它可能会导致过度拟合。

目前 ML 中最成功的非线性回归模型是*神经网络*，你在下一章看。

#### 分类

机器学习算法中的分类是一项基本任务，它处理将类别标签分配给来自问题领域的示例。

机器学习中的预测建模有各种类型的分类。本节重点介绍以下类型。

*   二元分类器

*   多类分类器

*   多标签分类器

*   不平衡的分类

唯一标记数据的类别提供了为特定任务表征数据的明显优势。前一节讨论了*回归*，它主要是关于数据集的曲线拟合。您已经看到最佳拟合曲线是一个输入数据项并分配一个数字的函数。与回归相反，*分类*指的是一个 ML 模型，它为其输入分配离散的标签。分类通常是处理*类*或离散值的监督学习算法。典型的输入是特征向量，典型的输出是类。

*预测建模*的一个很好的例子是我们在本章前面的 ML 的第一个用例:垃圾邮件过滤器。这基本上包括将电子邮件分类为“垃圾邮件”或“非垃圾邮件”

对于一个*二进制分类器*，输出是*二进制*(即是/否、真/假、开/关等。).从一个*神经网络*(下一章讨论)来看，输出层只有一个神经元可以做到这一点，常见的激活函数有`sigmoid`或`logistic`。下面是二进制分类工作的例子。

*   垃圾邮件过滤器:它是垃圾邮件吗？是/否

*   交易欺诈预测:是欺诈吗？是/否

二元分类任务通常包括被认为是正常状态的类别 0 和被称为*异常状态*的类别 1。例如，“非垃圾邮件”将被视为正常状态，而“垃圾邮件”将被视为异常状态。某些算法，如逻辑回归和支持向量机(SVM)，支持二进制分类，但不支持两个以上的类别。就其基本形式而言，SVM 不支持多分类[272]。它只是通过将多分类问题分解成多个二元分类问题的过程来实现的。

直观地说，*多类分类器*不是二元的。例如，将一个数字归类为前十个数字{0 到 9}之一。从*神经网络*的角度来看，这需要*每类*一个神经元。因此，这种类型的分类器通常需要多于一个神经元。多类分类器的另一个例子是光学对象分类(面部、植物等。).在神经元网络处理中，`softmax` *函数*处理多类分类器。

*多标签分类*是指具有两个或两个以上类别标签的任务，其中每个数据点可以预测一个或多个类别标签。一个例子是其中具有多个对象的照片和可以预测多个已知对象的存在的相应模型，诸如汽车、大象、人等等。在二进制和多类情况下，处理单个类标签，而在多类情况下，有两个或多个类标签。

*不平衡分类*涉及每类中的实例数量*而非*平均分布的任务。典型地，不平衡分类任务是二元分类任务。例如，训练数据集中的许多数据点属于类 0，少数示例属于类 1。为了简化计算任务，有时使用诸如对多数类欠采样或对少数类过采样之类的专门技术来操纵训练数据集。类似地，也使用专门的建模算法。

#### 数据驱动预测

大多数 ML 算法都有相同的总体特征:它们被输入数据并输出对查询的响应。在这个大数据时代，实时原始数据的检查和评估至关重要，尤其是在金融行业和网络安全领域。当一个金融机构希望预测股票价格时，他们可以查看价格预测的时间序列值。

如果数据的处理涉及图像分析，那么图像的内容和相应的排序被视为*分类*。通常，数据被认为是输入，模型的预测被认为是*输出*。

预测模型及其用法的例子多种多样。其中一个就是*图像识别*。如果我们看到一头大象，我们通过视觉刺激认出它是一头大象，因为我们通过观察它们或它们的照片了解了大象是什么。然而，如何给计算机编程以本能地识别大象并不是直观上显而易见的。在 ML 中，我们向计算机呈现许多图像，它从这些图像中学习大象的“样子”。同样，也可以教会计算机老虎长什么样。因此，在用图像作为输入数据的几次这样的*训练*之后，计算机学会了如何对大象和老虎进行分类。系统看到的各种形状、大小和姿势的大象和老虎的图像越多，识别和分类它们的效率就越高。

*时间序列*数据的*预测*是一个重要的预测应用。在不同时间点记录的一组数据点构成了时间序列数据。数据点是在相邻的时间段收集的；因此，考虑观察值之间存在相关性的可能性是合乎逻辑的。如果我们考虑涵盖两次美国选举的连续八年的美元记录值，我们可以找到同一时期的重要宏观经济变量的记录，如国内生产总值(GDP)、黄金价格或原油价格。由于美元的价格受其他指标和政治变化的影响，并且我们通过时间了解其价格行为，如果某个政党赢得总统选举，我们可能能够预测美元价格在给定年份的变化。

另一个重要的预测与医学或故障查找有关，它被称为*诊断*。例如，如果我们试图根据人们的胆固醇水平、血压、年龄、体重、吸烟习惯或锻炼方式来预测心脏骤停的发生，我们将无法肯定地预测心脏病发作。相反，考虑到这些因素，我们也许能够预测它发生的可能性有多大。这种类型的预测基于*逻辑回归*。

Note

*逻辑回归*，尽管听起来好像是一个*回归*算法，但它是一个分类算法。逻辑回归被认为是机器学习研究人员采用的统计回归模型，他们将其用作分类器。

以下是一些常见的预测模型。

*   线性回归

*   多变量回归

*   多项式回归

### 复杂性

问题的复杂性是指从算法、计算时间等角度对涉及资源使用的问题类别的研究。为了估计总的计算成本，需要对资源进行分析。这是通过运行解决问题所需的算法来完成的。

计算机运行一个算法的时间就是该算法在特定计算平台上的运行时间。根据经典计算的基本原理，通过验证数据库中的项目直到找到一个期望的项目，可以获得数据库搜索目标的解决方案。这个练习需要时间复杂度为 *O* ( *n* )的最坏情况场景。

*算法的计算复杂度*是算法的时间、规模和相关资源需求如何随着数据集或问题规模的增长而发展的量化表达。算法旨在应用于未知函数或一组数据，以确定函数的属性(如周期或最小值)、因数或分类数据。

函数的输入数量(即数据大小)可以是从一位数到数万亿或更多。有很多算法，我们有足够的时间去挑选和试验它们，直到我们找到完成这项工作的算法。一旦我们选择了一个我们认为服务于我们的目的或目标的算法，我们需要决定对以下问题的回答。随着输入数量的增加，算法的运行时间表现如何？这被称为算法对*大小*的*敏感度*。

随着算法问题规模的增长，它的运行时间也在增长。这被称为*时间复杂度*。以下是下一章要讨论的一些时间复杂性。

*   恒定时间复杂度

*   多项式时间复杂度

*   非多项式时间复杂度

第 [1](1.html) 章提到了计算复杂性，这将贯穿全书。当我们谈到量子机器学习的复杂性时，我们会深入讨论它。

#### 混淆矩阵

现在我们已经探讨了分类的基本原理，接下来我们来看看*真阳性*(TP)*假阳性*(FP)*真阴性*(TN)*假阴性* (FN)。当一个分类器说一个数据点是 *X* 时，它就是 *X* ，这就是所谓的*真正*。当分类器将一个数据点识别为 *X* ，但它实际上是一个 *Y* 时，就会出现假阳性。当一个数据点被归类为*而不是 X* ，并且它真的不是*时，为真否定。*

最重要的分类指标是*准确度*，这在本章前面讨论方差和偏差时已经讨论过了。精确度是有定义的，但是让我们在这里扩展一下这个定义。

![$$ accuracy=\frac{number\ of\ correctly\ classified\ cases}{total\ number\ of\ cases} $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equv.png)

![$$ =\frac{\  TPs+ TNs}{total\ number\ of\ cases} $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equw.png)

数据科学家和工程师也有兴趣知道分类器如何避免错误警报。这是由分类器的*精度*定义的。

![$$ precision=\frac{\  TPs}{TPs+ FPs} $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equx.png)

如果我们不希望错过任何一个 TPs，并且希望尽可能多地捕捉到 *X* s，那么衡量成功的标准就是所谓的*召回*。

![$$ recall=\frac{\  TPs}{TPs+ FNs} $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equy.png)

直观表示 TPs、FPs、TNs 和 FNs 的标准方法称为*混淆矩阵*。例如，对于二进制分类，**混淆矩阵**是一个 2 × 2 的表格，如下所示。

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
|   | 归类为**是** | 分类为**否** |
| 真**是** | TPs 数量 | 联合国编号 |
| 真**否** | FPs 数量 | TNs 数量 |

其中，TP 为真正；FP 是假阳性；TN 是真阴性；FN 是假阴性。

例如，如果诊所中的患者被分类为正确诊断患有癌症，或错误诊断患有癌症，或患有癌症但未被诊断，或未患癌症但被正确诊断为未患疾病，则癌症诊断过程的*混淆矩阵*如下表所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figr_HTML.png](../images/502577_1_En_2_Chapter/502577_1_En_2_Figr_HTML.png)

f *-score* 或 *f-measure* 是*精度*和*召回*的调和平均值。使用 f 分数是因为虽然精确度和召回率是非常重要的度量，但是只处理其中一个并不能向我们呈现完整的场景。F-score 是总结这两个值的一种方式，并且提供了对分类器性能的更现实的测量。

### 监督学习

一个*监督学习* ML 算法被呈现为输入数据样本或*训练集* *s* 被*标记为*，并输出对特定问题的响应。在这种情况下，训练集包括期望的解决方案或*标签*，这允许它从数据中学习。这里的目标是从训练集中学习，以便可以对算法以前看不到的新数据进行有意义的预测。监督学习通常分为两种:回归和分类。

垃圾邮件过滤器用例是一个名为*分类*的监督学习任务的例子。该过滤器一直使用已知的垃圾邮件样本进行训练。它看到的训练数据越多，就越能更好地完成分类哪些邮件是垃圾邮件，哪些不是的任务。该算法会将电子邮件归类为垃圾邮件分类和“欺诈”或“非欺诈”表 [2-1](#Tab1) 列出了一些最常见的监督学习算法和相关的用例。

表 2-1

监督学习算法的例子

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

监督学习方法

 | 

例子

 | 

算法

 |
| --- | --- | --- |
| 回归 | 股价预测，房价预测 | 线性回归，岭，套索，多项式 |
| 分类 | 垃圾邮件:欺诈/非欺诈，癌症/非癌症 | 逻辑回归，SVM，KNN |
| 决策树 | 预测股票价格(回归)，分类(信用卡欺诈) | 决策树，随机森林 |

类似地，如果我们使用威斯康星州乳腺癌数据集<sup>[1](#Fn1)</sup>【12】来训练诸如逻辑回归或 KNN 的 ML 模型，则可以基于特征的分类来预测患者是否患有癌症。

监督学习的主要目标之一是实现低偏差和低方差误差。

#### 从数据到预测

从监督模型中的数据进行预测的途径包括四个基本步骤。

作为第一步，数据被清理、处理，并且选择*模型族*作为第一猜测。由于这是监督学习，所以需要对数据进行标注，并且知道数据特征和定义。例如，数据可以用线性加权函数来表示。通过拟合参数来训练模型。步骤如图[2-19(a-d)](#Fig22)所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig25_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig25_HTML.jpg)

图 2-19d

数据驱动预测的第 4 步

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig24_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig24_HTML.jpg)

图 2-19c

数据驱动预测的第 3 步

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig23_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig23_HTML.jpg)

图 2-19b

数据驱动预测的步骤 2

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig22_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig22_HTML.jpg)

图 2-19a

数据驱动预测的第一步

在图 [2-19a](#Fig22) 中，显示了具有未知关系的输入 *x* 和输出 *y* 的一维数据集。在图 [2-19b](#Fig23) 中，选择一个模型；例如，诸如回归的线性模型和用于分类的*双曲正切*函数。图 [2-19c](#Fig24) 显示了使用训练集拟合数据的训练模型，同时测试数据集在训练后验证模型。在图 [2-19d](#Fig25) 中，输入*x*T16】’被馈入模型，得到输出*y*<sup>’</sup>。

在监督学习中，一个*目标函数*通常是通过先定义一个函数 up 来*估计*，比如 *y* = *f* ( *x* )，其中 *x* 是输入， *y* 是输出。

错误有三种主要类型。

*   方差误差

*   偏移误差

*   不可约误差

与方差或偏差误差不同，不可约误差，顾名思义，是不能减少或最小化的。它们通常是由未知的变量或参数或数据中无法消除的噪声引起的。

#### 支持向量机(SVM)

SVM 是一种监督学习技术。支持向量机在 ML 中非常流行，是所有 ML 爱好者都应该知道的工具。支持向量机对于表现出复杂性的中小型数据集的分类特别有用。本节重点介绍 SVM 的核心功能。这些最大似然算法在数学上是稳健的，并且自 20 世纪 90 年代以来一直在研究。我推荐浏览 Aurélien Géron 的*使用 Scikit-Learn 和 TensorFlow 进行机器学习:构建智能系统的概念、工具和技术*，第二版(O'Reilly Media，2019) [15]。

SVM 是从具有多种特征的复杂高维数据集进行合理有效预测的一种简单方法。SVM 可以拯救更高维度的支持向量，并对它们进行分类。支持向量定义了所谓的*超平面*。可以利用不同的核来实现这一点，例如多项式或高斯 RBF。理解 SVM 的一个好方法是分析一些真实的数据。在本练习中，我们再次使用 Iris 数据集，并改编来自`scikit-learn` [16]的库。

##### 虹膜数据集的 SVM 示例

对鸢尾数据集的快速回顾提醒我们，公开可用的数据集由 150 朵鸢尾花的花瓣和萼片的长度和宽度的测量值组成。有三类不同的鸢尾花 50 个实例，每个都包括在数据集中:海滨鸢尾、杂色鸢尾和刚毛鸢尾[13]。您看到了*支持向量分类* (SVC)的用法，这是 SVM 的一种典型分类。SVC 类允许添加几个多项式特征*，而不需要添加它们*。从计算成本的角度来看，这有助于避免增加特征数量的压力，因为我们没有添加任何特征。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig26_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig26_HTML.jpg)

图 2-20

带有虹膜数据集的 SVM(由 scikit-learn 文档提供[16])

图 [2-20](#Fig26) (生成图形的代码可在 [`https://scikit-learn.org/stable/auto_examples/svm/plot_iris_svc.html`](https://scikit-learn.org/stable/auto_examples/svm/plot_iris_svc.html) 获得)显示萼片长度和萼片宽度，具有线性、多项式和高斯 RBF 核。如果我们目测图形，多项式核相对于线性核的灵活性是显而易见的。线性模型具有线性决策边界(相交超平面)。非线性核模型(多项式或高斯 RBF)具有更灵活的非线性决策边界，其形状取决于核的种类及其参数。

使用`scikit-learn`创建 SVM 模型不可避免地涉及到指定一些超参数，比如`C`(参见下面的代码片段)。低或高的`C`会影响图形的边界定义。之前，我们讨论了对于某些数据集，多项式核优于线性核的一些优点，这是因为前者具有更高的自由度，从而提供了灵活性。通过`poly`内核实现多项式特性很简单，如下面的代码片段所示。

```
models = (svm.SVC(kernel='linear', C=C),
          svm.LinearSVC(C=C, max_iter=10000),
          svm.SVC(kernel='rbf', gamma=0.7, C=C),
          svm.SVC(kernel='poly', degree=3, gamma='auto', C=C))
models = (clf.fit(X, y) for clf in models)

```

多项式核可以与许多 ML 算法一起工作，并且不是特定于 SVM 的。然而，最好记住，低多项式次数的`poly`内核在处理高复杂度的数据集时效率会降低。如果使用高多项式次数，则往往会以很高的计算成本创建许多要素(即，它会变得很慢)。注意，`LinearSVC`比有`kernel =`’`linear`的`SVC`快很多。

使用多项式核时要注意的一个问题是，如果模型过拟合，降低多项式次数可能会有所帮助。另一方面，如果结果是拟合不足，增加多项式次数可能是前进的方向。代码中的`gamma`类似于正则化超参数。

高斯 RBF 核的 SVC 类用不同的`C`和`gamma.`值定义，如果`gamma`增大，则使钟形部分变窄，更小的`gamma`使其变宽，给出更平滑的判决边界。在这些情况下，`gamma`作为一个正则化超参数。如果模型过拟合，应减小`gamma`；如果是欠拟合，应增加`gamma`。

其他类型的内核不太常用，比如用于文本或 DNA 序列分类的*字符串内核*。根据经验，首先尝试线性核来处理大型训练集或大型特征集。对于非常大的数据集，高斯 RBF 核也能很好地工作。

作为 SVM 的一个练习，查看可视化选项和分类可能是有用的。我们利用 Python 的`seaborn`库，它构建在`matplotlib`之上。`seaborn`库提供了一个高级数据可视化接口来创建一个名为*热图*的矩阵表示，以二维形式表示数据。数据值在图表中用颜色表示。本节后面生成的热图(见图 [2-21](#Fig27) )的目的是提供一个彩色的可视化信息摘要。SVM 分类练习代码可以从本书的网站下载，作为`svmIris.ipynb`在 Jupyter 笔记本上运行，如清单[2-3(a–d)](#PC6)所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figf_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Figf_HTML.jpg)

```
#import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline
#Get the data and define col names
colnames=["sepal_length_in_cm", "sepal_width_in_cm","petal_length_in_cm","petal_width_in_cm", "class"]
#Read the dataset
dataset = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data", header = None, names= colnames )
#See the Data
dataset.head()

Listing 2-3aSVM Classification

of Iris Dataset: Importing Libraries and Observing Data

```

清单 [2-3a](#PC6) 导入所需的库，包括`seaborn`，下载 Iris 数据，并以下面的表格格式打开数据头定义。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figg_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Figg_HTML.jpg)

ML 算法对数字比对文本更有效。这意味着，如果数据包含分类数据，我们必须将其编码为数字，然后才能用它们来评估模型。两种流行的技术是*整数编码*和*一键编码*。一种更新的技术，叫做*学习嵌入* g，在其他两种方法之间提供了一个有用的中间地带。

*   **整数编码**:每个唯一标签映射到一个整数。

*   **一键编码**:每个标签映射到一个二进制向量。

*   **学习嵌入**:学习类别的分布式表示。

查看数据格式，将`class`改为数字而不是花的名称可能会有用。清单 [2-3b](#PC7) 中的代码片段改变了分类格式。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figh_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Figh_HTML.jpg)

```
#Use pandas to encode the categorized columns
dataset = dataset.replace({"class":  {"Iris-setosa":1,"Iris-versicolor":2, "Iris-virginica":3}})
#Read the new dataset
dataset.head()

Listing 2-3bSVM Classification of Iris Dataset: Change the Class to Numbers

```

由于清单 [2-3b](#PC7) 中的代码，刚毛鸢尾被更改为`class` 1，杂色鸢尾被更改为`class` 2，海滨鸢尾被更改为`class` 3，如以下示例输出所示。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figi_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Figi_HTML.jpg)

接下来，让我们使用清单 [2-3c](#PC8) 中的代码用 seaborn 绘制热图。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figj_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Figj_HTML.jpg)

```
plt.figure(1)
sns.heatmap(dataset.corr(), cmap="YlGnBu")
plt.title('Correlation between iris Classes')

Listing 2-3cSVM Classification of Iris Dataset: Generate Heatmap

```

列表 [2-3c](#PC8) 生成如图 [2-21](#Fig27) 所示的热图，该图显示了花的种类与其花瓣和萼片的长度和宽度之间的相关性。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig27_HTML.png](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig27_HTML.png)

图 2-21

带有虹膜数据集的 SVM:热图

在最后一步中，在清单 [2-3d](#PC9) 中，数据被分割，SVM 分类器被创建，精确度被计算。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figk_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Figk_HTML.jpg)

```
# Split Data
X = dataset.iloc[:,:-1]
y = dataset.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)

#Create the SVM classifier model

from sklearn.svm import SVC
classifier = SVC(kernel = 'linear', random_state = 0)
#Fit the model for the data

classifier.fit(X_train, y_train)

#Make the prediction
y_pred = classifier.predict(X_test)

#Accuracy of Model
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print(cm)

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)
print("Accuracy: {:.2f} %".format(accuracies.mean()*100))
print("Standard Deviation: {:.2f} %".format(accuracies.std()*100))

Listing 2-3dSVM Classification of Iris Dataset: SVM Classifier and Accuracy code

```

以下输出显示 98%的准确性和 3.64%的标准偏差。也说明只有一个分类错误的数据。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figl_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Figl_HTML.jpg)

#### k-最近邻

k 最近邻 (KNN)是最容易在 ML 中实现的技术之一。KNN 处理结构化的、有标签的数据，并根据它们之间的*相似性*将它们分组。书籍的普及就是一个例子。在图 [2-22](#Fig28) 中，小圆圈代表犯罪小说，而方块代表科幻小说。不知何故，绘图似乎是基于距离。如果出版了流派未知(用三角形表示)的新书，算法会在训练数据中搜索与新例最近的邻居 *S* ，然后对其进行分类。KNN 不会生成分隔训练数据点的线。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig28_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig28_HTML.jpg)

图 2-22

k 近邻

KNN 的优点是易于实现，并且能够很好地处理行为良好的结构化数据。KNN 能够正确实现任意复杂的分割线，也称为*超平面*。KNN 的一个缺点是数据点中的单个错误可能会导致较差的分类结果。如果一个新的未知点紧挨着另一个类的离群点，则它被分类到错误的类中。这是*过度拟合*的另一个例子，其中对随机误差进行了拟合。

#### 误差和损失函数

在本章早些时候，我们在方程 [2.5](#Equf) 和 [2.6](#Equi) 中看到了方差、偏差及其混合关系产生的各种误差。*损失函数*是计算误差的计算函数。预测误差与用于计算它们的损失函数直接相关(即，不同的损失函数可以为相同的预测计算不同的误差)。

##### 回归的误差和损失函数

为了理解某些损失函数可能如何工作，让我们考虑六个学生在机器学习考试中的成绩。表 [2-2a](#Tab2) 列出了学生及其成绩。

表 2-2a

等级

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"></colgroup> 
| 

学生#

 | 

级别

 |
| --- | --- |
| one | fifty-six |
| Two | seventy-eight |
| three | eighty-nine |
| four | Sixty-three |
| five | Seventy-three |
| six | Ninety-one |

假设选择用来预测成绩的模型非常简单。它始终预测 75 为等级。现实中，没有一个成绩是 75。实际成绩与预测成绩之差为*残差*或*误差*，如表 [2-2b](#Tab3) 所示。

表 2-2b

等级误差/残差

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"> <col class="tcol4 align-left"></colgroup> 
| 

学生#

 | 

级别

 | 

预报

 | 

误差或残差

 |
| --- | --- | --- | --- |
| one | fifty-six | Seventy-five | 56 – 75 = –19 |
| Two | seventy-eight | Seventy-five | 78 – 75 = 3 |
| three | eighty-nine | Seventy-five | 89 – 75 = 14 |
| four | Sixty-three | Seventy-five | 63 – 75 = –12 |
| five | Seventy-three | Seventy-five | 73 – 75 = –2 |
| six | Eighty-seven | Seventy-five | 91 – 75 = 16 |

表 [2-2b](#Tab3) 显示误差之和为

![$$ \left(-19+3+14-12-2+16\right)=0 $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equz.png)

这意味着误差可以相互抵消，给人的印象是方差和偏差“很好”,而隐藏在明显的地方。然而，假设我们将这些误差平方，以去除负号并消除误差的抵消，从而更容易检查隐藏在我们“简单”模型中的陷阱。平方误差提供了放大大偏差或“异常值”的额外优势，使它们更容易检测。这导致了*误差平方和* (SSE)。

SSE 也被称为*残差平方和* (RSS)或*残差平方和* (SSR)。在本例中，我们正在处理一个玩具数据集，但实际上，一般数据都附有标签和权重。一般来说，SSE 由下面表达式中的 *E* 给出。

![$$ {E}_{SSE}=\frac{1}{2}\sum_n{\left({t}^{(n)}-{y}^{(n)}\right)}^2 $$](../images/502577_1_En_2_Chapter/502577_1_En_2_Chapter_TeX_Equaa.png)

(2.15)

其中 *t* 数据集是目标(或标签)。 *y* 是模型的输出。( *n* )是标记样本范围内各个数据的指数。因此*t*T8】(*I*)是第 *i* 个训练行向量的目标的索引。

下面是从数学上定义 SSE 的另一种方式。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figm_HTML.png](../images/502577_1_En_2_Chapter/502577_1_En_2_Figm_HTML.png)

其中 *x* 数据集是实际值，是预测值。( *n* )是标记个体数据的指标。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fign_HTML.png](../images/502577_1_En_2_Chapter/502577_1_En_2_Fign_HTML.png)

are the predicted values. The (

SSE 是 ML 中最简单、通用的错误度量之一。

还有*均方误差* (MSE)，定义如下。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figo_HTML.png](../images/502577_1_En_2_Chapter/502577_1_En_2_Figo_HTML.png)

MSE 速度快，计算梯度。但是由于它直接依赖于数据集计数，它对数据集中的偏差可能有些敏感，并且显示与数据有较大差异的预测可能会受到严重惩罚。

回归的最后一个重要误差是平均绝对误差，定义为

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figp_HTML.png](../images/502577_1_En_2_Chapter/502577_1_En_2_Figp_HTML.png)

MAE 是稳健的，一般不会受到偏差的很大影响。当数据被认为是损坏的时候使用它。选择任何回归误差函数都没有一成不变的规则。在三种常用的方法中，为了获得最佳结果，通常推荐使用试错法。

##### 分类的误差和损失函数

以下是分类任务中常用的一些预测误差损失函数。

*二元类熵*衡量实际值和预测值之间概率分布的散度，常用于二元分类。这在数学上由下式给出

![../images/502577_1_En_2_Chapter/502577_1_En_2_Figq_HTML.png](../images/502577_1_En_2_Chapter/502577_1_En_2_Figq_HTML.png)

在*分类交叉熵*中，只预测了众多标签中的一个。

以下是其他一些损失函数。

*   负对数似然

*   边缘分类器

*   软边界分类器

*   稀疏分类交叉熵

### 无监督学习

在无监督学习中，目标是在未标记的数据集中找到自然结构。该算法仅被输入数据，并且被期望自己找到有意义的结构，而没有外部监督或输入。这种类型的 ML 的一个例子是在图书馆中不断增长的文本集合中寻找聚类。这可以根据书籍主题随时间的变化、过时的讨论和主题以及作者身份来完成，这些内容对于现代读者而言可能已经变得过于敏感，而不是几个世纪前最初写作时的目标读者。

在无监督学习中，没有训练集和测试集。所有数据点都是训练数据点。聚类是从这些数据点构建的。

解决*可视化*的算法也是无监督学习的例子。可以向算法提供复杂和非结构化的数据，以获得表示的输出。

*聚类*是在数据中寻找自然分组的过程。人类的大脑倾向于自然地将我们遇到的数据聚集在一起。我们在头脑中对它们进行分类，并按照一定的类别对它们进行组织，因为我们的大脑通过为它们形成明确定义的组来简化分类。图 [2-23a](#Fig29) 显示了茶、咖啡、牛奶和果汁的分类方案。这有助于您理解数据，并找到与您所学内容相似的实例。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig29_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig29_HTML.jpg)

图 2-23a

聚类示例

无监督学习的一个重要应用是在网络安全和*异常检测*中，例如，信用卡欺诈，其中已经显示正常交易的系统试图识别任何异常交易模式。图 [2-3b](#Fig3) 展示了聚类如何用于欺诈或异常检测。

![../images/502577_1_En_2_Chapter/502577_1_En_2_Fig30_HTML.jpg](../images/502577_1_En_2_Chapter/502577_1_En_2_Fig30_HTML.jpg)

图 2-23b

聚类异常检测

现代生活中另一个无监督学习的伟大例子是谷歌新闻，其中一种算法自动将新闻故事分组到特定的部分。表 [2-3](#Tab4) 列出了一些最常见的无监督学习算法和相关的示例用例。

表 2-3

无监督学习算法的例子

<colgroup><col class="tcol1 align-left"> <col class="tcol2 align-left"> <col class="tcol3 align-left"></colgroup> 
| 

无监督学习方法

 | 

例子

 | 

算法

 |
| --- | --- | --- |
| 使聚集 | 群集病毒数据，会议中的访问者群体 | 层次聚类，k-均值聚类 |
| 降维 | 数据维数的减少 | 主成分分析 |

### k 均值聚类

任何聚类算法的主要目标都是将数据点分配给代表它们在一个 *N* 维空间中的相似性的聚类。 *k-means 聚类*是一种无监督学习算法。无监督学习是没有标签或目标的学习。k 均值聚类是一种产生数据聚类的算法。聚类包括为所有相似的数据点分配聚类名称。通常，集群被命名为 1、2、3 等等。

k-means 聚类将几个质心作为输入，其中每个质心定义一个聚类。当算法开始时，质心被放置在数据点向量空间中的随机位置。k-means 聚类有一个称为*分配、*的阶段和另一个称为*最小化*的阶段。该算法在这两个阶段循环几次。在*分配*阶段，该算法使用欧几里德距离计算将每个数据点放置在离其最近的质心旁边。在最小化阶段，通过向使质心更靠近数据点的方向移动质心，使质心和指定给它们的所有数据点之间的距离之和最小化。这被称为一个*周期。*一个周期的结束产生一个*就绪超平面。*

在一个循环结束后，下一个循环通过将数据点与其质心分离来开始。从位置上看，质心保持不变。有了这些，一个新的关联阶段就开始了，它可能会决定分配不同于前一个周期的任务。当遇到新的数据点时，它被分配给最近的质心，并继承该质心的名称作为标签。k-means 中的聚类是质心周围的区域。

在理论设置中，聚类中不需要标签。但是如果没有标签将它们联系起来，评估指标就变得无关紧要了。如果没有要定义的元素，度量标准将定义什么？没有标签，我们无法计算真阳性、假阳性、真阴性和假阴性。[24]中给出了聚类中分类评估指标用法的详细说明，称为聚类的*外部评估。*

然而，有时我们根本无法获得标签，被迫在没有标签的情况下工作。在这种情况下，我们可以使用集群的*内部评估。在几种可用的评估指标中，Dunn [25]评估指标是最受欢迎的。邓恩系数的重点是测量一个 *N* 维空间中的团簇密度。通过计算每个聚类的邓恩系数来评估每个聚类的质量。*

### 强化学习

在这种情况下，组成学习系统的算法被称为*代理。*代理人观察、选择并执行特定的行动以换取奖励或惩罚。强化学习应用的一个例子是如何教会机器人行走或执行任务。他们因做正确的工作而得到“奖励”，因做错工作而受到“惩罚”。另一个例子是有时人们如何学习玩电子游戏。他们尝试新事物，如点击地点、开门、获得弹药或金钱，并最终学会如何玩。类似地，强化学习算法中的代理在继续从基于数据的观察和自动学习中学习时尝试新事物。强化学习的一个非常受欢迎的领域是神经网络，这将在第三章[中探讨。](3.html)

有一些非常吸引人的媒体产品很好地展示了强化学习，包括在 [`https://openai.com/blog/emergent-tool-use/`](https://openai.com/blog/emergent-tool-use/) 。

## 摘要

机器学习(ML)已经成为人工智能和认知科学研究的一个子领域，自 2014 年以来，已经被企业以惊人的速度采用。第 [2](2.html) 章讲述了进入由量子力学推动的机器学习世界所需的一些基础知识。下一章在移动到量子信息处理概念之前包括神经网络的本质。

<aside aria-label="Footnotes" class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

这指的是威斯康星大学医院的内科医生 William H. Wolberg 博士创建的威斯康星乳腺癌数据库中的一个公开可用的数据集。该数据集包含 569 个恶性和良性肿瘤细胞样本。沃尔伯格博士使用了从乳腺实性肿块患者身上采集的液体样本，以及一种易于使用的图形计算机程序 Xcyt，该程序可以基于数字扫描进行细胞学特征分析。该程序使用曲线拟合算法来计算样本中每个细胞的十个特征，然后计算图像每个特征的平均值、极值和标准误差。数据集可在 [https:// archive 获得。ics。uci。edu/ ml/数据集/乳腺癌+乳腺癌+Wi sconsin+(诊断)](https://archive.ics.uci.edu/ml/datasets/Breast%252BCancer%252BWisconsin%252B%2528Diagnostic%2529)。

 </aside>