# 5.从简单的训练集中学习分类器调整

*调优*是在不过度拟合、欠拟合或产生高方差的情况下最大化算法性能的过程。*过度拟合*是指算法训练数据过于精确，以至于可能无法拟合新数据或可靠地预测未来结果。当模型对于它试图训练的数据来说过于复杂时，通常会发生过度拟合。过于复杂的模型可以很好地训练数据，但也会拟合不属于数据的噪声。因此，当用于训练新数据时，会引入噪声，导致不可预测的结果。

*欠拟合*是指算法无法充分捕捉数据的底层结构。拟合不足的模型表现不佳，因为它不够复杂，无法捕捉数据的含义。*高方差*是指算法在预测中引入过多误差，导致性能不佳。

高性能调整是通过从模型中选择最佳超参数来实现的。模型*超参数*是模型外部的配置，其值无法从数据中估计。大多数机器学习算法都有一组超参数。有些算法很少，有些算法很多。超参数越少的算法越容易调优，因为需要考虑的调整越少。

调整机器学习算法非常困难，因为它通常是一个非直观、耗时且系统的试错过程。由于必须在训练开始前手动设置超参数，因此难度增加。通过阅读学术文章、行业书籍、在线文章(例如 Scikit-Learn 文档)、观看 YouTube 视频、数据和数据集经验、勤奋、努力工作以及简单的实践，可以增强调优专业知识。

为我们的调整示例选择的机器学习算法不是巧合。我选择它们是基于许多小时的实验、阅读和洞察力。对于给定的数据集，表现最好的算法被包括在内，表现差的算法则不包括在内。

Scikit-Learn 提供了两种优化超参数调优的工具:GridSearchCV 和 RandomizedSearchCV。 *GridSearchCV* 对估计器(或机器学习算法)的指定参数值进行彻底搜索，并返回最佳性能的超参数组合。

因此，我们需要做的就是指定我们想要试验的超参数及其值的范围，GridSearchCV 使用交叉验证来执行超参数值的所有可能组合。因此，我们自然会限制超参数的选择及其取值范围。理论上，我们可以为模型的所有超参数指定一组参数值，但是这种搜索会消耗大量的计算机资源和时间。

*RandomizedSearchCV* 基于超参数的预定子集进行评估，从给定域中随机选择选定数量的超参数对，并仅测试那些被选择的超参数对。RandomizedSearchCV 的计算成本和耗时更少，因为它不会评估每个可能的超参数组合。这种方法极大地简化了分析，而没有明显牺牲优化。对于高维数据，RandomizedSearchCV 通常是一个很好的选择，因为它可以非常快速地返回一个好的超参数组合。

### 小费

在给定足够的计算资源的情况下，使用 GridSearchCV 进行调优适合于彻底搜索性能最佳的超参数。使用 RandomizedSearchCV 进行调优适用于良好的搜索，或者如果调优高维数据。

学习调整分类器可以通过使用各种数据集和分类器的例子来加速。但是，我也建议遵循结构化流程:

1.  总是从使用基线算法的默认超参数开始。

2.  尝试训练和测试规模。

3.  处理高维数据时使用降维。

4.  处理大型数据集时，随机抽取样本。

5.  缩放数据(在适当的情况下)以潜在地提高性能。

6.  使用 GridSearchCV 或 RandomizedSearchCV 进行调整。

7.  一旦使用基线算法进行了调整，就可以使用复杂的算法进行实验。

一个*基线算法*具有很少的超参数，因此很容易调整。它还允许我们在预测建模问题上建立基线性能。使用基线提供了一个与更高级算法的比较点，您可以在稍后的调优过程中对这些算法进行评估。

### 小费

从基线算法(及其默认的超参数)开始调优，以建立基线性能。

一旦在样本数据上创建了优化的算法，如果有足够的计算机资源可用，就可以对整个数据集进行实验。虽然这样的实验可能会很昂贵，但至少我们有一个很好的模型可以使用。想象一下没有采样的试错实验的代价！

因为调优是一项复杂的工作，所以通过处理简单的数据集来学习是一个好主意。简单来说，我们指的是*低维的*和*小的*数据集。首先，调整简单的数据允许在没有大量计算费用或时间的情况下进行实验。简单数据集上的试错调优实验消耗相对较少的计算机和人员时间。第二，简单的数据集易于处理和理解。第三，我们可以通过 GridSearchCV 或 RandomizedSearchCV 使用许多(如果不是全部)超参数。

## 调整数据集

我们专注于四个数据集:虹膜、数字、银行和葡萄酒。Iris 数据集由 150 个数据元素组成，代表三种 Iris。数字数据集由 1797 个数字图像组成。银行数据集由 41188 个代表客户订阅的数据元素组成。葡萄酒数据集由 178 个代表葡萄酒质量的数据元素组成。

## 调谐虹膜数据

清单 [5-1](#PC2) 中所示的代码示例使用 KNeighborsClassifier、GridSearchCV 和 RandomizedSearchCV 来训练和调整 load_iris。因为我们在下面的代码片段中使用了人性化的软件包，并且它通常不是预装的，所以请按如下方式安装:

```py
import numpy as np, humanfriendly as hf
import time
from sklearn.datasets import load_iris
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score

def get_scores(model, Xtrain, ytrain, Xtest, ytest):
    y_pred = model.predict(Xtrain)
    train = accuracy_score(ytrain, y_pred)
    y_pred = model.predict(Xtest)
    test = accuracy_score(ytest, y_pred)
    return train, test, model.__class__.__name__

def get_cross(model, data, target, groups=10):
    return cross_val_score(model, data, target, cv=groups)

def see_time(note):
    end = time.perf_counter()
    elapsed = end - start
    print (note, hf.format_timespan(elapsed, detailed=True))

if __name__ == "__main__":
    br = '\n'
    iris = load_iris()
    X = iris.data
    y = iris.target
    targets = iris.target_names
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
    knn = KNeighborsClassifier()
    print (knn, br)
    distances = [1, 2, 3, 4, 5]
    k_range = list(range(1, 31))
    leaf = [10]
    param_grid = dict(n_neighbors=k_range, p=distances, leaf_size=leaf)
    start = time.perf_counter()
    grid = GridSearchCV(knn, param_grid, cv=10, scoring="accuracy")
    grid.fit(X, y)
    see_time('GridSearchCV total tuning time:')
    bp = grid.best_params_
    print ()
    print ('best parameters:')
    print (bp, br)
    knn_best = KNeighborsClassifier(**bp).fit(X_train, y_train)
    train, test, name = get_scores(knn_best, X_train, y_train

, X_test, y_test)
    print (name, 'train/test scores (GridSearchCV):')
    print (train, test, br)
    scores = get_cross(knn, X, y)
    print ('cross-val scores:')
    print (scores, br)
    print ('avg cross-val score:', np.mean(scores), br)
    d = grid.cv_results_
    print ('mean grid score:', np.mean(d['mean_test_score']), br)
    vector = [[3, 5, 4, 2]]
    vectors = [[2, 5, 3, 5], [1, 4, 2, 1]]
    y_pred = knn_best.predict(vector)
    print (targets[y_pred])
    y_preds = knn_best.predict(vectors)
    print (targets[y_preds], br)
    start = time.perf_counter()
    rand = RandomizedSearchCV(knn, param_grid, cv=10, random_state=0, scoring="accuracy", n_iter=10)
    rand.fit(X, y)
    see_time('RandomizedSearchCV total tuning time:')
    bp = rand.best_params_
    print()
    print ('best parameters:')
    print (bp, br)
    knn_best = KNeighborsClassifier(**bp).fit(X_train, y_train)
    train, test, name = get_scores(knn_best, X_train, y_train, X_test, y_test)
    print (name, 'train/test scores (RandomizedSearchCV):')
    print (train, test)

Listing 5-1Tuning Iris data with KNeighborsClassifier

```

```py
pip install humanfriendly

```

继续执行清单 [5-1](#PC2) 中的代码。请记住，您可以从本书的示例下载中找到示例。您不需要手动键入示例。更容易访问示例下载和复制/粘贴。

执行清单 [5-1](#PC2) 的输出应该如下所示:

```py
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric="minkowski", metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights="uniform")

GridSearchCV total tuning time: 7 seconds and 388.94 milliseconds

best parameters:
{'leaf_size': 10, 'n_neighbors': 6, 'p': 3}

KNeighborsClassifier train/test scores (GridSearchCV):
0.9732142857142857 0.9736842105263158

cross-val scores:
[1\.         0.93333333 1\.         1\.         0.86666667 0.93333333
 0.93333333 1\.         1\.         1\.        ]

avg cross-val score: 0.9666666666666668

mean grid score: 0.9673333333333333

['versicolor']
['versicolor' 'setosa']

RandomizedSearchCV total tuning time: 473.88 milliseconds

best parameters:
{'p': 3, 'n_neighbors': 13, 'leaf_size': 10}

KNeighborsClassifier train/test scores (RandomizedSearchCV):
0.9642857142857143 0.9736842105263158

```

代码从导入 GridSearchCV、RandomizedSearchCV、cross_val_score 和其他必需的包开始。函数 get_scores 返回训练测试精度和算法名称。函数 get_cross 返回交叉验证分数。函数 see_time 返回经过的时间。主模块加载数据，并将其分成训练测试子集。然后显示 KNeighborsClassifier 的超参数。

### 小费

在调整之前显示算法的超参数总是一个好主意。

我们通过调整 *p* 、 *leaf_size* 和 *n_neighbors* 来调优 KNeighborsClassifier。

### 小费

Scikit-Learn 和其他在线文档是了解算法的超参数的好地方。

*p* 是用于调整距离的闵可夫斯基度量的功率参数。调整*叶子* _ *大小*以减少邻居的候选数量。调整 *n_neighbors* 控制邻居数量。

代码继续为 GridSearchCV 创建参数网格。我们想测试距离(或 p)从 1 到 5，n_neighbors 从 1 到 31，leaf_size 为 10。通过将列表[10]分配给 leaf_size，我们覆盖了它的默认值。

### 小费

如果搜索中不包括超参数，则使用其默认值。如果搜索中包含单个值(作为列表),则其值会覆盖默认值，但不会增加搜索的计算开销。

接下来，我们使用 GridSearchCV 进行调优。注意，我们使用 X 和 y，因为 GridSearchCV 自己对数据集进行交叉验证。我们继续显示最佳参数。然后，我们使用 KNeighborsClassifier 的最佳参数。

结果非常好，因为分数超过 97%，几乎完全符合。我们对训练数据进行交叉验证，以了解一个算法应该执行得有多好。交叉验证分数略低于 97%，这意味着我们的结果是可靠的。调整实验的准确度应该接近或超过交叉验证分数。

### 小费

交叉验证分数接近我们可以从算法中获得的最佳性能。所以，我们的表现应该接近或者有望更好。

然后我们计算并显示 GridSearchCV 的平均分数。用我们调整过的模型，我们做一些预测。代码以使用具有相同参数网格的 RandomizedSearchCV 进行调优结束。分数几乎相同，但是使用 RandomizedSearchCV 所用的时间要好得多！

## 调谐数字数据

清单 [5-2](#PC4) 中所示的代码示例使用 KNeighborsClassifier、LogisticRegression 和 GridSearchCV 来训练和调整 load_digits。

```py
import numpy as np, humanfriendly as hf
import time
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split,\
     cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV

def get_scores(model, Xtrain, ytrain, Xtest, ytest):
    y_pred = model.predict(Xtrain)
    train = accuracy_score(ytrain, y_pred)
    y_pred = model.predict(Xtest)
    test = accuracy_score(ytest, y_pred)
    return train, test, model.__class__.__name__

def get_cross(model, data, target, groups=10):
    return cross_val_score(model, data, target, cv=groups)

def see_time(note):
    end = time.perf_counter()
    elapsed = end - start
    print (note, hf.format_timespan(elapsed, detailed=True))

if __name__ == "__main__":
    br = '\n'
    digits = load_digits()
    X = digits.data
    y = digits.target
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
    knn = KNeighborsClassifier().fit(X_train, y_train)
    print (knn, br)
    train, test, name = get_scores(knn, X_train, y_train, X_test, y_test)
    knn_name, acc1, acc2 = name, train, test
    print (str(knn_name) + ':')
    print ('train:', np.round(acc1, 2),
           'test:', np.round(acc2, 2), br)
    param_grid = {'n_neighbors': np.arange(1, 31, 2),
                  'metric': ['euclidean', 'cityblock']}
    start = time.perf_counter()
    grid = GridSearchCV(knn, param_grid, cv=5, n_jobs=-1)
    grid.fit(X, y)
    see_time('GridSearchCV total tuning time:')
    best_params = grid.best_params_
    print (best_params, br)
    knn_tuned = KNeighborsClassifier(**best_params)
    knn_tuned.fit(X_train, y_train)
    train, test, name = get_scores(knn_tuned, X_train, y_train, X_test, y_test)
    knn_name, acc1, acc2 = name, train, test
    print (knn_name + ' (tuned):')
    print ('train:', np.round(acc1, 2),
           'test:', np.round(acc2, 2), br)
    lr = LogisticRegression(random_state=0, max_iter=4000,
                            multi_class='auto'

, solver="lbfgs")
    print (lr, br)
    lr.fit(X_train, y_train)
    train, test, name = get_scores(lr, X_train, y_train, X_test, y_test)
    lr_name, acc1, acc2 = name, train, test
    print (lr_name + ':')
    print ('train:', np.round(acc1, 2),
           'test:', np.round(acc2, 2), br)
    param_grid = {'penalty': ['l2'],
                  'solver': ['newton-cg', 'lbfgs', 'sag'],
                  'max_iter': [4000], 'multi_class': ['auto'],
                  'C': [0.001, 0.01, 0.1]}
    start = time.perf_counter()
    grid = GridSearchCV(lr, param_grid, cv=5, n_jobs=-1)
    grid.fit(X, y)
    see_time('GridSearchCV total tuning time:')
    bp = grid.best_params_
    print (bp)
    lr_tuned = LogisticRegression(**bp, random_state=0)
    lr_tuned.fit(X_train, y_train)
    train, test, name = get_scores(lr_tuned, X_train, y_train, X_test, y_test)
    lr_name, acc1, acc2 = name, train, test

    print (lr_name + ' (tuned):')
    print ('train:', np.round(acc1, 2),
           'test:', np.round(acc2, 2), br)
    print ('cross-validation score knn:')
    knn = KNeighborsClassifier()
    scores = get_cross(knn, X, y)
    print (np.mean(scores))

Listing 5-2Tuning digits data with two algorithms

```

执行清单 [5-2](#PC4) 的输出应该如下所示:

```py
KNeighborsClassifier(algorithm='auto', leaf_size=30,
           metric='minkowski', metric_params=None, n_jobs=None,
           n_neighbors=5, p=2, weights="uniform")

KNeighborsClassifier:
train: 0.99 test: 0.98

GridSearchCV total tuning time: 9 seconds and 609.98 milliseconds
{'metric': 'euclidean', 'n_neighbors': 3}

KNeighborsClassifier (tuned):
train: 0.99 test: 0.99

LogisticRegression(C=1.0, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=4000,
          multi_class='auto', n_jobs=None, penalty="l2",
          random_state=0, solver="lbfgs", tol=0.0001, verbose=0,
          warm_start=False)

LogisticRegression:
train: 1.0 test: 0.95

GridSearchCV total tuning time: 12 seconds and 708.79 milliseconds
{'C': 0.01, 'max_iter': 4000, 'multi_class': 'auto', 'penalty': 'l2', 'solver': 'lbfgs'}
LogisticRegression (tuned):
train: 0.99 test: 0.96

cross-validation score knn:
0.9739482872546906

```

代码从导入必需的包开始。函数 get_scores 返回精确度分数和模型名称。函数 see_time 返回经过的时间。主模块将数字数据加载到 X 和 y 中，并将其分成训练测试子集。接下来，KNeighborsClassifier(使用*默认*超参数)对数据进行训练，并显示结果。

代码继续使用 GridSearchCV 进行调优。对于调优实验，KNeighborsClassifier 是模型，我们调整 *n_neighbors* 和*度量*超参数。根据我的经验和研究，邻居的数量是 KNeighborsClassifier 需要调整的最重要的超参数。超参数*度量*是用于树的距离。

调整提高了性能，因为我们有一个理想的拟合。当然，load_digits 经过了大量的预处理，这使得它很容易调优。然而，调优是如此复杂，以至于从简单的数据集学习基础知识是一个好主意。

代码继续使用 LogisticRegression 进行调优。算法(及其默认参数)太复杂，因为结果显示过度拟合。也就是说，该算法完美地训练了数据，但是测试集精度相当低。

### 小费

当测试精度比训练精度低很多时，训练算法对于数据集来说太复杂，因此会发生过拟合。

用 GridSearchCV 调优 LogisticRegression 减少了过度拟合，但在数据上的表现不如 KNeighborsClassifier。本次调优实验调整的超参数包括*罚值*、*解算器*、 *max_iter* 和 *C* 。*罚值*涉及正则化的类型。*解算器*指定优化过程中使用的算法。 *max_iter* 超参数表示求解器收敛所需的最大迭代次数。最后， *C* 表示正则化强度的倒数。C 值越小，正则化越强。

代码以使用 KNeighborsClassifier 进行交叉验证结束。我们用这个算法进行了交叉验证，因为它在数据上表现最好。*交叉验证*是用于评估机器学习模型性能的重采样程序。在这种情况下，我们的性能接近 99%，比交叉验证分数要好。因此，我们确信我们的最佳模型(KNeighborsClassifier)的性能是最佳的。如果交叉验证与我们最好的建模实验非常不同，我们可能做错了什么，或者需要继续调整。

### 小费

如果有足够的计算资源，交叉验证是测试算法准确性的一种很好的技术。

虽然 LogisticRegression 的性能不如 KNeighborsClassifier，但调优确实提高了性能。也就是说，测试性能向上调整，而训练性能向下调整。当调整将训练和测试性能相互调整时，我们就取得了进展。但是，如果我们仍然对性能不满意，我们应该继续试验。但是，至少我们正朝着积极的方向前进。

### 小费

随着调优实验将训练和测试分数相互调整，我们知道我们的调优实验正在取得进展。

## 调谐库数据

清单 [5-3](#PC6) 中显示的第一个代码示例使用 svm.SVC 调优从银行数据集中抽取的随机样本。

```py
import numpy as np, humanfriendly as hf, random
import time
from sklearn.model_selection import train_test_split,\
     RandomizedSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

def get_scores(model, xtrain, ytrain, xtest, ytest):
    ypred = model.predict(xtest)
    train = model.score(xtrain, ytrain)
    test = model.score(xtest, y_test)
    name = model.__class__.__name__
    return (name, train, test)

def get_cross(model, data, target, groups=10):
    return cross_val_score(model, data, target, cv=groups)

def prep_data(data, target):
    d = [data[i] for i, _ in enumerate(data)]
    t = [target[i] for i, _ in enumerate(target)]
    return list(zip(d, t))

def create_sample(d, n, replace="yes"):
    if replace == 'yes': s = random.sample(d, n)
    else: s = [random.choice(d)
               for i, _ in enumerate(d) if i < n]
    Xs = [row[0] for i, row in enumerate(s)]
    ys = [row[1] for i, row in enumerate(s)]
    return np.array(Xs), np.array(ys)

def see_time(note):
    end = time.perf_counter()
    elapsed = end - start
    print (note, hf.format_timespan(elapsed, detailed=True))

if __name__ == "__main__":
    br = '\n'
    X = np.load('data/X_bank.npy')
    y = np.load('data/y_bank.npy')
    sample_size = 4000
    data = prep_data(X, y)
    Xs, ys = create_sample(data, sample_size, replace="no")
    Xs = StandardScaler().fit_transform(Xs)
    X_train, X_test, y_train, y_test = train_test_split\

                                       (Xs, ys, random_state=0)
    svm = SVC(gamma='scale', random_state=0)
    print (svm, br)
    svm.fit(X_train, y_train)
    svm_scores = get_scores(svm, X_train, y_train, X_test, y_test)
    print (svm_scores[0] + ' (train, test):')
    print (svm_scores[1], svm_scores[2], br)
    Cs = [0.0001, 0.001]
    param_grid = {'C': Cs}
    start = time.perf_counter()
    rand = RandomizedSearchCV(svm, param_grid, cv=3, n_jobs = -1, random_state=0, verbose=2, n_iter=2)
    rand.fit(X, y)
    see_time('RandomizedSearchCV total tuning time:')
    bp = rand.best_params_
    print (bp, br)
    svm_tuned = SVC(**bp, gamma="scale", random_state=0)
    svm_tuned.fit(X_train, y_train)
    svm_scores = get_scores(svm_tuned, X_train, y_train, X_test, y_test)
    print (svm_scores[0] + ' (train, test):')
    print (svm_scores[1], svm_scores[2], br)
    print ('cross-validation score:')
    svm = SVC(gamma='scale')
    scores = get_cross(svm, Xs, ys)
    print (np.mean(scores))

Listing 5-3Tuning a bank data random sample with svm.SVC

```

执行清单 [5-3](#PC6) 的输出应该如下所示:

```py
SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma="scale",
  kernel='rbf', max_iter=-1, probability=False, random_state=0,
  shrinking=True, tol=0.001, verbose=False)

SVC (train, test):
0.949 0.893

Fitting 3 folds for each of 2 candidates, totalling 6 fits
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.
[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:   55.4s remaining:   55.4s
[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:   57.0s finished
RandomizedSearchCV total tuning time: 1 minute, 31 seconds and 171.06 milliseconds
{'C': 0.0001}

SVC (train, test):
0.891 0.875

cross-validation score:
0.9102441546509665

```

代码从导入 RandomizedSearchCV，svm 开始。SVC 和其他必备的包。函数 get_scores 返回精确度分数和模型名称。函数 prep_data 为函数 create_sample 中的样本处理准备数据。函数 create_sample 创建一个随机样本。函数 see_time 返回经过的时间。

主程序块加载数据，创建 4000 个无替换的样本，并将数据分成训练测试子集。接下来，我们缩放数据，用 svm 进行训练。SVC(使用默认超参数)，并显示结果。代码通过调整 svm 继续。随机搜索。

我们只调整 *C* 超参数，它是一个正则化参数，控制在训练数据上实现低误差和最小化权重范数之间的权衡。当我们增加 C 时，模型的复杂性增加，这增加了过度拟合的机会。另请注意，verbose 设置为 2(verbose = 2)。

详细参数(*而非*超参数)控制详细程度。我们设置的数字越高，收到的消息就越多。因此，在执行时，我们会注意到关于调优过程中发生了什么的消息。GridSearchCV 还有一个 verbosity 选项。

仅仅通过调整 C 的两个值，运行时间已经超过一分钟了！然而，我们似乎达到了很好的契合。交叉验证分数证实了我们在 svm 方面做得很好。SVC，但是通过更多的调优实验可以做得更好。也就是说，我们也许能够从 svm 中挤出更多的性能。SVC 与更多的实验。

### 小费

如果我们最好的模型测试分数接近交叉验证分数，我们就不需要继续调优了。

通过大量的调优实验，我能够大幅降低调优的复杂性。我不仅仅从两个 C 值开始，也不仅仅用 C 进行调优。此外，我最初尝试用整个数据集进行调优，但发现计算开销太大，所以我用一个样本进行了训练。

清单 [5-4](#PC8) 中显示的下一个代码示例使用 KNeighborsClassifier 调优从银行数据集中抽取的随机样本。

```py
import numpy as np, humanfriendly as hf, random
import time
from sklearn.model_selection import train_test_split,\
     RandomizedSearchCV, cross_val_score
from sklearn.neighbors import KNeighborsClassifier

def get_scores(model, xtrain, ytrain, xtest, ytest):
    ypred = model.predict(xtest)
    train = model.score(xtrain, ytrain)
    test = model.score(xtest, y_test)
    name = model.__class__.__name__
    return (name, train, test)

def get_cross(model, data, target, groups=10):
    return cross_val_score(model, data, target, cv=groups)

def prep_data(data, target):
    d = [data[i] for i, _ in enumerate(data)]
    t = [target[i] for i, _ in enumerate(target)]
    return list(zip(d, t))

def create_sample(d, n, replace="yes"):
    if replace == 'yes': s = random.sample(d, n)
    else: s = [random.choice(d)
               for i, _ in enumerate(d) if i < n]
    Xs = [row[0] for i, row in enumerate(s)]
    ys = [row[1] for i, row in enumerate(s)]
    return np.array(Xs), np.array(ys)

def see_time(note):
    end = time.perf_counter()
    elapsed = end - start
    print (note, hf.format_timespan(elapsed, detailed=True))

if __name__ == "__main__":
    br = '\n'
    X = np.load('data/X_bank.npy')
    y = np.load('data/y_bank.npy')
    sample_size = 4000
    data = prep_data(X, y)
    Xs, ys = create_sample(data, sample_size, replace="no")
    X_train, X_test, y_train, y_test = train_test_split\
                                       (Xs, ys, random_state=0)
    knn = KNeighborsClassifier()
    print (knn, br)
    knn.fit(X_train, y_train)
    knn_scores = get_scores(knn, X_train, y_train, X_test, y_test)
    print (knn_scores[0] + ' (train, test):')
    print (knn_scores[1], knn_scores[2], br)
    param_grid = {'n_neighbors': np.arange(1, 31, 2),
                  'metric': ['euclidean']}
    start = time.perf_counter()
    rand = RandomizedSearchCV(knn, param_grid, cv=3, n_jobs = -1,
                              random_state=0, verbose=2)
    rand.fit(X, y)
    see_time('RandomizedSearchCV total tuning time:')
    bp = rand.best_params_
    print (bp, br)
    file = 'data/bp_bank'
    np.save(file, bp)
    knn_tuned = KNeighborsClassifier(**bp).fit(X_train

, y_train)
    knn_scores = get_scores(knn_tuned, X_train, y_train, X_test, y_test)
    print (knn_scores[0] + ' (train, test):')
    print (knn_scores[1], knn_scores[2], br)
    print ('cross-validation score:')
    knn = KNeighborsClassifier()
    scores = get_cross(knn, Xs, ys)
    print (np.mean(scores))

Listing 5-4Tuning a bank data random sample with KNeighborsClassifier

```

执行清单 [5-4](#PC8) 的输出应该如下所示:

```py
KNeighborsClassifier(algorithm='auto', leaf_size=30,
           metric='minkowski', metric_params=None, n_jobs=None,
           n_neighbors=5, p=2, weights="uniform")

KNeighborsClassifier (train, test):
0.927 0.906

Fitting 3 folds for each of 10 candidates, totalling 30 fits
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.
[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   59.6s finished
RandomizedSearchCV total tuning time: 1 minute and 654.85 milliseconds
{'n_neighbors': 29, 'metric': 'euclidean'}

KNeighborsClassifier (train, test):
0.913 0.91

cross-validation score:
0.9032489046806542

```

代码从导入必需的包开始。函数 get_scores 返回精确度分数和模型名称。函数 prep_data 为函数 create_sample 中的样本处理准备数据。函数 create_sample 创建一个随机样本。函数 see_time 返回经过的时间。

主程序块加载数据，创建 4000 个无替换的样本，并将数据分成训练测试子集。接下来，我们使用 KNeighborsClassifier(使用默认的超参数)进行训练，并显示结果。代码通过用 RandomizedSearchCV 调谐来继续。我们调整 *n_neighbors* 并强制*度量*为*欧几里得*。我们还保存了最佳参数，供下一个代码示例使用。

通过实验，我发现*欧几里德*效果最好。调整 KNeighborsClassifier 提供了比使用默认参数的模型更好的拟合。交叉验证分数证实了我们做得很好，因为它非常接近我们的测试分数。请注意，我们确实使用了 10 个折叠进行交叉验证。我的经验表明，5 或 10 的交叉验证似乎效果很好。但是，要小心，因为更多的交叉验证会增加处理时间。

清单 [5-5](#PC10) 中显示的本节中的最终代码示例使用 KNeighborsClassifier 和从之前的调优练习中获得的最佳参数对*整个*银行数据集进行建模。

```py
import numpy as np, humanfriendly as hf, random
import time
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

def get_scores(model, xtrain, ytrain, xtest, ytest):
    ypred = model.predict(xtest)
    train = model.score(xtrain, ytrain)
    test = model.score(xtest, y_test)
    name = model.__class__.__name__
    return (name, train, test)

def see_time(note):
    end = time.perf_counter()
    elapsed = end - start
    print (note, hf.format_timespan(elapsed, detailed=True))

if __name__ == "__main__":
    br = '\n'
    X = np.load('data/X_bank.npy')
    y = np.load('data/y_bank.npy')
    bp = np.load('data/bp_bank.npy')
    bp = bp.tolist()
    print ('best parameters:')
    print (bp, br)
    X_train, X_test, y_train, y_test = train_test_split\
                                       (X, y, random_state=0)
    start = time.perf_counter()
    knn = KNeighborsClassifier(**bp)
    knn.fit(X_train, y_train)
    see_time('training time:')
    start = time.perf_counter()
    knn_scores = get_scores(knn, X_train, y_train, X_test, y_test)
    see_time('scoring time:')
    print ()
    print (knn_scores[0] + ' (train, test):')
    print (knn_scores[1], knn_scores[2])

Listing 5-5Tuning bank data with KNeighborsClassifier

```

执行清单 [5-5](#PC10) 的输出应该如下所示:

```py
best parameters:
{'n_neighbors': 29, 'metric': 'euclidean'}

training time: 461.58 milliseconds
scoring time: 10 seconds and 62.98 milliseconds

KNeighborsClassifier (train, test):
0.9154769997733968 0.9138584053607847

```

该代码示例导入必需的包。函数 get_scores 返回精确度分数和模型名称。函数 see_time 返回经过的时间。主程序块为 KNeighborsClassifier 加载银行数据和最佳参数。接下来，数据被分成训练测试子集。代码以使用最佳参数训练模型并显示结果结束。

结果表明，我们实现了非常好的拟合，整个处理时间不到 11 秒！因此，用随机样本进行调优是减少计算开销的一个好方法。

### 小费

随机采样是一种计算成本低廉的调整方式。

## 调整葡萄酒数据

清单 [5-6](#PC12) 中显示的第一个代码示例利用了 load_wine 上的 SGDClassifier 和 LinearDiscriminantAnalysis。

```py
import numpy as np, random
from sklearn.datasets import load_wine
from sklearn.preprocessing import StandardScaler
from sklearn.discriminant_analysis\
     import LinearDiscriminantAnalysis as LDA
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import train_test_split,\
     cross_val_score
from sklearn import metrics

def get_cross(model, data, target, groups=10):
    return cross_val_score(model, data, target, cv=groups)

if __name__ == "__main__":
    br = '\n'
    wine = load_wine()
    X = wine.data
    y = wine.target
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
    lda = LDA().fit(X_train, y_train)
    print (lda, br)
    lda_name = lda.__class__.__name__
    y_pred = lda.predict(X_train)
    accuracy = metrics.accuracy_score(y_train, y_pred)
    accuracy = str(accuracy * 100) + '%'
    print (lda_name + ':')
    print ('train:', accuracy)
    y_pred_test = lda.predict(X_test)
    accuracy = metrics.accuracy_score(y_test, y_pred_test)
    accuracy = str(round(accuracy * 100, 2)) + '%'
    print ('test: ', accuracy, br)
    print ('cross-validation:')
    scores = get_cross(lda, X, y)
    print (np.mean(scores), br)
    n, ls = 100, []
    for i, row in enumerate(range(n)):
        rs = random.randint(1, 100)
        sgd = LDA().fit(X_train, y_train)
        y_pred = lda.predict(X_test)
        accuracy = metrics.accuracy_score(y_test, y_pred)
        ls.append(accuracy)
    avg = sum(ls) / len(ls)
    print ('MCS')
    print (avg, br)
    X = StandardScaler().fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
    sgd = SGDClassifier(max_iter=100, random_state=1)
    print (sgd, br)
    sgd.fit(X_train, y_train)
    sgd_name = sgd.__class__.__name__
    y_pred = sgd.predict(X_train)
    y_pred_test = sgd.predict(X_test)
    print (sgd_name + ':')
    print('train: {:.2%}'.format(metrics.accuracy_score\
                                 (y_train, y_pred)))
    print('test:  {:.2%}\n'.format(metrics.accuracy_score\
                                   (y_test, y_pred_test)))
    print ('cross-validation:')
    scores = get_cross(sgd, X, y)
    print (np.mean(scores), br)
    n, ls = 100, []

    for i, row in enumerate(range(n)):
        rs = random.randint(1, 100)
        sgd = SGDClassifier(max_iter=100).fit(X_train, y_train)
        y_pred = sgd.predict(X_test)
        accuracy = metrics.accuracy_score(y_test, y_pred)
        ls.append(accuracy)
    avg = sum(ls) / len(ls)
    print ('MCS:')
    print (avg)

Listing 5-6Exploring wine data with two classifiers

```

执行清单 [5-6](#PC12) 的输出应该如下所示:

```py
LinearDiscriminantAnalysis(n_components=None, priors=None,
              shrinkage=None, solver="svd",
              store_covariance=False, tol=0.0001)

LinearDiscriminantAnalysis:
train: 100.0%
test:  97.78%

cross-validation:
0.9832989336085312

MCS
0.9777777777777754

SGDClassifier(alpha=0.0001, average=False, class_weight=None,
       early_stopping=False, epsilon=0.1, eta0=0.0,
       fit_intercept=True, l1_ratio=0.15,
       learning_rate='optimal', loss="hinge", max_iter=100,
       n_iter=None, n_iter_no_change=5, n_jobs=None,
       penalty='l2', power_t=0.5, random_state=1, shuffle=True,
       tol=None, validation_fraction=0.1, verbose=0,
       warm_start=False)

SGDClassifier:
train: 100.00%
test:  97.78%

cross-validation:
0.9616959064327485

MCS:
0.9966666666666663

```

代码从导入 LinearDiscriminantAnalysis、SGDClassifier 和其他必需的包开始。主模块加载 wine 数据，将其分成训练测试集，并使用线性判别分析进行训练。代码继续显示准确性分数、交叉验证和 MCS 分数。

交叉验证和 MCS 分数表明，调整很可能不会增加线性判别分析的测试准确性。所以，我们不会开始调谐实验。然而，这个例子确实证明了在不进行调整实验的情况下获得高精度分数是可能的。但是，请记住，load_wine 数据集是经过大量处理的。在工业中，数据很少如此干净或处理得如此漂亮。

代码的下一部分用 SGDClassifier 对数据进行定型。请注意，我们在将数据分成训练测试子集之前对其进行了缩放。我在没有缩放的情况下运行了一个实验，获得了非常差的结果。因此，SGDClassifier 往往会从数据缩放中受益匪浅。

线性判别分析的缩放数据不会改变结果，因此我们在该实验中没有使用缩放数据。同样，SGDClassifier 在没有调优的情况下，精度得分非常高。然而，在取得满分时要谨慎。我做了几个实验，调整了随机状态参数，结果分数变了。当然，变化不是很大，但是训练测试分数并不完美。

尽管计算成本很高，但 MCS 是一个很好的指标，可以反映算法在数据集上的表现。对于 load_wine 数据，MCS 不是问题，因为数据集很小，并且不是由高维数据组成的。交叉验证也是算法性能的一个优秀指标，但它往往比 MCS 更保守。它在计算上也比 MCS 便宜得多。

我们可以调整随机状态参数来修改结果。通过将 SGD 分类器上的随机状态从 0 改为 1，测试准确度下降到 97.78%。这是运行交叉验证和 MCS(给定足够的计算资源)的另一个原因，以了解数据集上给定算法的基线准确性。

### 小费

调整随机状态参数会改变评分结果，因此运行交叉验证以建立稳定的基线准确度分数始终是一个好主意。

清单 [5-7](#PC14) 中显示的最后一个代码示例用各种分类器对 load_wine 进行了一个实验。我用这个例子来演示如何探索给定数据集的算法的可行性。当然，我们必须考虑计算开销。但是，考虑到进行这种实验的资源，从长远来看，我们可能会节省时间和金钱。

```py
from sklearn.datasets import load_wine
from sklearn.neighbors import KNeighborsClassifier as knn
from sklearn.svm import SVC
from sklearn.gaussian_process import\
     GaussianProcessClassifier as gpc
from sklearn.gaussian_process.kernels import RBF as rbf
from sklearn.tree import DecisionTreeClassifier as dt
from sklearn.ensemble import RandomForestClassifier as rf,\
     AdaBoostClassifier as ada
from sklearn.naive_bayes import GaussianNB as gnb
from sklearn.discriminant_analysis import\
     QuadraticDiscriminantAnalysis as qda,\
     LinearDiscriminantAnalysis as lda
from sklearn.linear_model import SGDClassifier as sgd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import metrics

if __name__ == "__main__":
    br = '\n'
    wine = load_wine()
    X = wine.data
    y = wine.target
    X = StandardScaler().fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=.4, random_state=0)
    classifiers = [knn(3), qda(), lda(), gnb(),
                   SVC(kernel='linear', gamma="scale",
                       random_state=0),
                   ada(random_state=0), dt(random_state=0),
                   sgd(max_iter=100, random_state=0),
                   gpc(1.0 * rbf(1.0), random_state=0),
                   rf(random_state=0, n_estimators=100)]
    for clf in classifiers:
        clf.fit(X_train, y_train)
        train_score = clf.score(X_train, y_train)
        test_score = clf.score(X_test, y_test)
        name = clf.__class__.__name__
        print (name + '(train/test scores):')
        print (train_score, test_score)

Listing 5-7Exploring wine data with a variety of classifiers

```

执行清单 [5-7](#PC14) 的输出应该如下所示:

```py
KNeighborsClassifier(train/test scores):
0.9905660377358491 0.9027777777777778
QuadraticDiscriminantAnalysis(train/test scores):
0.9905660377358491 1.0
LinearDiscriminantAnalysis(train/test scores):
1.0 0.9722222222222222
GaussianNB(train/test scores):
0.9905660377358491 0.9444444444444444
SVC(train/test scores):
1.0 0.9722222222222222
AdaBoostClassifier(train/test scores):
1.0 0.9027777777777778
DecisionTreeClassifier(train/test scores):
1.0 0.9166666666666666
SGDClassifier(train/test scores):
1.0 0.9861111111111112
GaussianProcessClassifier(train/test scores):
1.0 0.9722222222222222
RandomForestClassifier(train/test scores):
1.0 0.9583333333333334

```

代码首先加载必要的包和各种分类器，包括 SGDClassifier 和 LinearDiscriminantAnalysis(在前面的示例中演示过)。请记住，这个例子只是一个给定适当计算资源的有趣实验。

主模块加载 wine 数据，对其进行缩放，并将其分成训练测试子集。代码继续创建分类器列表。该代码通过遍历分类器列表、用每个分类器训练数据并显示准确度得分来结束。

从结果来看，对于 load_wine 最可行的分类器是 SGD 分类器、线性判别分析、二次判别分析、svm。SVC 和 GaussianProcessClassifier。RandomForestClassifier 和 GaussianNB 也有潜力，但不如首先列出的那些。QuadraticDiscriminantAnalysis 产生了一个几乎完美的分数令人难以置信的拟合！

我们可以调整其他算法来提高它们的性能，但是我的经验和这个实验告诉我，我们应该使用最有前途的算法来节省时间和金钱。这个实验也是接触各种分类算法的好方法。